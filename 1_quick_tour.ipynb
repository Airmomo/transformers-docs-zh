{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "使用 pipeline() 是利用预训练模型进行推理的最简单的方式。你能够将 pipeline() 开箱即用地用于跨不同模态的多种任务。来看看它支持的任务列表："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 任务                 | 描述                                                         | 模态        | Pipeline 标识符                                                                                   |\n",
    "|----------------------|--------------------------------------------------------------|-------------|------------------------------------------------------------------------------------------------------|\n",
    "| 文本分类            | 为给定的文本序列指定标签                                     | 自然语言处理 | `pipeline(task=\"sentiment-analysis\")`                                                                 |\n",
    "| 文本生成            | 在给定提示的情况下生成文本                                 | 自然语言处理 | `pipeline(task=\"text-generation\")`                                                                   |\n",
    "| 总结                | 生成文本或文档序列的摘要                                     | 自然语言处理 | `pipeline(task=\"summarization\")`                                                                     |\n",
    "| 图像分类            | 为图像指定标签                                               | 计算机视觉   | `pipeline(task=\"image-classification\")`                                                               |\n",
    "| 图像分割            | 为图像的每个像素分配标签（支持语义、全景和实例分割）       | 计算机视觉   | `pipeline(task=\"image-segmentation\")`                                                                 |\n",
    "| 对象检测            | 预测图像中对象的边界框和类别                                 | 计算机视觉   | `pipeline(task=\"object-detection\")`                                                                   |\n",
    "| 音频分类            | 为某些音频数据分配标签                                       | 音频         | `pipeline(task=\"audio-classification\")`                                                               |\n",
    "| 自动语音识别        | 将语音转录为文本                                             | 音频         | `pipeline(task=\"automatic-speech-recognition\")`                                                       |\n",
    "| 视觉问题回答        | 回答一个关于图像的问题，给出一个图像和一个问题               | Multimodal多式         | `pipeline(task=\"vqa\")`                                                                               |\n",
    "| 文档问答            | 回答一个关于文档的问题，给出一个文档和一个问题               | Multimodal多式         | `pipeline(task=\"document-question-answering\")`                                                       |\n",
    "| 图像字幕            | 为给定图像生成字幕                                           | Multimodal多式         | `pipeline(task=\"image-to-text\")`                                                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以将[pipeline()](https://huggingface.co/docs/transformers/v4.44.2/zh/main_classes/pipelines#transformers.pipeline)用于任何一种上面提到的任务，如果想知道支持的任务的完整列表，可以查阅[pipeline API](https://huggingface.co/docs/transformers/v4.44.2/zh/main_classes/pipelines)。\n",
    "\n",
    "首先，创建一个 pipeline() 实例并且指定你想要将它用于的任务(`Task`)。在这篇教程中，我们将 pipeline() 用在一个情感分析任务(`task=\"sentiment-analysis\"`)上作为示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\WorkSpaces\\PythonProjects\\transformers-practice\\transformers-playground-windows-ctv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\OneDrive\\WorkSpaces\\PythonProjects\\transformers-practice\\transformers-playground-windows-ctv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\WorkSpaces\\PythonProjects\\transformers-practice\\transformers-playground-windows-ctv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "if importlib.util.find_spec(\"tf-keras\") is None:\n",
    "    raise ImportError(f\"'tf-keras' is not installed. Please install it before running this script.\")\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# pipeline() 会下载并缓存一个用于情感分析的预训练模型和分词器。\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# 在目标文本上使用 classifier\n",
    "classifier(\"We are very happy to show you the 🤗 Transformers library.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以把多个输入放入一个列表然后传给pipeline()，它将会返回一个字典列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline() 也可以遍历整个数据集。在下面这个示例中，我们选择自动语音识别作为任务, 加载 [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) 音频数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generating train split: 563 examples [00:00, 6469.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "if importlib.util.find_spec(\"soundfile\") is None:\n",
    "    raise ImportError(f\"'soundfile' is not installed. Please install it before running this script.\")\n",
    "\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "from datasets import load_dataset, Audio\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\", trust_remote_code=True)\n",
    "\n",
    "# 你需要确保数据集中音频的采样率与 facebook/wav2vec2-base-960h 训练用到的音频的采样率一致\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当调用 \"audio\" 列时, 音频文件将会自动加载并重采样。 从前四个样本中提取原始波形数组，将它作为列表传给 pipeline："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "if importlib.util.find_spec(\"librosa\") is None:\n",
    "    raise ImportError(f\"'librosa' is not installed. Please install it before running this script.\")\n",
    "\n",
    "result = speech_recognizer(dataset[:4][\"audio\"])\n",
    "print([d[\"text\"] for d in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，对于输入很大的大型数据集（如语音或视觉），则需要传递一个生成器而不是用一个列表来加载内存中的所有输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在 pipeline 中使用另一个模型和分词器\n",
    "\n",
    "在上文中提到，若 pipeline() 在指定任务后未指定模型和分词器，则会下载并缓存一个用于情感分析的预训练模型和分词器。\n",
    "\n",
    "因为 pipeline() 可以容纳Hub中的任何模型，从而我们可以轻松地让 pipeline() 适用于其他用例。\n",
    "\n",
    "例如，如果您想要一个能够处理法语文本的模型，可以先使用 Hub 上的 `Tags` 筛选合适的模型。\n",
    "\n",
    "在这里，我们选择了一个多语言BERT模型，该模型经过微调，可用于法语文本的情感分析："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多语言BERT模型\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 transformers 库中，加载预训练模型主要有两种方式：\n",
    "- **使用 pipeline() 加载。**\n",
    "\n",
    "    **特点**\n",
    "\n",
    "    1. 高阶封装：pipeline 函数提供了一个高阶封装，使得加载和使用预训练模型变得非常简单。\n",
    "    2. 易用性：适合快速实验和原型开发，因为它自动处理了很多细节，如模型加载、分词器配置等。\n",
    "    3. 多功能：支持多种任务类型（如文本分类、问答、命名实体识别等），**只需指定任务名称**即可。\n",
    "    4. 默认配置：**使用默认的模型和分词器配置**，无需手动调整。\n",
    "\n",
    "    **适用场景**\n",
    "    \n",
    "    1. 快速验证模型效果。\n",
    "    2. 简单的应用程序开发。\n",
    "    3. 不需要自定义模型或分词器配置的情况。\n",
    "- **直接加载模型和分词器。**\n",
    "\n",
    "    **特点**\n",
    "\n",
    "    1. 灵活性：允许更细粒度的控制和自定义，如修改分词器的配置、调整模型的超参数等。\n",
    "    2. 可扩展性：适合**需要自定义模型或分词器**的情况，例如添加新的特殊标记、调整分词策略等。\n",
    "    3. 显式控制：加载模型和分词器的过程是显式的，便于调试和理解。\n",
    "\n",
    "    **适用场景**\n",
    "\n",
    "    1. 需要自定义模型或分词器配置。\n",
    "    2. 进行更深入的模型研究和调优。\n",
    "    3. 开发复杂的应用程序，需要更精细的控制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里使用`AutoModelForSequenceClassification`和`AutoTokenizer`直接加载预训练模型及其关联的分词器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\WorkSpaces\\PythonProjects\\transformers-practice\\transformers-playground-windows-ctv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Pytorch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 pipeline() 中指定模型和分词器`tokenizer`，现在您可以将分类器`classifier`来处理法语文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "# 在后台，`AutoModelForSequenceClassification`和`AutoTokenizer`类一起工作，为上面使用的 pipeline() 提供动力。\n",
    "\n",
    "classifier(\"Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你没有找到适合你的模型，就需要在你的数据上微调一个预训练模型了。\n",
    "\n",
    "查看[微调教程](https://huggingface.co/docs/transformers/v4.44.2/zh/training)来学习怎样进行微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Class\n",
    "\n",
    "`AutoClass`是一种快捷方式，可以从预训练模型的名称或路径中自动检索其架构，你只需为任务及其关联的预处理类选择适当的`AutoClass`。\n",
    "\n",
    "让我们回到上一节的示例，看看如何使用 AutoClass 复制 pipeline() 的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoTokenizer\n",
    "\n",
    "分词器负责预处理文本，将文本转换为用于输入模型的数字数组。有多个用来管理分词过程的规则，包括如何拆分单词和在什么样的级别上拆分单词。\n",
    "\n",
    "注意：实例化的分词器要与模型的名称相同, 以确保和模型训练时使用相同的分词规则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "# 使用AutoTokenizer加载令牌化器，实例化的分词器要与模型的名称相同\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将文本传入分词器 tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(\"We are very happy to show you the 🤗 Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分词器返回了含有如下内容的字典:\n",
    "- input_ids：这是一个整数序列，每个整数代表词汇表中的一个特定token。**模型使用这个序列作为输入来理解和处理文本数据**。\n",
    "- token_type_ids：token_type_ids 是一个与 input_ids 相同长度的序列，它表示输入序列中每个 token 的类型。这个字段主要用于**区分不同类型的输入序列**，尤其是在处理由多个文本序列组成的输入时，例如问答系统中的问题和答案，或者文本分类任务中的文本和标签。\n",
    "- attention_mask：这个序列表示输入序列中哪些 token 是实际的文本token，哪些是填充（padding）token。在处理批量数据时，**由于不同序列的长度可能不同，通常需要使用填充token来使所有序列长度一致**。`attention_mask` 中的 `1 表示实际的文本token`，而 `0 表示填充token`，这样模型就可以忽略填充token。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分词器也可以接受列表作为输入，并填充和截断文本，返回具有统一长度的批次："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "tf_batch = tokenizer(\n",
    "    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查阅[预处理数据教程](https://huggingface.co/docs/transformers/v4.44.2/zh/preprocessing)来获得有关分词的更详细的信息，以及如何使用 `AutoFeatureExtractor` 和 `AutoProcessor` 来处理图像，音频，还有多模式输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoModel\n",
    "\n",
    "🤗 Transformers 提供了一种简单统一的方式来加载预训练的实例. 这表示你可以像加载 AutoTokenizer 一样加载 AutoModel。\n",
    "\n",
    "需要注意的是，**AutoModel 是一个通用的接口，它可以加载各种类型的预训练模型，但可能需要额外的配置才能用于特定任务。**\n",
    "\n",
    "而 `AutoModelForSequenceClassification` 是专门为文本或序列的分类任务定制的接口，已自动为你配置好了一个适用于序列分类任务的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 [任务摘要](https://huggingface.co/docs/transformers/v4.44.2/zh/task_summary) 查找 AutoModel 支持的任务."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在可以把之前预处理好的输入批次直接传递模型。你需要通过 ** 来解包字典:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "pt_outputs = pt_model(**pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "tf_outputs = tf_model(**tf_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**logits**\n",
    "- 定义：logits是模型输出的原始分数，通常是通过一个线性层（全连接层）得到的。这些分数在没有经过任何激活函数处理之前，表示模型对每个类别的原始预测值。\n",
    "- 作用：logits本身并不直接表示概率，而是需要通过激活函数（如softmax）转换为概率。\n",
    "**激活结果**\n",
    "- 定义：激活结果通常是指将logits通过激活函数（如softmax、sigmoid等）处理后的输出。激活函数的作用是将logits转换为某种形式的概率或决策边界。\n",
    "- 作用：激活函数可以使模型的输出更易于解释和使用。例如，softmax函数可以将logits转换为多类分类任务中的概率分布。\n",
    "\n",
    "模型在 `pt_outputs.logits` 输出最终的激活结果. 这里在 logits 上应用 `softmax` 函数来查询概率:\n",
    "- `dim = -1`：表示在最后一个维度上进行softmax操作，通常在多类分类任务中，最后一个维度是类别维度。\n",
    "- 在多类分类任务中，softmax 函数将 logits 转换为概率分布，能够帮助我们了解模型对每个类别的预测置信度，从而做出更准确的决策。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pt_predictions` 是一个概率分布，每个元素表示对应类别的概率，每个类别的概率值表示模型对该类别的置信度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "tf_predictions = tf.nn.softmax(tf_outputs.logits, dim=-1)\n",
    "print(tf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有 🤗 Transformers 模型（PyTorch 或 TensorFlow）在最终的激活函数（比如 softmax）之前输出张量， 因为最终的激活函数常常与损失(loss)融合。\n",
    "\n",
    "模型的输出是特殊的数据类，所以它们的属性可以在 IDE 中被自动补全。模型的输出就像一个元组或字典（你可以通过整数、切片或字符串来索引它），为 None 的属性会被忽略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型\n",
    "\n",
    "当你的模型微调完成(预训练完成)，可以使用 `PreTrainedModel.save_pretrained()` 把模型和模型的分词器保存下来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "pt_model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "tf_save_directory = \"./tf_save_pretrained\"\n",
    "tokenizer.save_pretrained(tf_save_directory)\n",
    "tf_model.save_pretrained(tf_save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次使用这个模型时，可以使用 `PreTrainedModel.from_pretrained()` 加载它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"./tf_save_pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤗 Transformers 有一个特别酷的功能，保存一个模型后，在加载时可以选择地将它加载为 PyTorch 或 TensorFlow 模型。`from_pt` 或 `from_tf` 参数可以将模型从一个框架转换为另一个框架："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow To Pytorch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True) # from_tf 将 TensorFlow 模型加载为 PyTorch 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch To TensorFlow\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n",
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义模型构建\n",
    "\n",
    "你可以修改模型的配置类来改变模型的构建方式。配置模型的属性，比如隐藏层或者注意力头的数量。当你根据自定义的配置类初始化模型时，模型的属性都是随机初始化的，你需要先训练模型才能得到有意义的结果。\n",
    "\n",
    "自定义模型构建通过导入 `AutoConfig` 来加载你想修改的预训练模型。在 `AutoConfig.from_pretrained()` 中，你能够指定想要修改的属性，比如注意力头的数量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `AutoModel.from_config()` 根据你的自定义配置创建一个模型:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "from transformers import AutoModel\n",
    "\n",
    "my_model = AutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "my_model = TFAutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer - PyTorch 优化训练循环\n",
    "\n",
    "所有的模型都是标准的 `[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)`，所以你可以在任何典型的训练模型中使用它们。\n",
    "\n",
    "当你编写自己的训练循环时，🤗 Transformers 为 PyTorch 提供了一个 `Trainer` 类，它包含了基础的训练循环并且为诸如分布式训练，混合精度等特性增加了额外的功能。\n",
    "\n",
    "根据于你的任务, 你可以传递以下的参数给 `Trainer`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用 `PreTrainedModel` 或者 `torch.nn.Module` 来开始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **`TrainingArguments` 含有你可以修改的模型超参数**，比如学习率，批次大小和训练时的迭代次数。如果你没有指定训练参数，那么它会使用默认值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"path/to/save/folder/\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 加载一个预处理类，比如分词器，特征提取器或者处理器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 加载一个数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 创建一个给数据集用于分词的函数，并且使用 `map` 将分词器应用到整个数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])\n",
    "\n",
    "dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 创建一个数据集预处理工具 `DataCollatorWithPadding`\n",
    "\n",
    "- `DataCollatorWithPadding` 是一个高效的数据预处理工具，能够自动处理批次数据的填充和掩码生成，极大地简化了NLP任务中的数据预处理步骤。通过使用这个类，可以确保模型输入的一致性，提高训练效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在把所有的类传给 `Trainer`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ") \n",
    "# 一切准备就绪后，调用 train() 进行训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于像翻译或摘要这些使用序列到序列模型的任务，用 `Seq2SeqTrainer` 和 `Seq2SeqTrainingArguments` 来替代。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义训练循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以通过子类化 `Trainer` 并重写其中的方法来自定义训练循环。这样你就可以**自定义像损失函数，优化器和调度器等这样的特性**。查阅 [Trainer 参考手册](https://huggingface.co/docs/transformers/v4.44.2/en/main_classes/trainer#transformers.Trainer)了解哪些方法能够被子类化。\n",
    "\n",
    "另一个自定义训练循环的方式是通过[回调(Callbacks)](https://huggingface.co/docs/transformers/main_classes/callback)。你可以**使用回调来与其他库集成**，查看训练循环来报告进度或提前结束训练。\n",
    "\n",
    "**注意：回调并不会修改训练循环。如果想自定义损失函数等，就需要子类化 Trainer 了。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 Tensorflow 训练\n",
    "\n",
    "所有模型都是标准的 `[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)`，所以你可以**通过 `Keras API` 实现在 Tensorflow 中训练**。\n",
    "\n",
    "🤗 Transformers 提供了 `prepare_tf_dataset()` 方法来轻松地将数据集加载为 `tf.data.Dataset`，这样你就可以使用 Keras 的 `compile` 和 `fit` 方法马上开始训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用 `TFPreTrainedModel` 或者 `tf.keras.Model` 来开始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 加载一个数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 加载一个预处理类，比如分词器，特征提取器或者处理器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 创建一个给数据集用于分词的函数，并且使用 `map` 将分词器应用到整个数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])\n",
    "\n",
    "dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 将数据集和分词器传给 `prepare_tf_dataset()`对数据集进行预处理。如果你需要的话，也可以在这里改变批次大小和是否打乱数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "tf_dataset = model.prepare_tf_dataset(\n",
    "    dataset, batch_size=16, shuffle=True, tokenizer=tokenizer\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 一切准备就绪后，调用 `compile` 和 `fit` 开始训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "from transformers.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(3e-5))\n",
    "model.fit(dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 接下来做什么\n",
    "\n",
    "现在你已经完成了 🤗 Transformers 的快速上手教程，来看看我们的指南并且学习如何做一些更具体的事情，比如写一个自定义模型，为某个任务微调一个模型以及如何使用脚本来训练模型。\n",
    "\n",
    "如果你有兴趣了解更多 🤗 Transformers 的核心章节，那就喝杯咖啡然后来看看我们的概念指南吧！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
