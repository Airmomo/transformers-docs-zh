{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb22abab",
   "metadata": {},
   "source": [
    "# é—®é¢˜è§£ç­”(é—®ç­”ä»»åŠ¡)\n",
    "\n",
    "é—®é¢˜è§£ç­”ä»»åŠ¡æ˜¯ç»™å®šä¸€ä¸ªé—®é¢˜ï¼Œè¿”å›ä¸€ä¸ªç­”æ¡ˆã€‚å¦‚æœä½ æ›¾ç»é—®è¿‡åƒ Alexaã€Siri æˆ– Google è¿™æ ·çš„è™šæ‹ŸåŠ©æ‰‹å¤©æ°”å¦‚ä½•ï¼Œé‚£ä¹ˆä½ å·²ç»ä½¿ç”¨è¿‡é—®é¢˜è§£ç­”æ¨¡å‹äº†ã€‚é—®é¢˜è§£ç­”ä»»åŠ¡ä¸»è¦æœ‰ä¸¤ç§ç±»å‹ï¼š\n",
    "\n",
    "- **æŠ½å–å¼**ï¼šä»ç»™å®šçš„ä¸Šä¸‹æ–‡ä¸­æå–ç­”æ¡ˆã€‚\n",
    "- **æŠ½è±¡å¼**ï¼šæ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆä¸€ä¸ªæ­£ç¡®å›ç­”é—®é¢˜çš„ç­”æ¡ˆã€‚\n",
    "\n",
    "æœ¬æŒ‡å—å°†å‘ä½ å±•ç¤ºå¦‚ä½•ï¼š\n",
    "\n",
    "1. åœ¨ [SQuAD](https://huggingface.co/datasets/squad) æ•°æ®é›†ä¸Šå¾®è°ƒ [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) æ¨¡å‹ï¼Œç”¨äºæŠ½å–å¼é—®é¢˜è§£ç­”ã€‚\n",
    "2. ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚\n",
    "\n",
    "è¦æŸ¥çœ‹æ‰€æœ‰ä¸è¯¥ä»»åŠ¡å…¼å®¹çš„æ¶æ„å’Œæ£€æŸ¥ç‚¹ï¼Œæˆ‘ä»¬å»ºè®®æŸ¥çœ‹ [ä»»åŠ¡é¡µé¢](https://huggingface.co/tasks/question-answering)ã€‚\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²ç»å®‰è£…äº†æ‰€æœ‰å¿…è¦çš„åº“ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a18452",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f297b",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬é¼“åŠ±ä½ ç™»å½•ä½ çš„ Hugging Face è´¦æˆ·ï¼Œè¿™æ ·ä½ å°±å¯ä»¥ä¸Šä¼ å¹¶ä¸ç¤¾åŒºåˆ†äº«ä½ çš„æ¨¡å‹ã€‚å½“æç¤ºæ—¶ï¼Œè¾“å…¥ä½ çš„ä»¤ç‰Œç™»å½•ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b820257",
   "metadata": {},
   "source": [
    "\n",
    "## åŠ è½½ SQuAD æ•°æ®é›†\n",
    "\n",
    "é¦–å…ˆä» ğŸ¤— Datasets åº“ä¸­åŠ è½½ SQuAD æ•°æ®é›†çš„ä¸€ä¸ªè¾ƒå°çš„å­é›†ã€‚è¿™å°†è®©ä½ æœ‰æœºä¼šè¿›è¡Œå®éªŒï¼Œå¹¶ç¡®ä¿ä¸€åˆ‡æ­£å¸¸å·¥ä½œï¼Œç„¶åå†åœ¨å®Œæ•´æ•°æ®é›†ä¸ŠèŠ±è´¹æ›´å¤šæ—¶é—´è¿›è¡Œè®­ç»ƒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "squad = load_dataset(\"squad\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a251401",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) æ–¹æ³•å°†æ•°æ®é›†çš„ `train` åˆ†å‰²æˆä¸€ä¸ªè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1142ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = squad.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec3223f",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åæŸ¥çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6340b",
   "metadata": {},
   "source": [
    "\n",
    "è¿™é‡Œæœ‰å‡ ä¸ªé‡è¦çš„å­—æ®µï¼š\n",
    "\n",
    "- `answers`ï¼šç­”æ¡ˆçš„èµ·å§‹ä½ç½®å’Œç­”æ¡ˆæ–‡æœ¬ã€‚\n",
    "- `context`ï¼šæ¨¡å‹éœ€è¦ä»ä¸­æå–ç­”æ¡ˆçš„èƒŒæ™¯ä¿¡æ¯ã€‚\n",
    "- `question`ï¼šæ¨¡å‹åº”è¯¥å›ç­”çš„é—®é¢˜ã€‚\n",
    "\n",
    "## é¢„å¤„ç†\n",
    "\n",
    "ä¸‹ä¸€æ­¥æ˜¯åŠ è½½ DistilBERT åˆ†è¯å™¨æ¥å¤„ç† `question` å’Œ `context` å­—æ®µï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750882d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8cf830",
   "metadata": {},
   "source": [
    "\n",
    "é—®é¢˜è§£ç­”ä»»åŠ¡æœ‰ä¸€äº›ç‰¹æ®Šçš„é¢„å¤„ç†æ­¥éª¤ä½ åº”è¯¥æ³¨æ„ï¼š\n",
    "\n",
    "1. æ•°æ®é›†ä¸­çš„æŸäº›ç¤ºä¾‹å¯èƒ½æœ‰ä¸€ä¸ªéå¸¸é•¿çš„ `context`ï¼Œè¶…è¿‡äº†æ¨¡å‹çš„è¾“å…¥é•¿åº¦é™åˆ¶ã€‚ä¸ºäº†å¤„ç†æ›´é•¿çš„åºåˆ—ï¼Œåªæˆªæ–­ `context`ï¼Œè®¾ç½® `truncation=\"only_second\"`ã€‚\n",
    "2. æ¥ä¸‹æ¥ï¼Œé€šè¿‡è®¾ç½® `return_offset_mapping=True`ï¼Œå°†ç­”æ¡ˆçš„èµ·å§‹å’Œç»“æŸä½ç½®æ˜ å°„åˆ°åŸå§‹ `context`ã€‚\n",
    "3. æœ‰äº†æ˜ å°„ï¼Œç°åœ¨ä½ å¯ä»¥æ‰¾åˆ°ç­”æ¡ˆçš„èµ·å§‹å’Œç»“æŸæ ‡è®°ã€‚ä½¿ç”¨ [sequence_ids](https://huggingface.co/docs/tokenizers/main/en/api/encoding#tokenizers.Encoding.sequence_ids) æ–¹æ³•æ¥æ‰¾åˆ°åç§»é‡ä¸­å“ªéƒ¨åˆ†å¯¹åº”äº `question`ï¼Œå“ªéƒ¨åˆ†å¯¹åº”äº `context`ã€‚\n",
    "\n",
    "ä»¥ä¸‹æ˜¯å¦‚ä½•åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥æˆªæ–­å¹¶å°† `answer` çš„èµ·å§‹å’Œç»“æŸæ ‡è®°æ˜ å°„åˆ° `context`ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9da4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # æ‰¾åˆ°ä¸Šä¸‹æ–‡çš„å¼€å§‹å’Œç»“æŸ\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # å¦‚æœç­”æ¡ˆä¸å®Œå…¨åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œæ ‡è®°ä¸º (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # å¦åˆ™å®ƒæ˜¯èµ·å§‹å’Œç»“æŸæ ‡è®°çš„ä½ç½®\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69832219",
   "metadata": {},
   "source": [
    "\n",
    "è¦åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨é¢„å¤„ç†å‡½æ•°ï¼Œä½¿ç”¨ ğŸ¤— Datasets çš„ [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) å‡½æ•°ã€‚ä½ å¯ä»¥é€šè¿‡è®¾ç½® `batched=True` æ¥åŠ é€Ÿ `map` å‡½æ•°ï¼Œä»¥ä¾¿ä¸€æ¬¡å¤„ç†æ•°æ®é›†ä¸­çš„å¤šä¸ªå…ƒç´ ã€‚åˆ é™¤ä½ ä¸éœ€è¦çš„ä»»ä½•åˆ—ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf9d2e9",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨ä½¿ç”¨ [DefaultDataCollator](/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator) åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ‰¹æ¬¡ã€‚ä¸å…¶ä»– ğŸ¤— Transformers ä¸­çš„æ•°æ®æ•´ç†å™¨ä¸åŒï¼Œ[DefaultDataCollator](/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator) ä¸ä¼šåº”ç”¨ä»»ä½•é¢å¤–çš„é¢„å¤„ç†ï¼Œå¦‚å¡«å……ã€‚\n",
    "\n",
    "Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ae3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edb8e2",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fec564",
   "metadata": {},
   "source": [
    "\n",
    "## è®­ç»ƒ\n",
    "\n",
    "Pytorch\n",
    "\n",
    "å¦‚æœä½ ä¸ç†Ÿæ‚‰ä½¿ç”¨ [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹è¿™é‡Œçš„åŸºæœ¬æ•™ç¨‹ [è¿™é‡Œ](../training#train-with-pytorch-trainer)ï¼\n",
    "\n",
    "ç°åœ¨ä½ å‡†å¤‡å¥½å¼€å§‹è®­ç»ƒä½ çš„æ¨¡å‹äº†ï¼ä½¿ç”¨ [AutoModelForQuestionAnswering](/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForQuestionAnswering) åŠ è½½ DistilBERTï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661217b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0cdc70",
   "metadata": {},
   "source": [
    "\n",
    "åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œåªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "1. åœ¨ [TrainingArguments](/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) ä¸­å®šä¹‰ä½ çš„è®­ç»ƒè¶…å‚æ•°ã€‚å”¯ä¸€éœ€è¦çš„å‚æ•°æ˜¯ `output_dir`ï¼Œå®ƒæŒ‡å®šäº†ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚é€šè¿‡è®¾ç½® `push_to_hub=True` å°†æ¨¡å‹æ¨é€åˆ° Hubï¼ˆä½ éœ€è¦ç™»å½• Hugging Face æ‰èƒ½ä¸Šä¼ ä½ çš„æ¨¡å‹ï¼‰ã€‚\n",
    "2. å°†è®­ç»ƒå‚æ•°ä¼ é€’ç»™ [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)ï¼Œä»¥åŠæ¨¡å‹ã€æ•°æ®é›†ã€åˆ†è¯å™¨å’Œæ•°æ®æ•´ç†å™¨ã€‚\n",
    "3. è°ƒç”¨ [train()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) æ¥å¾®è°ƒä½ çš„æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63745d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_qa_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62ac09",
   "metadata": {},
   "source": [
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ [push_to_hub()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) æ–¹æ³•å°†ä½ çš„æ¨¡å‹åˆ†äº«åˆ° Hubï¼Œä»¥ä¾¿æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨ä½ çš„æ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1db644",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow\n",
    "\n",
    "å¦‚æœä½ ä¸ç†Ÿæ‚‰ä½¿ç”¨ Keras å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹è¿™é‡Œçš„åŸºæœ¬æ•™ç¨‹ [è¿™é‡Œ](../training#train-a-tensorflow-model-with-keras)ï¼\n",
    "\n",
    "è¦åœ¨ TensorFlow ä¸­å¾®è°ƒæ¨¡å‹ï¼Œé¦–å…ˆè®¾ç½®ä¸€ä¸ªä¼˜åŒ–å™¨å‡½æ•°ã€å­¦ä¹ ç‡è®¡åˆ’å’Œä¸€äº›è®­ç»ƒè¶…å‚æ•°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "batch_size = 16\n",
    "num_epochs = 2\n",
    "total_train_steps = (len(tokenized_squad[\"train\"]) // batch_size) * num_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=total_train_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3c4ac",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åä½¿ç”¨ [TFAutoModelForQuestionAnswering](/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForQuestionAnswering) åŠ è½½ DistilBERTï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23197e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996e65d",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [prepare_tf_dataset()](/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) å°†ä½ çš„æ•°æ®é›†è½¬æ¢ä¸º `tf.data.Dataset` æ ¼å¼ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_squad[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_squad[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49983c",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [`compile`](https://keras.io/api/models/model_training_apis/#compile-method) é…ç½®æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3539309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf9a470",
   "metadata": {},
   "source": [
    "\n",
    "åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰è¦è®¾ç½®çš„æœ€åä¸€ä»¶äº‹æ˜¯æä¾›ä¸€ç§å°†æ¨¡å‹æ¨é€åˆ° Hub çš„æ–¹æ³•ã€‚è¿™å¯ä»¥é€šè¿‡åœ¨ [PushToHubCallback](/docs/transformers/main/en/main_classes/keras_callbacks#transformers.PushToHubCallback) ä¸­æŒ‡å®šå°†æ¨¡å‹å’Œåˆ†è¯å™¨æ¨é€åˆ°å“ªé‡Œæ¥å®ç°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "callback = PushToHubCallback(\n",
    "    output_dir=\"my_awesome_qa_model\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b289d",
   "metadata": {},
   "source": [
    "\n",
    "æœ€åï¼Œä½ å‡†å¤‡å¥½å¼€å§‹è®­ç»ƒä½ çš„æ¨¡å‹äº†ï¼è°ƒç”¨ [`fit`](https://keras.io/api/models/model_training_apis/#fit-method)ï¼Œä½¿ç”¨ä½ çš„è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ã€epoch æ•°é‡å’Œä½ çš„å›è°ƒæ¥å¾®è°ƒæ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c4e6d2",
   "metadata": {},
   "source": [
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œä½ çš„æ¨¡å‹ä¼šè‡ªåŠ¨ä¸Šä¼ åˆ° Hubï¼Œä»¥ä¾¿æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨å®ƒï¼\n",
    "\n",
    "å¦‚æœä½ æƒ³è¦æ›´æ·±å…¥åœ°äº†è§£å¦‚ä½•ä¸ºé—®é¢˜è§£ç­”å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹ç›¸åº”çš„ [PyTorch ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb) æˆ– [TensorFlow ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)ã€‚\n",
    "\n",
    "## è¯„ä¼°\n",
    "\n",
    "é—®é¢˜è§£ç­”çš„è¯„ä¼°éœ€è¦å¤§é‡çš„åå¤„ç†ã€‚ä¸ºäº†ä¸å ç”¨ä½ å¤ªå¤šæ—¶é—´ï¼Œæœ¬æŒ‡å—è·³è¿‡äº†è¯„ä¼°æ­¥éª¤ã€‚[Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) ä»ç„¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®¡ç®—è¯„ä¼°æŸå¤±ï¼Œæ‰€ä»¥ä½ ä¸ä¼šå®Œå…¨ä¸çŸ¥é“ä½ çš„æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
    "\n",
    "å¦‚æœä½ æœ‰æ›´å¤šæ—¶é—´ï¼Œå¹¶ä¸”å¯¹å¦‚ä½•è¯„ä¼°ä½ çš„é—®é¢˜è§£ç­”æ¨¡å‹æ„Ÿå…´è¶£ï¼Œè¯·æŸ¥çœ‹ ğŸ¤— Hugging Face è¯¾ç¨‹ä¸­çš„ [é—®é¢˜è§£ç­”](https://huggingface.co/course/chapter7/7?fw=pt#post-processing) ç« èŠ‚ï¼\n",
    "\n",
    "## æ¨ç†\n",
    "\n",
    "å¤ªå¥½äº†ï¼Œç°åœ¨ä½ å·²ç»å¾®è°ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œä½ å¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†äº†ï¼\n",
    "\n",
    "æƒ³å‡ºä¸€ä¸ªé—®é¢˜å’Œä¸€äº›ä½ æƒ³è¦æ¨¡å‹é¢„æµ‹çš„ä¸Šä¸‹æ–‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f756e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many programming languages does BLOOM support?\"\n",
    "context = \"BLOOM has 176 billion parameters and can generate text in 46 natural languages and 13 programming languages.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab3a51",
   "metadata": {},
   "source": [
    "\n",
    "å°è¯•ä½ çš„å¾®è°ƒæ¨¡å‹è¿›è¡Œæ¨ç†çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨å®ƒåœ¨ä¸€ä¸ª [pipeline()](/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) ä¸­ã€‚ä¸ºé—®é¢˜è§£ç­”å®ä¾‹åŒ–ä¸€ä¸ª `pipeline`ï¼Œå¹¶å°†ä½ çš„æ–‡æœ¬ä¼ é€’ç»™å®ƒï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model=\"my_awesome_qa_model\")\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0936c2a1",
   "metadata": {},
   "source": [
    "\n",
    "å¦‚æœä½ æ„¿æ„ï¼Œä½ ä¹Ÿå¯ä»¥æ‰‹åŠ¨å¤åˆ¶ `pipeline` çš„ç»“æœï¼š\n",
    "\n",
    "Pytorch\n",
    "\n",
    "å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯å¹¶è¿”å› PyTorch å¼ é‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed136856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"my_awesome_qa_model\")\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e181aa",
   "metadata": {},
   "source": [
    "\n",
    "å°†ä½ çš„è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å¹¶è¿”å› `logits`ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195faf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"my_awesome_qa_model\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e925b",
   "metadata": {},
   "source": [
    "\n",
    "ä»æ¨¡å‹è¾“å‡ºä¸­è·å–èµ·å§‹å’Œç»“æŸä½ç½®çš„æœ€é«˜æ¦‚ç‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1401c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d48a5a",
   "metadata": {},
   "source": [
    "\n",
    "è§£ç é¢„æµ‹çš„æ ‡è®°ä»¥è·å¾—ç­”æ¡ˆï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b829663",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651a280",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow\n",
    "\n",
    "å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯å¹¶è¿”å› TensorFlow å¼ é‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f82566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"my_awesome_qa_model\")\n",
    "inputs = tokenizer(question, text, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1dc710",
   "metadata": {},
   "source": [
    "\n",
    "å°†ä½ çš„è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å¹¶è¿”å› `logits`ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64728534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"my_awesome_qa_model\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6555fe86",
   "metadata": {},
   "source": [
    "\n",
    "ä»æ¨¡å‹è¾“å‡ºä¸­è·å–èµ·å§‹å’Œç»“æŸä½ç½®çš„æœ€é«˜æ¦‚ç‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])\n",
    "answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00095b9",
   "metadata": {},
   "source": [
    "\n",
    "è§£ç é¢„æµ‹çš„æ ‡è®°ä»¥è·å¾—ç­”æ¡ˆï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "tokenizer.decode(predict_answer_tokens)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
