{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5fab6ed",
   "metadata": {},
   "source": [
    "# 图像分类\n",
    "\n",
    "图像分类是为图像分配标签或类别的任务。与文本或音频分类不同，图像分类的输入是构成图像的像素值。图像分类有许多应用，例如在自然灾害后检测损坏情况、监测作物健康状况或帮助筛选医学图像以寻找疾病的迹象。\n",
    "\n",
    "本指南将说明如何：\n",
    "\n",
    "1. 在 [Food-101](https://huggingface.co/datasets/food101) 数据集上微调 [ViT](model_doc/vit) 模型，以对图像中的食物项进行分类。\n",
    "2. 使用微调后的模型进行推理。\n",
    "\n",
    "要查看所有与该任务兼容的架构和检查点，我们建议查看 [任务页面](https://huggingface.co/tasks/image-classification)。\n",
    "\n",
    "在开始之前，请确保您已安装所有必要的库：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f54240",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate accelerate pillow torchvision scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee4597",
   "metadata": {},
   "source": [
    "\n",
    "我们鼓励您登录您的 Hugging Face 账户，上传并与社区分享您的模型。当提示时，输入您的令牌以登录：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b707a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70cfb5e",
   "metadata": {},
   "source": [
    "\n",
    "## 加载 Food-101 数据集\n",
    "\n",
    "首先，从 🤗 Datasets 库中加载 Food-101 数据集的一个较小的子集。这将让您有机会进行实验，并确保一切正常工作，然后再在完整数据集上花费更多时间进行训练。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "food = load_dataset(\"food101\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b7661",
   "metadata": {},
   "source": [
    "\n",
    "使用 [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) 方法将数据集的 `train` 分割成训练集和测试集：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eac54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "food = food.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d225f2a2",
   "metadata": {},
   "source": [
    "\n",
    "然后查看一个示例：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "food[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8e20f",
   "metadata": {},
   "source": [
    "\n",
    "数据集中的每个示例都有两个字段：\n",
    "\n",
    "- `image`：食物项的 PIL 图像\n",
    "- `label`：食物项的标签类别\n",
    "\n",
    "为了使模型能够从标签 ID 获取标签名称，创建一个将标签名称映射到整数和反之亦然的字典：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = food[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f841bb27",
   "metadata": {},
   "source": [
    "\n",
    "现在，您可以将标签 ID 转换为标签名称：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069de2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label[str(79)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925a33a",
   "metadata": {},
   "source": [
    "\n",
    "## 预处理\n",
    "\n",
    "下一步是加载 ViT 图像处理器，将图像处理成张量：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2210f9",
   "metadata": {},
   "source": [
    "\n",
    "Pytorch\n",
    "\n",
    "对图像应用一些图像变换，使模型更能抵抗过拟合。这里您将使用 torchvision 的 `transforms` 模块，但您也可以使用您喜欢的任何图像库。\n",
    "\n",
    "裁剪图像的随机部分，调整其大小，并使用图像均值和标准差进行归一化：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90255a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dba3c",
   "metadata": {},
   "source": [
    "\n",
    "然后创建一个预处理函数，应用变换并返回图像的 `pixel_values` - 模型的输入：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f325a32",
   "metadata": {},
   "source": [
    "\n",
    "要使用 🤗 Datasets 的 [with_transform](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.with_transform) 方法在整个数据集上应用预处理函数。当您加载数据集的元素时，变换将动态应用：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "food = food.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3970018",
   "metadata": {},
   "source": [
    "\n",
    "现在，使用 [DefaultDataCollator](/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator) 创建一个示例批次。与 🤗 Transformers 中的其他数据整理器不同，`DefaultDataCollator` 不会应用额外的预处理，例如填充。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf0363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cbee0f",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow\n",
    "\n",
    "为了避免过拟合并使模型更强大，请在数据集的训练部分添加一些数据增强。这里我们使用 Keras 预处理层来定义训练数据的变换（包括数据增强），以及验证数据的变换（仅中心裁剪、调整大小和归一化）。您可以使用 `tf.image` 或您喜欢的任何其他库。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0858ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "train_data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomCrop(size[0], size[1]),\n",
    "        layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    ],\n",
    "    name=\"train_data_augmentation\",\n",
    ")\n",
    "val_data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.CenterCrop(size[0], size[1]),\n",
    "        layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
    "    ],\n",
    "    name=\"val_data_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742642f",
   "metadata": {},
   "source": [
    "\n",
    "接下来，创建函数以对一批图像而不是单个图像应用适当的变换。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "def convert_to_tf_tensor(image: Image):\n",
    "    np_image = np.array(image)\n",
    "    tf_image = tf.convert_to_tensor(np_image)\n",
    "    # `expand_dims()` 用于添加一个批次维度，因为\n",
    "    # TF 增强层对批处理输入进行操作。\n",
    "    return tf.expand_dims(tf_image, 0)\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    images = [\n",
    "        train_data_augmentation(convert_to_tf_tensor(image.convert(\"RGB\"))) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    example_batch[\"pixel_values\"] = [tf.transpose(tf.squeeze(image)) for image in images]\n",
    "    return example_batch\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    images = [\n",
    "        val_data_augmentation(convert_to_tf_tensor(image.convert(\"RGB\"))) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    example_batch[\"pixel_values\"] = [tf.transpose(tf.squeeze(image)) for image in images]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d11f0a",
   "metadata": {},
   "source": [
    "\n",
    "使用 🤗 Datasets 的 [set_transform](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.set_transform) 方法在加载时应用变换：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "food[\"train\"].set_transform(preprocess_train)\n",
    "food[\"test\"].set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5e218",
   "metadata": {},
   "source": [
    "\n",
    "作为预处理步骤的最后一步，使用 `DefaultDataCollator` 创建一个示例批次。与 🤗 Transformers 中的其他数据整理器不同，`DefaultDataCollator` 不会应用额外的预处理，例如填充。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a14b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a696e5",
   "metadata": {},
   "source": [
    "\n",
    "## 评估\n",
    "\n",
    "在训练过程中包含一个指标通常有助于评估您的模型性能。您可以使用 🤗 [Evaluate](https://huggingface.co/docs/evaluate/index) 库快速加载评估方法。对于此任务，加载 [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) 指标（请参阅 🤗 Evaluate 的 [快速入门](https://huggingface.co/docs/evaluate/a_quick_tour) 以了解更多关于如何加载和计算指标的信息）：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d2b23",
   "metadata": {},
   "source": [
    "\n",
    "然后创建一个函数，将您的预测和标签传递给 [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) 以计算准确率：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13e1e2",
   "metadata": {},
   "source": [
    "\n",
    "您的 `compute_metrics` 函数现在准备好了，当您设置训练时，您将返回到它。\n",
    "\n",
    "## 训练\n",
    "\n",
    "Pytorch\n",
    "\n",
    "如果您不熟悉使用 [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) 微调模型，请查看 [这里](../training#train-with-pytorch-trainer) 的基本教程！\n",
    "\n",
    "您现在可以开始训练您的模型了！使用 [AutoModelForImageClassification](/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForImageClassification) 加载 ViT。指定标签数量以及预期的标签数量和标签映射：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4670e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5387a59b",
   "metadata": {},
   "source": [
    "\n",
    "在这一点上，只剩下三个步骤：\n",
    "\n",
    "1. 在 [TrainingArguments](/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) 中定义您的训练超参数。重要的是您不要删除未使用的列，因为这会删除 `image` 列。如果没有 `image` 列，您就无法创建 `pixel_values`。设置 `remove_unused_columns=False` 以防止这种行为！唯一其他必需的参数是 `output_dir`，它指定保存模型的位置。您将通过设置 `push_to_hub=True` 将模型推送到 Hub（您需要登录 Hugging Face 才能上传模型）。在每个 epoch 结束时，[Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) 将评估准确率并保存训练检查点。\n",
    "2. 将训练参数传递给 [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)，以及模型、数据集、标记器、数据整理器和 `compute_metrics` 函数。\n",
    "3. 调用 [train()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) 以微调您的模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98055ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_food_model\",\n",
    "    remove_unused_columns=False,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=food[\"train\"],\n",
    "    eval_dataset=food[\"test\"],\n",
    "    processing_class=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853bc2fc",
   "metadata": {},
   "source": [
    "\n",
    "训练完成后，使用 [push_to_hub()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) 方法将您的模型分享到 Hub，以便每个人都可以使用您的模型：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945a5b7",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow\n",
    "\n",
    "如果您不熟悉使用 Keras 微调模型，请先查看 [基本教程](./training#train-a-tensorflow-model-with-keras)！\n",
    "\n",
    "要在 TensorFlow 中微调模型，请按照以下步骤操作：\n",
    "\n",
    "1. 定义训练超参数，并设置优化器和学习率计划。\n",
    "2. 实例化预训练模型。\n",
    "3. 将 🤗 Dataset 转换为 `tf.data.Dataset`。\n",
    "4. 编译您的模型。\n",
    "5. 添加回调并使用 `fit()` 方法运行训练。\n",
    "6. 将您的模型上传到 🤗 Hub 以与社区分享。\n",
    "\n",
    "首先定义超参数、优化器和学习率计划：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "num_train_steps = len(food[\"train\"]) * num_epochs\n",
    "learning_rate = 3e-5\n",
    "weight_decay_rate = 0.01\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae989d",
   "metadata": {},
   "source": [
    "\n",
    "然后，使用 [TFAutoModelForImageClassification](/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForImageClassification) 加载 ViT 以及标签映射：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForImageClassification\n",
    "model = TFAutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012db4d",
   "metadata": {},
   "source": [
    "\n",
    "使用 [to_tf_dataset](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.to_tf_dataset) 和您的 `data_collator` 将您的数据集转换为 `tf.data.Dataset` 格式：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33486c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将我们的训练数据集转换为 tf.data.Dataset\n",
    "tf_train_dataset = food[\"train\"].to_tf_dataset(\n",
    "    columns=\"pixel_values\", label_cols=\"label\", shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "# 将我们的测试数据集转换为 tf.data.Dataset\n",
    "tf_eval_dataset = food[\"test\"].to_tf_dataset(\n",
    "    columns=\"pixel_values\", label_cols=\"label\", shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c358de",
   "metadata": {},
   "source": [
    "\n",
    "使用 `compile()` 配置模型进行训练：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127741f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ac07a",
   "metadata": {},
   "source": [
    "\n",
    "要计算准确率并将模型推送到 🤗 Hub，请使用 [Keras 回调](../main_classes/keras_callbacks)。将您的 `compute_metrics` 函数传递给 [KerasMetricCallback](../main_classes/keras_callbacks#transformers.KerasMetricCallback)，并使用 [PushToHubCallback](../main_classes/keras_callbacks#transformers.PushToHubCallback) 上传模型：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback\n",
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_eval_dataset)\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"food_classifier\",\n",
    "    tokenizer=image_processor,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "callbacks = [metric_callback, push_to_hub_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa39fe7",
   "metadata": {},
   "source": [
    "\n",
    "最后，您现在可以训练您的模型了！调用 `fit()` 并传入您的训练和验证数据集、epoch 数量以及回调以微调模型：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=num_epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf1ec5",
   "metadata": {},
   "source": [
    "\n",
    "恭喜！您已经微调了您的模型并将其分享在 🤗 Hub 上。现在，您可以使用它进行推理了！\n",
    "\n",
    "有关如何为图像分类微调模型的更深入示例，请查看相应的 [PyTorch 笔记本](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)。\n",
    "\n",
    "## 推理\n",
    "\n",
    "太好了，现在您已经微调了一个模型，您可以使用它进行推理了！\n",
    "\n",
    "加载您想要运行推理的图像：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"food101\", split=\"validation[:10]\")\n",
    "image = ds[\"image\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1773b363",
   "metadata": {},
   "source": [
    "\n",
    "![image of beignets](./resources/images/beignets-task-guide.png)\n",
    "\n",
    "尝试使用微调模型进行推理的最简单方法是将其用于 `pipeline()`。为图像分类实例化一个 `pipeline` 并传入您的图像：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"image-classification\", model=\"my_awesome_food_model\")\n",
    "classifier(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4c135",
   "metadata": {},
   "source": [
    "\n",
    "如果您愿意，您也可以手动复制 `pipeline` 的结果：\n",
    "\n",
    "Pytorch\n",
    "\n",
    "加载图像处理器以预处理图像并返回 PyTorch 张量的 `input`：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eb6c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "import torch\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"my_awesome_food_model\")\n",
    "inputs = image_processor(image, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803355d",
   "metadata": {},
   "source": [
    "\n",
    "将您的输入传递给模型并返回 logits：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69edf6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "model = AutoModelForImageClassification.from_pretrained(\"my_awesome_food_model\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746870f",
   "metadata": {},
   "source": [
    "\n",
    "获取概率最高的预测标签，并使用模型的 `id2label` 映射将其转换为标签：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc680972",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = logits.argmax(-1).item()\n",
    "model.config.id2label[predicted_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3709356",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow\n",
    "\n",
    "加载图像处理器以预处理图像并返回 TensorFlow 张量的 `input`：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"MariaK/food_classifier\")\n",
    "inputs = image_processor(image, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc9fc0e",
   "metadata": {},
   "source": [
    "\n",
    "将您的输入传递给模型并返回 logits：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForImageClassification\n",
    "model = TFAutoModelForImageClassification.from_pretrained(\"MariaK/food_classifier\")\n",
    "logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea4beb",
   "metadata": {},
   "source": [
    "\n",
    "获取概率最高的预测标签，并使用模型的 `id2label` 映射将其转换为标签：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])\n",
    "model.config.id2label[predicted_class_id]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
