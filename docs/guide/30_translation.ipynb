{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8da483",
   "metadata": {},
   "source": [
    "# ç¿»è¯‘\n",
    "\n",
    "ç¿»è¯‘æ˜¯å°†ä¸€æ®µæ–‡æœ¬ä»ä¸€ç§è¯­è¨€è½¬æ¢ä¸ºå¦ä¸€ç§è¯­è¨€çš„è¿‡ç¨‹ã€‚å®ƒæ˜¯å¯ä»¥è¡¨è¿°ä¸ºåºåˆ—åˆ°åºåˆ—ï¼ˆsequence-to-sequenceï¼‰é—®é¢˜çš„å‡ ç§ä»»åŠ¡ä¹‹ä¸€ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶ï¼Œç”¨äºä»è¾“å…¥è¿”å›æŸäº›è¾“å‡ºï¼Œå¦‚ç¿»è¯‘æˆ–æ€»ç»“ã€‚ç¿»è¯‘ç³»ç»Ÿé€šå¸¸ç”¨äºä¸åŒè¯­è¨€æ–‡æœ¬ä¹‹é—´çš„ç¿»è¯‘ï¼Œä½†ä¹Ÿå¯ä»¥ç”¨äºè¯­éŸ³æˆ–ä¸¤è€…ä¹‹é—´çš„æŸç§ç»„åˆï¼Œå¦‚æ–‡æœ¬åˆ°è¯­éŸ³æˆ–è¯­éŸ³åˆ°æ–‡æœ¬ã€‚\n",
    "\n",
    "æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ï¼š\n",
    "\n",
    "1. åœ¨ [OPUS Books](https://huggingface.co/datasets/opus_books) æ•°æ®é›†çš„è‹±è¯­-æ³•è¯­å­é›†ä¸Šå¾®è°ƒ [T5](https://huggingface.co/google-t5/t5-small)ï¼Œä»¥å°†è‹±è¯­æ–‡æœ¬ç¿»è¯‘æˆæ³•è¯­ã€‚\n",
    "2. ä½¿ç”¨æ‚¨å¾®è°ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚\n",
    "\n",
    "è¦æŸ¥çœ‹ä¸è¯¥ä»»åŠ¡å…¼å®¹çš„æ‰€æœ‰æ¶æ„å’Œæ£€æŸ¥ç‚¹ï¼Œå»ºè®®æŸ¥çœ‹ [ä»»åŠ¡é¡µé¢](https://huggingface.co/tasks/translation)ã€‚\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c89852",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0b136",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬é¼“åŠ±æ‚¨ç™»å½•æ‚¨çš„ Hugging Face è´¦æˆ·ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥ä¸Šä¼ å¹¶ä¸ç¤¾åŒºåˆ†äº«æ‚¨çš„æ¨¡å‹ã€‚å½“æç¤ºæ—¶ï¼Œè¾“å…¥æ‚¨çš„ä»¤ç‰Œä»¥ç™»å½•ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d3519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e0c19",
   "metadata": {},
   "source": [
    "\n",
    "## åŠ è½½ OPUS Books æ•°æ®é›†\n",
    "\n",
    "é¦–å…ˆä» ğŸ¤— Datasets åº“ä¸­åŠ è½½ [OPUS Books](https://huggingface.co/datasets/opus_books) æ•°æ®é›†çš„è‹±è¯­-æ³•è¯­å­é›†ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77122bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "books = load_dataset(\"opus_books\", \"en-fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc36a0",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) æ–¹æ³•å°†æ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ecfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed860bf",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åæŸ¥çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a286b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29a8b0",
   "metadata": {},
   "source": [
    "\n",
    "`translation`ï¼šæ–‡æœ¬çš„è‹±è¯­å’Œæ³•è¯­ç¿»è¯‘ã€‚\n",
    "\n",
    "## é¢„å¤„ç†\n",
    "\n",
    "ä¸‹ä¸€æ­¥æ˜¯åŠ è½½ä¸€ä¸ª T5 åˆ†è¯å™¨æ¥å¤„ç†è‹±è¯­-æ³•è¯­è¯­è¨€å¯¹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f883dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6699aa22",
   "metadata": {},
   "source": [
    "\n",
    "æ‚¨è¦åˆ›å»ºçš„é¢„å¤„ç†å‡½æ•°éœ€è¦ï¼š\n",
    "\n",
    "1. åœ¨è¾“å…¥å‰æ·»åŠ æç¤ºï¼Œä»¥ä¾¿ T5 çŸ¥é“è¿™æ˜¯ç¿»è¯‘ä»»åŠ¡ã€‚ä¸€äº›èƒ½å¤Ÿæ‰§è¡Œå¤šç§ NLP ä»»åŠ¡çš„æ¨¡å‹éœ€è¦ç‰¹å®šä»»åŠ¡çš„æç¤ºã€‚\n",
    "2. åœ¨ `text_target` å‚æ•°ä¸­è®¾ç½®ç›®æ ‡è¯­è¨€ï¼ˆæ³•è¯­ï¼‰ï¼Œä»¥ç¡®ä¿åˆ†è¯å™¨æ­£ç¡®å¤„ç†ç›®æ ‡æ–‡æœ¬ã€‚å¦‚æœä¸è®¾ç½® `text_target`ï¼Œåˆ†è¯å™¨ä¼šå°†ç›®æ ‡æ–‡æœ¬ä½œä¸ºè‹±è¯­å¤„ç†ã€‚\n",
    "3. æˆªæ–­åºåˆ—ï¼Œä½¿å…¶ä¸è¶…è¿‡ `max_length` å‚æ•°è®¾ç½®çš„æœ€å¤§é•¿åº¦ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdfcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = \"en\"\n",
    "target_lang = \"fr\"\n",
    "prefix = \"translate English to French: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
    "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55b776",
   "metadata": {},
   "source": [
    "\n",
    "è¦åº”ç”¨é¢„å¤„ç†å‡½æ•°åˆ°æ•´ä¸ªæ•°æ®é›†ï¼Œä½¿ç”¨ ğŸ¤— Datasets çš„ [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) æ–¹æ³•ã€‚æ‚¨å¯ä»¥é€šè¿‡è®¾ç½® `batched=True` æ¥åŠ é€Ÿ `map` å‡½æ•°ï¼Œä»¥ä¾¿ä¸€æ¬¡å¤„ç†æ•°æ®é›†çš„å¤šä¸ªå…ƒç´ ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de0eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_books = books.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d827c8",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨ä½¿ç”¨ [DataCollatorForSeq2Seq](/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorForSeq2Seq) åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ‰¹æ¬¡ã€‚åœ¨æ•´ç†è¿‡ç¨‹ä¸­ï¼Œ_åŠ¨æ€å¡«å……_ å¥å­åˆ°æ‰¹æ¬¡ä¸­æœ€é•¿çš„é•¿åº¦æ›´é«˜æ•ˆï¼Œè€Œä¸æ˜¯å°†æ•´ä¸ªæ•°æ®é›†å¡«å……åˆ°æœ€å¤§é•¿åº¦ã€‚\n",
    "\n",
    "### Pytorch\n",
    "\n",
    "éšè— Pytorch å†…å®¹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd7781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa7d005",
   "metadata": {},
   "source": [
    "\n",
    "### TensorFlow\n",
    "\n",
    "éšè— TensorFlow å†…å®¹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f6e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400500c6",
   "metadata": {},
   "source": [
    "\n",
    "## è¯„ä¼°\n",
    "\n",
    "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒ…å«ä¸€ä¸ªæŒ‡æ ‡é€šå¸¸æœ‰åŠ©äºè¯„ä¼°æ¨¡å‹çš„è¡¨ç°ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) åº“å¿«é€ŸåŠ è½½è¯„ä¼°æ–¹æ³•ã€‚å¯¹äºæ­¤ä»»åŠ¡ï¼ŒåŠ è½½ [SacreBLEU](https://huggingface.co/spaces/evaluate-metric/sacrebleu) æŒ‡æ ‡ï¼ˆå‚è§ ğŸ¤— Evaluate [å¿«é€Ÿæ•™ç¨‹](https://huggingface.co/docs/evaluate/a_quick_tour) ä»¥äº†è§£æ›´å¤šå…³äºå¦‚ä½•åŠ è½½å’Œè®¡ç®—æŒ‡æ ‡çš„ä¿¡æ¯ï¼‰ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c38799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18012c42",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶ååˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå°†æ‚¨çš„é¢„æµ‹å’Œæ ‡ç­¾ä¼ é€’ç»™ [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) ä»¥è®¡ç®— SacreBLEU åˆ†æ•°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05286767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f0425",
   "metadata": {},
   "source": [
    "\n",
    "æ‚¨çš„ `compute_metrics` å‡½æ•°ç°åœ¨å‡†å¤‡å¥½äº†ï¼Œæ‚¨å°†åœ¨è®¾ç½®è®­ç»ƒæ—¶è¿”å›åˆ°å®ƒã€‚\n",
    "\n",
    "## è®­ç»ƒ\n",
    "\n",
    "### Pytorch\n",
    "\n",
    "éšè— Pytorch å†…å®¹\n",
    "\n",
    "å¦‚æœæ‚¨ä¸ç†Ÿæ‚‰ä½¿ç”¨ [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹è¿™é‡Œçš„ basic tutorial [here](../training#train-with-pytorch-trainer)ï¼\n",
    "\n",
    "æ‚¨ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒæ‚¨çš„æ¨¡å‹äº†ï¼åŠ è½½ T5 ä¸ [AutoModelForSeq2SeqLM](/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSeq2SeqLM)ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae78a58",
   "metadata": {},
   "source": [
    "\n",
    "æ­¤æ—¶ï¼Œåªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "1. åœ¨ [Seq2SeqTrainingArguments](/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments) ä¸­å®šä¹‰æ‚¨çš„è®­ç»ƒè¶…å‚æ•°ã€‚å”¯ä¸€å¿…éœ€çš„å‚æ•°æ˜¯ `output_dir`ï¼Œå®ƒæŒ‡å®šäº†ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚æ‚¨å¯ä»¥é€šè¿‡è®¾ç½® `push_to_hub=True` å°†æ¨¡å‹æ¨é€åˆ° Hubï¼ˆæ‚¨éœ€è¦ç™»å½• Hugging Face æ‰èƒ½ä¸Šä¼ æ‚¨çš„æ¨¡å‹ï¼‰ã€‚åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ï¼Œ[Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) å°†è¯„ä¼° SacreBLEU æŒ‡æ ‡å¹¶ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚\n",
    "2. å°†è®­ç»ƒå‚æ•°ä¼ é€’ç»™ [Seq2SeqTrainer](/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainer)ï¼ŒåŒæ—¶ä¼ é€’æ¨¡å‹ã€æ•°æ®é›†ã€åˆ†è¯å™¨ã€æ•°æ®æ•´ç†å™¨å’Œ `compute_metrics` å‡½æ•°ã€‚\n",
    "3. è°ƒç”¨ [train()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) ä»¥å¾®è°ƒæ‚¨çš„æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d931741",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_opus_books_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,  # change to bf16=True for XPU\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_books[\"train\"],\n",
    "    eval_dataset=tokenized_books[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3a07d",
   "metadata": {},
   "source": [
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ [push_to_hub()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) æ–¹æ³•å°†æ‚¨çš„æ¨¡å‹åˆ†äº«åˆ° Hubï¼Œä»¥ä¾¿æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨æ‚¨çš„æ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de487f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f3586",
   "metadata": {},
   "source": [
    "\n",
    "### TensorFlow\n",
    "\n",
    "éšè— TensorFlow å†…å®¹\n",
    "\n",
    "å¦‚æœæ‚¨ä¸ç†Ÿæ‚‰ä½¿ç”¨ Keras å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹è¿™é‡Œçš„ basic tutorial [here](../training#train-a-tensorflow-model-with-keras)ï¼\n",
    "\n",
    "è¦åœ¨ TensorFlow ä¸­å¾®è°ƒæ¨¡å‹ï¼Œé¦–å…ˆè®¾ç½®ä¸€ä¸ªä¼˜åŒ–å™¨å‡½æ•°ã€å­¦ä¹ ç‡è°ƒåº¦å’Œä¸€äº›è®­ç»ƒè¶…å‚æ•°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003941da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamWeightDecay\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c2bfe",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åæ‚¨å¯ä»¥åŠ è½½ T5 ä¸ [TFAutoModelForSeq2SeqLM](/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForSeq2SeqLM)ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4f34e",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [prepare_tf_dataset()](/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) å°†æ‚¨çš„æ•°æ®é›†è½¬æ¢ä¸º `tf.data.Dataset` æ ¼å¼ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_books[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = model.prepare_tf_dataset(\n",
    "    tokenized_books[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2204ed",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [`compile`](https://keras.io/api/models/model_training_apis/#compile-method) é…ç½®æ¨¡å‹ä»¥è¿›è¡Œè®­ç»ƒã€‚è¯·æ³¨æ„ï¼ŒTransformers æ¨¡å‹éƒ½æœ‰ä¸€ä¸ªé»˜è®¤çš„ä»»åŠ¡ç›¸å…³æŸå¤±å‡½æ•°ï¼Œæ‰€ä»¥æ‚¨ä¸éœ€è¦æŒ‡å®šä¸€ä¸ªï¼Œé™¤éæ‚¨æƒ³è¿™æ ·åšï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(optimizer=optimizer)  # No loss argument!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d97657",
   "metadata": {},
   "source": [
    "\n",
    "åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰ï¼Œæœ€åä¸¤ä»¶äº‹æ˜¯è®¡ç®— SacreBLEU æŒ‡æ ‡å’Œæä¾›ä¸€ç§å°†æ‚¨çš„æ¨¡å‹æ¨é€åˆ° Hub çš„æ–¹æ³•ã€‚è¿™ä¸¤è€…éƒ½é€šè¿‡ä½¿ç”¨ [Keras callbacks](../main_classes/keras_callbacks) å®Œæˆã€‚\n",
    "\n",
    "å°†æ‚¨çš„ `compute_metrics` å‡½æ•°ä¼ é€’ç»™ [KerasMetricCallback](/docs/transformers/main/en/main_classes/keras_callbacks#transformers.KerasMetricCallback)ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb32d86",
   "metadata": {},
   "source": [
    "\n",
    "åœ¨ [PushToHubCallback](/docs/transformers/main/en/main_classes/keras_callbacks#transformers.PushToHubCallback) ä¸­æŒ‡å®šè¦æ¨é€æ¨¡å‹å’Œåˆ†è¯å™¨çš„ä½ç½®ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b612f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"my_awesome_opus_books_model\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50d1c2",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åå°†æ‚¨çš„å›è°ƒæ†ç»‘åœ¨ä¸€èµ·ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [metric_callback, push_to_hub_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2dca1",
   "metadata": {},
   "source": [
    "\n",
    "æœ€åï¼Œæ‚¨å·²ç»å‡†å¤‡å¥½å¼€å§‹è®­ç»ƒæ‚¨çš„æ¨¡å‹äº†ï¼è°ƒç”¨ [`fit`](https://keras.io/api/models/model_training_apis/#fit-method) å¹¶ä¼ å…¥æ‚¨çš„è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ã€epoch æ•°é‡å’Œå›è°ƒä»¥å¾®è°ƒæ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd487ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4c39f8",
   "metadata": {},
   "source": [
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œæ‚¨çš„æ¨¡å‹å°†è‡ªåŠ¨ä¸Šä¼ åˆ° Hubï¼Œä»¥ä¾¿æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨å®ƒï¼\n",
    "\n",
    "è¦æ·±å…¥äº†è§£å¦‚ä½•å¾®è°ƒç¿»è¯‘æ¨¡å‹ï¼Œè¯·æŸ¥çœ‹ç›¸åº”çš„ [PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb) æˆ– [TensorFlow notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)ã€‚\n",
    "\n",
    "## æ¨ç†\n",
    "\n",
    "å¤ªå¥½äº†ï¼Œç°åœ¨æ‚¨å·²ç»å¾®è°ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†äº†ï¼\n",
    "\n",
    "æƒ³å‡ºä¸€äº›æ‚¨æƒ³è¦ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€çš„æ–‡æœ¬ã€‚å¯¹äº T5ï¼Œæ‚¨éœ€è¦æ ¹æ®æ‚¨æ­£åœ¨å¤„ç†çš„ä»»åŠ¡åœ¨è¾“å…¥å‰æ·»åŠ å‰ç¼€ã€‚å¯¹äºä»è‹±è¯­åˆ°æ³•è¯­çš„ç¿»è¯‘ï¼Œæ‚¨åº”è¯¥åƒä¸‹é¢è¿™æ ·æ·»åŠ å‰ç¼€ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfeb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"translate English to French: Legumes share resources with nitrogen-fixing bacteria.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a3d12",
   "metadata": {},
   "source": [
    "\n",
    "å°è¯•æ‚¨å¾®è°ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨ [pipeline()](/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline)ã€‚ä½¿ç”¨æ‚¨çš„æ¨¡å‹å®ä¾‹åŒ–ä¸€ä¸ª `pipeline` ç”¨äºç¿»è¯‘ï¼Œå¹¶å°†æ‚¨çš„æ–‡æœ¬ä¼ é€’ç»™å®ƒï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30acd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation_en_to_fr\", model=\"username/my_awesome_opus_books_model\")\n",
    "translator(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4331b",
   "metadata": {},
   "source": [
    "\n",
    "æ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨å¤åˆ¶ `pipeline` çš„ç»“æœï¼Œå¦‚æœæ‚¨æ„¿æ„çš„è¯ï¼š\n",
    "\n",
    "### Pytorch\n",
    "\n",
    "éšè— Pytorch å†…å®¹\n",
    "\n",
    "å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯å¹¶è¿”å› `input_ids` ä½œä¸º PyTorch å¼ é‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d3e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"username/my_awesome_opus_books_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96820f6d",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [generate()](/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationMixin.generate) æ–¹æ³•åˆ›å»ºç¿»è¯‘ã€‚æœ‰å…³ä¸åŒæ–‡æœ¬ç”Ÿæˆç­–ç•¥å’Œç”Ÿæˆæ§åˆ¶çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ [Text Generation](../main_classes/text_generation) APIã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9775061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"username/my_awesome_opus_books_model\")\n",
    "outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86223a4f",
   "metadata": {},
   "source": [
    "\n",
    "å°†ç”Ÿæˆçš„ token ids è§£ç å›æ–‡æœ¬ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b313dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdfb3e",
   "metadata": {},
   "source": [
    "\n",
    "### TensorFlow\n",
    "\n",
    "éšè— TensorFlow å†…å®¹\n",
    "\n",
    "å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯å¹¶è¿”å› `input_ids` ä½œä¸º TensorFlow å¼ é‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"username/my_awesome_opus_books_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"tf\").input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd56cc8",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ `~transformers.generation_tf_utils.TFGenerationMixin.generate` æ–¹æ³•åˆ›å»ºç¿»è¯‘ã€‚æœ‰å…³ä¸åŒæ–‡æœ¬ç”Ÿæˆç­–ç•¥å’Œç”Ÿæˆæ§åˆ¶çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ [Text Generation](../main_classes/text_generation) APIã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3158316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"username/my_awesome_opus_books_model\")\n",
    "outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba87cab9",
   "metadata": {},
   "source": [
    "\n",
    "å°†ç”Ÿæˆçš„ token ids è§£ç å›æ–‡æœ¬ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
