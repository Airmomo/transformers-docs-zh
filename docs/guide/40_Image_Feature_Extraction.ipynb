{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc3f13f",
   "metadata": {},
   "source": [
    "# 图像特征提取\n",
    "\n",
    "图像特征提取是从给定的图像中提取语义上有意义的特征的任务。这一任务有许多应用场景，包括图像相似性和图像检索。此外，大多数计算机视觉模型都可以用于图像特征提取，其中可以通过移除任务特定的头部（如图像分类、目标检测等）来获取特征。这些特征在高层次上非常有用，例如边缘检测、角点检测等。根据模型的深度，这些特征也可能包含有关现实世界的信息（例如猫的样子）。因此，这些输出可以用于训练特定数据集上的新分类器。\n",
    "\n",
    "在这个指南中，你将：\n",
    "\n",
    "- 学习如何基于 `image-feature-extraction` 管道构建一个简单的图像相似性系统。\n",
    "- 通过裸模型推理实现相同的任务。\n",
    "\n",
    "## 使用 `image-feature-extraction` 管道实现图像相似性\n",
    "\n",
    "我们有两张猫坐在渔网上的图片，其中一张是生成的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "img_urls = [\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cats.png\", \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cats.jpeg\"]\n",
    "image_real = Image.open(requests.get(img_urls[0], stream=True).raw).convert(\"RGB\")\n",
    "image_gen = Image.open(requests.get(img_urls[1], stream=True).raw).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece19213",
   "metadata": {},
   "source": [
    "\n",
    "让我们看看管道的实际应用。首先，初始化管道。如果你不传递任何模型，管道将自动初始化为 `google/vit-base-patch16-224`。如果你想计算相似度，可以将 `pool` 参数设置为 `True`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pipe = pipeline(task=\"image-feature-extraction\", model_name=\"google/vit-base-patch16-384\", device=DEVICE, pool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535771d1",
   "metadata": {},
   "source": [
    "\n",
    "要使用 `pipe` 进行推理，可以将两张图片传递给它。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95777b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pipe([image_real, image_gen])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873263f",
   "metadata": {},
   "source": [
    "\n",
    "输出包含这两张图片的池化嵌入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取单个输出的长度\n",
    "print(len(outputs[0][0]))\n",
    "# 显示输出\n",
    "print(outputs)\n",
    "\n",
    "# 768\n",
    "# [[-0.03909236937761307, 0.43381670117378235, -0.06913255900144577,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f429a",
   "metadata": {},
   "source": [
    "\n",
    "为了获得相似度分数，我们需要将它们传递给相似度函数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "similarity_score = cosine_similarity(torch.Tensor(outputs[0]),\n",
    "                                     torch.Tensor(outputs[1]), dim=1)\n",
    "\n",
    "print(similarity_score)\n",
    "\n",
    "# tensor([0.6043])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0501e",
   "metadata": {},
   "source": [
    "\n",
    "如果你希望获取池化之前的最后一个隐藏状态，可以避免传递 `pool` 参数，因为默认值为 `False`。这些隐藏状态对于基于模型特征训练新的分类器或模型非常有用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4332b90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task=\"image-feature-extraction\", model_name=\"google/vit-base-patch16-224\", device=DEVICE)\n",
    "output = pipe(image_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8dcc9",
   "metadata": {},
   "source": [
    "\n",
    "由于输出未池化，我们得到的是最后一个隐藏状态，其中第一个维度是批量大小，最后两个维度是嵌入形状。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.array(output).shape)\n",
    "# (1, 197, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065d3b1",
   "metadata": {},
   "source": [
    "\n",
    "## 使用 `AutoModel` 获取特征和相似性\n",
    "\n",
    "我们还可以使用 `transformers` 的 `AutoModel` 类来获取特征。`AutoModel` 加载任何没有任务特定头部的变换器模型，我们可以使用它来获取特征。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "model = AutoModel.from_pretrained(\"google/vit-base-patch16-224\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34e419",
   "metadata": {},
   "source": [
    "\n",
    "让我们编写一个简单的推理函数。我们将首先将输入传递给 `processor`，然后将其输出传递给 `model`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ae47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(image):\n",
    "  inputs = processor(image, return_tensors=\"pt\").to(DEVICE)\n",
    "  outputs = model(**inputs)\n",
    "  return outputs.pooler_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70279b32",
   "metadata": {},
   "source": [
    "\n",
    "我们可以直接将图片传递给这个函数并获取嵌入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989cdda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_real = infer(image_real)\n",
    "embed_gen = infer(image_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c2007",
   "metadata": {},
   "source": [
    "\n",
    "再次计算嵌入的相似度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbd7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "similarity_score = cosine_similarity(embed_real, embed_gen, dim=1)\n",
    "print(similarity_score)\n",
    "\n",
    "# tensor([0.6061], device='cuda:0', grad_fn=<SumBackward1>)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
