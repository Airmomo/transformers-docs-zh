{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4743f806",
   "metadata": {},
   "source": [
    "# é®è”½è¯­è¨€æ¨¡å‹\n",
    "\n",
    "é®è”½è¯­è¨€æ¨¡å‹é¢„æµ‹åºåˆ—ä¸­çš„é®è”½æ ‡è®°ï¼Œå¹¶ä¸”æ¨¡å‹å¯ä»¥åŒå‘å…³æ³¨æ ‡è®°ã€‚è¿™æ„å‘³ç€æ¨¡å‹å¯ä»¥å®Œå…¨è®¿é—®å·¦å³ä¸¤è¾¹çš„æ ‡è®°ã€‚é®è”½è¯­è¨€æ¨¡å‹éå¸¸é€‚åˆéœ€è¦å¯¹æ•´ä¸ªåºåˆ—æœ‰è‰¯å¥½ä¸Šä¸‹æ–‡ç†è§£çš„ä»»åŠ¡ã€‚BERT å°±æ˜¯ä¸€ä¸ªé®è”½è¯­è¨€æ¨¡å‹çš„ä¾‹å­ã€‚\n",
    "\n",
    "æœ¬æŒ‡å—å°†å‘ä½ å±•ç¤ºå¦‚ä½•ï¼š\n",
    "\n",
    "1. åœ¨ [ELI5](https://huggingface.co/datasets/eli5) æ•°æ®é›†çš„ [r/askscience](https://www.reddit.com/r/askscience/) å­é›†ä¸Šå¾®è°ƒ [DistilRoBERTa](https://huggingface.co/distilbert/distilroberta-base)ã€‚\n",
    "2. ä½¿ç”¨ä½ çš„å¾®è°ƒæ¨¡å‹è¿›è¡Œæ¨ç†ã€‚\n",
    "\n",
    "è¦æŸ¥çœ‹ä¸æ­¤ä»»åŠ¡å…¼å®¹çš„æ‰€æœ‰æ¶æ„å’Œæ£€æŸ¥ç‚¹ï¼Œæˆ‘ä»¬æ¨èæŸ¥çœ‹[ä»»åŠ¡é¡µé¢](https://huggingface.co/tasks/fill-mask)ã€‚\n",
    "\n",
    "å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b703c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326670c",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬é¼“åŠ±ä½ ç™»å½•ä½ çš„ Hugging Face è´¦æˆ·ï¼Œè¿™æ ·ä½ å°±å¯ä»¥ä¸Šä¼ å¹¶ä¸ç¤¾åŒºåˆ†äº«ä½ çš„æ¨¡å‹ã€‚å½“æç¤ºæ—¶ï¼Œè¾“å…¥ä½ çš„ token ä»¥ç™»å½•ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769eefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aed161",
   "metadata": {},
   "source": [
    "\n",
    "## åŠ è½½ ELI5 æ•°æ®é›†\n",
    "\n",
    "é¦–å…ˆä½¿ç”¨ ğŸ¤— Datasets åº“åŠ è½½ [ELI5-Category](https://huggingface.co/datasets/eli5_category) æ•°æ®é›†çš„å‰ 5000 ä¸ªç¤ºä¾‹ã€‚è¿™å°†ç»™ä½ ä¸€ä¸ªæœºä¼šè¿›è¡Œå®éªŒå¹¶ç¡®ä¿ä¸€åˆ‡å·¥ä½œæ­£å¸¸ï¼Œç„¶åå†èŠ±æ›´å¤šæ—¶é—´åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè®­ç»ƒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1fbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "eli5 = load_dataset(\"eli5_category\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea1d44",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) æ–¹æ³•å°†æ•°æ®é›†çš„ `train` åˆ†å‰²æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfedcb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = eli5.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1945c957",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åæŸ¥çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea0a70",
   "metadata": {},
   "source": [
    "\n",
    "è™½ç„¶è¿™çœ‹èµ·æ¥å¾ˆå¤šï¼Œä½†ä½ çœŸæ­£æ„Ÿå…´è¶£çš„æ˜¯ `text` å­—æ®µã€‚è¯­è¨€å»ºæ¨¡ä»»åŠ¡çš„é…·ä¹‹å¤„åœ¨äºä½ ä¸éœ€è¦æ ‡ç­¾ï¼ˆä¹Ÿç§°ä¸ºæ— ç›‘ç£ä»»åŠ¡ï¼‰ï¼Œå› ä¸ºä¸‹ä¸€ä¸ªè¯å°±æ˜¯æ ‡ç­¾ã€‚\n",
    "\n",
    "## é¢„å¤„ç†\n",
    "\n",
    "å¯¹äºé®è”½è¯­è¨€å»ºæ¨¡ï¼Œä¸‹ä¸€æ­¥æ˜¯åŠ è½½ä¸€ä¸ª DistilRoBERTa åˆ†è¯å™¨æ¥å¤„ç† `text` å­å­—æ®µï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilroberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5d020",
   "metadata": {},
   "source": [
    "\n",
    "ä½ ä¼šä»ä¸Šé¢çš„ç¤ºä¾‹ä¸­æ³¨æ„åˆ°ï¼Œ`text` å­—æ®µå®é™…ä¸ŠåµŒå¥—åœ¨ `answers` é‡Œé¢ã€‚è¿™æ„å‘³ç€ä½ éœ€è¦ä½¿ç”¨ [`flatten`](https://huggingface.co/docs/datasets/process#flatten) æ–¹æ³•ä»å…¶åµŒå¥—ç»“æ„ä¸­æå– `text` å­å­—æ®µï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = eli5.flatten()\n",
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a54aa",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨æ¯ä¸ªå­å­—æ®µéƒ½æ˜¯ä¸€ä¸ªå•ç‹¬çš„åˆ—ï¼Œå¦‚ `answers` å‰ç¼€æ‰€ç¤ºï¼Œ`text` å­—æ®µç°åœ¨æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚ä¸è¦å•ç‹¬å¯¹æ¯ä¸ªå¥å­è¿›è¡Œåˆ†è¯ï¼Œå°†åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œä»¥ä¾¿ä½ å¯ä»¥ä¸€èµ·å¯¹å®ƒä»¬è¿›è¡Œåˆ†è¯ã€‚\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªé¢„å¤„ç†å‡½æ•°ï¼Œç”¨äºå°†æ¯ä¸ªç¤ºä¾‹çš„å­—ç¬¦ä¸²åˆ—è¡¨è¿æ¥èµ·æ¥å¹¶åˆ†è¯ç»“æœï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer([\" \".join(x) for x in examples[\"answers.text\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a6ade",
   "metadata": {},
   "source": [
    "\n",
    "è¦åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨è¿™ä¸ªé¢„å¤„ç†å‡½æ•°ï¼Œä½¿ç”¨ ğŸ¤— Datasets çš„ [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) æ–¹æ³•ã€‚ä½ å¯ä»¥é€šè¿‡è®¾ç½® `batched=True` æ¥åŠ é€Ÿ `map` å‡½æ•°ï¼Œä»¥ä¾¿ä¸€æ¬¡å¤„ç†æ•°æ®é›†ä¸­çš„å¤šä¸ªå…ƒç´ ï¼Œå¹¶ä½¿ç”¨ `num_proc` å¢åŠ è¿›ç¨‹æ•°ã€‚åˆ é™¤ä½ ä¸éœ€è¦çš„ä»»ä½•åˆ—ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eli5 = eli5.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=eli5[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf14407",
   "metadata": {},
   "source": [
    "\n",
    "è¿™ä¸ªæ•°æ®é›†åŒ…å«äº†æ ‡è®°åºåˆ—ï¼Œä½†å…¶ä¸­ä¸€äº›åºåˆ—æ¯”æ¨¡å‹çš„æœ€å¤§è¾“å…¥é•¿åº¦è¿˜è¦é•¿ã€‚\n",
    "\n",
    "ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨ç¬¬äºŒä¸ªé¢„å¤„ç†å‡½æ•°æ¥ï¼š\n",
    "\n",
    "- è¿æ¥æ‰€æœ‰çš„åºåˆ—\n",
    "- å°†è¿æ¥çš„åºåˆ—åˆ†å‰²æˆç”± `block_size` å®šä¹‰çš„æ›´çŸ­çš„å—ï¼Œå®ƒåº”è¯¥æ¯”æ¨¡å‹çš„æœ€å¤§è¾“å…¥é•¿åº¦çŸ­ï¼Œå¹¶ä¸”è¶³å¤ŸçŸ­ä»¥é€‚åº”ä½ çš„ GPU å†…å­˜ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed267fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "\n",
    "def group_texts(examples):\n",
    "    # è¿æ¥æ‰€æœ‰æ–‡æœ¬ã€‚\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # æˆ‘ä»¬å¯ä»¥æ·»åŠ å¡«å……è€Œä¸æ˜¯è¿™ç§ä¸¢å¼ƒï¼Œå¦‚æœæ¨¡å‹æ”¯æŒçš„è¯ï¼Œä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€è¦å®šåˆ¶è¿™éƒ¨åˆ†ã€‚\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # æŒ‰ block_size åˆ†å‰²å—ã€‚\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100af4ed",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨ä½¿ç”¨ [DataCollatorForLanguageModeling](/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling) åˆ›å»ºä¸€æ‰¹ç¤ºä¾‹ã€‚åœ¨æ•´ç†è¿‡ç¨‹ä¸­åŠ¨æ€å¡«å……å¥å­åˆ°æ‰¹æ¬¡ä¸­çš„æœ€é•¿é•¿åº¦ï¼Œè€Œä¸æ˜¯å°†æ•´ä¸ªæ•°æ®é›†å¡«å……åˆ°æœ€å¤§é•¿åº¦ï¼Œè¿™æ ·åšæ›´æœ‰æ•ˆã€‚\n",
    "\n",
    "Pytorch\n",
    "\n",
    "éšè— Pytorch å†…å®¹\n",
    "\n",
    "ä½¿ç”¨åºåˆ—ç»“æŸæ ‡è®°ä½œä¸ºå¡«å……æ ‡è®°ï¼Œå¹¶æŒ‡å®š `mlm_probability` ä»¥åœ¨æ¯æ¬¡éå†æ•°æ®æ—¶éšæœºé®è”½æ ‡è®°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f4399",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow\n",
    "\n",
    "éšè— TensorFlow å†…å®¹\n",
    "\n",
    "ä½¿ç”¨åºåˆ—ç»“æŸæ ‡è®°ä½œä¸ºå¡«å……æ ‡è®°ï¼Œå¹¶æŒ‡å®š `mlm_probability` ä»¥åœ¨æ¯æ¬¡éå†æ•°æ®æ—¶éšæœºé®è”½æ ‡è®°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaefbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b61c0a",
   "metadata": {},
   "source": [
    "\n",
    "## è®­ç»ƒ\n",
    "\n",
    "Pytorch\n",
    "\n",
    "éšè— Pytorch å†…å®¹\n",
    "\n",
    "å¦‚æœä½ ä¸ç†Ÿæ‚‰å¦‚ä½•ä½¿ç”¨ [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[è¿™é‡Œ](../training#train-with-pytorch-trainer)çš„åŸºæœ¬æ•™ç¨‹ï¼\n",
    "\n",
    "ç°åœ¨ä½ å¯ä»¥å¼€å§‹è®­ç»ƒä½ çš„æ¨¡å‹äº†ï¼ä½¿ç”¨ [AutoModelForMaskedLM](/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForMaskedLM) åŠ è½½ DistilRoBERTaï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60888834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"distilbert/distilroberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad7f35",
   "metadata": {},
   "source": [
    "\n",
    "æ­¤æ—¶ï¼Œåªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "1. åœ¨ [TrainingArguments](/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) ä¸­å®šä¹‰ä½ çš„è®­ç»ƒè¶…å‚æ•°ã€‚å”¯ä¸€å¿…éœ€çš„å‚æ•°æ˜¯ `output_dir`ï¼Œå®ƒæŒ‡å®šäº†ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚ä½ å¯ä»¥é€šè¿‡è®¾ç½® `push_to_hub=True`ï¼ˆéœ€è¦ç™»å½• Hugging Face æ‰èƒ½ä¸Šä¼ ä½ çš„æ¨¡å‹ï¼‰å°†æ­¤æ¨¡å‹æ¨é€åˆ° Hubã€‚\n",
    "2. å°†è®­ç»ƒå‚æ•°ä¼ é€’ç»™ [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) ä»¥åŠæ¨¡å‹ã€æ•°æ®é›†å’Œæ•°æ®æ•´ç†å™¨ã€‚\n",
    "3. è°ƒç”¨ [train()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) å¾®è°ƒä½ çš„æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_eli5_mlm_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ba992",
   "metadata": {},
   "source": [
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ [evaluate()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.evaluate) æ–¹æ³•è¯„ä¼°ä½ çš„æ¨¡å‹å¹¶è·å–å®ƒçš„å›°æƒ‘åº¦ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f831d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4145d85",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åä½¿ç”¨ [push_to_hub()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) æ–¹æ³•å°†ä½ çš„æ¨¡å‹åˆ†äº«åˆ° Hubï¼Œè¿™æ ·æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨ä½ çš„æ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abdb958",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f64ce",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow\n",
    "\n",
    "éšè— TensorFlow å†…å®¹\n",
    "\n",
    "å¦‚æœä½ ä¸ç†Ÿæ‚‰å¦‚ä½•ä½¿ç”¨ Keras å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[è¿™é‡Œ](../training#train-a-tensorflow-model-with-keras)çš„åŸºæœ¬æ•™ç¨‹ï¼\n",
    "\n",
    "è¦å¾®è°ƒ TensorFlow ä¸­çš„æ¨¡å‹ï¼Œé¦–å…ˆè®¾ç½®ä¸€ä¸ªä¼˜åŒ–å™¨å‡½æ•°ã€å­¦ä¹ ç‡è®¡åˆ’å’Œä¸€äº›è®­ç»ƒè¶…å‚æ•°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aaa6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer, AdamWeightDecay\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65083760",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åä½ å¯ä»¥ä½¿ç”¨ [TFAutoModelForMaskedLM](/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForMaskedLM) åŠ è½½ DistilRoBERTaï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForMaskedLM\n",
    "\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(\"distilbert/distilroberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486dcda",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [prepare_tf_dataset()](/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) å°†ä½ çš„æ•°æ®é›†è½¬æ¢ä¸º `tf.data.Dataset` æ ¼å¼ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    lm_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = model.prepare_tf_dataset(\n",
    "    lm_dataset[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1582304",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [`compile`](https://keras.io/api/models/model_training_apis/#compile-method) é…ç½®æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚æ³¨æ„ï¼ŒTransformer æ¨¡å‹éƒ½æœ‰ä¸€ä¸ªé»˜è®¤çš„ä»»åŠ¡ç›¸å…³æŸå¤±å‡½æ•°ï¼Œæ‰€ä»¥ä½ ä¸éœ€è¦æŒ‡å®šä¸€ä¸ªï¼Œé™¤éä½ æƒ³ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eadf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(optimizer=optimizer)  # No loss argument!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bab0ae",
   "metadata": {},
   "source": [
    "\n",
    "è¿™å¯ä»¥é€šè¿‡æŒ‡å®šåœ¨å“ªé‡Œæ¨é€ä½ çš„æ¨¡å‹å’Œåˆ†è¯å™¨æ¥å®Œæˆ [PushToHubCallback](/docs/transformers/main/en/main_classes/keras_callbacks#transformers.PushToHubCallback)ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ead6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "callback = PushToHubCallback(\n",
    "    output_dir=\"my_awesome_eli5_mlm_model\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd371a6c",
   "metadata": {},
   "source": [
    "\n",
    "æœ€åï¼Œä½ å‡†å¤‡å¥½å¼€å§‹è®­ç»ƒä½ çš„æ¨¡å‹äº†ï¼ç”¨ä½ çš„è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ã€è®­ç»ƒå‘¨æœŸæ•°å’Œä½ çš„å›è°ƒæ¥è°ƒç”¨ [`fit`](https://keras.io/api/models/model_training_apis/#fit-method) å¾®è°ƒæ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e083ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551fb0b",
   "metadata": {},
   "source": [
    "\n",
    "ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œä½ çš„æ¨¡å‹ä¼šè‡ªåŠ¨ä¸Šä¼ åˆ° Hubï¼Œè¿™æ ·æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨å®ƒï¼\n",
    "\n",
    "æœ‰å…³å¦‚ä½•å¾®è°ƒé®è”½è¯­è¨€æ¨¡å‹çš„æ›´æ·±å…¥ç¤ºä¾‹ï¼Œè¯·æŸ¥çœ‹ç›¸åº”çš„ [PyTorch ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb) æˆ– [TensorFlow ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)ã€‚\n",
    "\n",
    "## æ¨ç†\n",
    "\n",
    "å¤ªå¥½äº†ï¼Œç°åœ¨ä½ å·²ç»å¾®è°ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œä½ å¯ä»¥ç”¨å®ƒè¿›è¡Œæ¨ç†äº†ï¼\n",
    "\n",
    "æƒ³å‡ºä¸€äº›ä½ æƒ³è®©æ¨¡å‹å¡«è¡¥ç©ºç™½çš„æ–‡æœ¬ï¼Œå¹¶ä½¿ç”¨ç‰¹æ®Šçš„ `<mask>` æ ‡è®°æ¥è¡¨ç¤ºç©ºç™½ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Milky Way is a <mask> galaxy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715796c2",
   "metadata": {},
   "source": [
    "\n",
    "å°è¯•ä½ çš„å¾®è°ƒæ¨¡å‹è¿›è¡Œæ¨ç†çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨å®ƒåœ¨ [pipeline()](/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) ä¸­ã€‚ä¸ºä½ çš„æ¨¡å‹å®ä¾‹åŒ–ä¸€ä¸ª `pipeline` è¿›è¡Œå¡«å……æ©ç ï¼Œå¹¶ä¼ é€’ä½ çš„æ–‡æœ¬ç»™å®ƒã€‚å¦‚æœå–œæ¬¢ï¼Œä½ å¯ä»¥ä½¿ç”¨ `top_k` å‚æ•°æ¥æŒ‡å®šè¿”å›å¤šå°‘ä¸ªé¢„æµ‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb314490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\"fill-mask\", \"username/my_awesome_eli5_mlm_model\")\n",
    "mask_filler(text, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdecad3",
   "metadata": {},
   "source": [
    "\n",
    "Pytorch\n",
    "\n",
    "éšè— Pytorch å†…å®¹\n",
    "\n",
    "å°†æ–‡æœ¬åˆ†è¯å¹¶è¿”å› PyTorch å¼ é‡çš„ `input_ids`ã€‚ä½ è¿˜éœ€è¦æŒ‡å®š `<mask>` æ ‡è®°çš„ä½ç½®ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"username/my_awesome_eli5_mlm_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"username/my_awesome_eli5_mlm_model\")\n",
    "logits = model(**inputs).logits\n",
    "mask_token_logits = logits[0, mask_token_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce274b",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åè¿”å›ä¸‰ä¸ªå¯èƒ½æ€§æœ€é«˜çš„é®è”½æ ‡è®°å¹¶æ‰“å°å®ƒä»¬ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4103ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_tokens = torch.topk(mask_token_logits, 3, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_3_tokens:\n",
    "    print(text.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a71368",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow\n",
    "\n",
    "éšè— TensorFlow å†…å®¹\n",
    "\n",
    "å°†æ–‡æœ¬åˆ†è¯å¹¶è¿”å› TensorFlow å¼ é‡çš„ `input_ids`ã€‚ä½ è¿˜éœ€è¦æŒ‡å®š `<mask>` æ ‡è®°çš„ä½ç½®ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37370105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"username/my_awesome_eli5_mlm_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"tf\")\n",
    "mask_token_index = tf.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[0, 1]\n",
    "\n",
    "from transformers import TFAutoModelForMaskedLM\n",
    "\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(\"username/my_awesome_eli5_mlm_model\")\n",
    "logits = model(**inputs).logits\n",
    "mask_token_logits = logits[0, mask_token_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bb919",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åè¿”å›ä¸‰ä¸ªå¯èƒ½æ€§æœ€é«˜çš„é®è”½æ ‡è®°å¹¶æ‰“å°å®ƒä»¬ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96871d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_tokens = tf.math.top_k(mask_token_logits, 3).indices.numpy()\n",
    "\n",
    "for token in top_3_tokens:\n",
    "    print(text.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81999aba",
   "metadata": {},
   "source": [
    "\n",
    "è¿™æ ·ï¼Œä½ å°±å¯ä»¥ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹æ¥é¢„æµ‹é®è”½è¯ï¼Œå¹¶å¾—åˆ°æœ€æœ‰å¯èƒ½çš„ä¸‰ä¸ªå¡«å……è¯ã€‚è¿™ç§æ–¹æ³•å¯ä»¥åº”ç”¨äºä»»ä½•éœ€è¦ä¸Šä¸‹æ–‡ç†è§£çš„ä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬ç”Ÿæˆã€é—®ç­”ç³»ç»Ÿç­‰ã€‚\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
