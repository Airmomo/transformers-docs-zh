{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11df696b",
   "metadata": {},
   "source": [
    "# å›¾åƒåˆ†å‰²\n",
    "\n",
    "å›¾åƒåˆ†å‰²æ¨¡å‹ç”¨äºå°†å›¾åƒä¸­å¯¹åº”ä¸åŒå…´è¶£åŒºåŸŸçš„éƒ¨åˆ†è¿›è¡Œåˆ†ç¦»ã€‚è¿™äº›æ¨¡å‹é€šè¿‡ä¸ºæ¯ä¸ªåƒç´ åˆ†é…ä¸€ä¸ªæ ‡ç­¾æ¥å®ç°ã€‚åˆ†å‰²ç±»å‹åŒ…æ‹¬è¯­ä¹‰åˆ†å‰²ã€å®ä¾‹åˆ†å‰²å’Œå…¨æ™¯åˆ†å‰²ã€‚\n",
    "\n",
    "åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†ï¼š\n",
    "\n",
    "1. æŸ¥çœ‹ä¸åŒç±»å‹çš„åˆ†å‰²ã€‚\n",
    "2. æä¾›ä¸€ä¸ªç«¯åˆ°ç«¯çš„è¯­ä¹‰åˆ†å‰²å¾®è°ƒç¤ºä¾‹ã€‚\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4c6a4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install -q datasets transformers evaluate accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178621e",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬é¼“åŠ±æ‚¨ç™»å½•æ‚¨çš„ Hugging Face è´¦æˆ·ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥ä¸Šä¼ å¹¶ä¸ç¤¾åŒºåˆ†äº«æ‚¨çš„æ¨¡å‹ã€‚å½“æç¤ºæ—¶ï¼Œè¾“å…¥æ‚¨çš„ä»¤ç‰Œä»¥ç™»å½•ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781f289",
   "metadata": {},
   "source": [
    "\n",
    "## åˆ†å‰²ç±»å‹\n",
    "\n",
    "è¯­ä¹‰åˆ†å‰²ä¸ºå›¾åƒä¸­çš„æ¯ä¸ªåƒç´ åˆ†é…ä¸€ä¸ªæ ‡ç­¾æˆ–ç±»åˆ«ã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹è¯­ä¹‰åˆ†å‰²æ¨¡å‹çš„è¾“å‡ºã€‚å®ƒå°†ä¸ºå›¾åƒä¸­é‡åˆ°çš„å¯¹è±¡çš„æ¯ä¸ªå®ä¾‹åˆ†é…ç›¸åŒçš„ç±»åˆ«ï¼Œä¾‹å¦‚ï¼Œæ‰€æœ‰çŒ«éƒ½å°†è¢«æ ‡è®°ä¸ºâ€œçŒ«â€ï¼Œè€Œä¸æ˜¯â€œçŒ«-1â€ã€â€œçŒ«-2â€ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ transformers çš„å›¾åƒåˆ†å‰²ç®¡é“å¿«é€Ÿæ¨æ–­è¯­ä¹‰åˆ†å‰²æ¨¡å‹ã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹ç¤ºä¾‹å›¾åƒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90345b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/segmentation_input.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7024b8",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ [nvidia/segformer-b1-finetuned-cityscapes-1024-1024](https://huggingface.co/nvidia/segformer-b1-finetuned-cityscapes-1024-1024)ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcdd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_segmentation = pipeline(\"image-segmentation\", \"nvidia/segformer-b1-finetuned-cityscapes-1024-1024\")\n",
    "results = semantic_segmentation(image)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286cd405",
   "metadata": {},
   "source": [
    "\n",
    "åˆ†å‰²ç®¡é“è¾“å‡ºåŒ…æ‹¬æ¯ä¸ªé¢„æµ‹ç±»åˆ«çš„æ©ç ã€‚\n",
    "\n",
    "æŸ¥çœ‹æ±½è½¦ç±»åˆ«çš„æ©ç ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯è¾†æ±½è½¦éƒ½è¢«åˆ†ç±»ä¸ºç›¸åŒçš„æ©ç ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[-1][\"mask\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8811a4",
   "metadata": {},
   "source": [
    "\n",
    "![è¯­ä¹‰åˆ†å‰²è¾“å‡º](../../resources/images/semantic_segmentation_output.png)\n",
    "\n",
    "åœ¨å®ä¾‹åˆ†å‰²ä¸­ï¼Œç›®æ ‡ä¸æ˜¯å¯¹æ¯ä¸ªåƒç´ è¿›è¡Œåˆ†ç±»ï¼Œè€Œæ˜¯é¢„æµ‹ç»™å®šå›¾åƒä¸­å¯¹è±¡çš„æ¯ä¸ªå®ä¾‹çš„æ©ç ã€‚å®ƒçš„å·¥ä½œåŸç†ä¸ç›®æ ‡æ£€æµ‹éå¸¸ç›¸ä¼¼ï¼Œç›®æ ‡æ£€æµ‹ä¸­æ¯ä¸ªå®ä¾‹éƒ½æœ‰ä¸€ä¸ªè¾¹ç•Œæ¡†ï¼Œè€Œå®ä¾‹åˆ†å‰²ä¸­åˆ™æ˜¯ä¸€ä¸ªåˆ†å‰²æ©ç ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ [facebook/mask2former-swin-large-cityscapes-instance](https://huggingface.co/facebook/mask2former-swin-large-cityscapes-instance) è¿›è¡Œæ­¤æ“ä½œã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_segmentation = pipeline(\"image-segmentation\", \"facebook/mask2former-swin-large-cityscapes-instance\")\n",
    "results = instance_segmentation(image)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fef3ca",
   "metadata": {},
   "source": [
    "\n",
    "å¦‚æ‚¨æ‰€è§ï¼Œè¿™é‡Œæœ‰å¤šè¾†æ±½è½¦è¢«åˆ†ç±»ï¼Œå¹¶ä¸”é™¤äº†å±äºæ±½è½¦å’Œäººå®ä¾‹çš„åƒç´ å¤–ï¼Œæ²¡æœ‰å¯¹å…¶ä»–åƒç´ è¿›è¡Œåˆ†ç±»ã€‚\n",
    "\n",
    "æŸ¥çœ‹å…¶ä¸­ä¸€ä¸ªæ±½è½¦æ©ç å¦‚ä¸‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[2][\"mask\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee51cfa",
   "metadata": {},
   "source": [
    "\n",
    "![å®ä¾‹åˆ†å‰²è¾“å‡º](../../resources/images/instance_segmentation_output.png)\n",
    "\n",
    "å…¨æ™¯åˆ†å‰²ç»“åˆäº†è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²ï¼Œæ¯ä¸ªåƒç´ éƒ½è¢«åˆ†ç±»ä¸ºä¸€ä¸ªç±»åˆ«å’Œè¯¥ç±»åˆ«çš„å®ä¾‹ï¼Œå¹¶ä¸”æ¯ä¸ªç±»åˆ«çš„æ¯ä¸ªå®ä¾‹éƒ½æœ‰å¤šä¸ªæ©ç ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [facebook/mask2former-swin-large-cityscapes-panoptic](https://huggingface.co/facebook/mask2former-swin-large-cityscapes-panoptic) è¿›è¡Œæ­¤æ“ä½œã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2897696",
   "metadata": {},
   "outputs": [],
   "source": [
    "panoptic_segmentation = pipeline(\"image-segmentation\", \"facebook/mask2former-swin-large-cityscapes-panoptic\")\n",
    "results = panoptic_segmentation(image)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33186907",
   "metadata": {},
   "source": [
    "\n",
    "å¦‚æ‚¨æ‰€è§ï¼Œæˆ‘ä»¬æœ‰æ›´å¤šçš„ç±»åˆ«ã€‚ç¨åæˆ‘ä»¬å°†è¯´æ˜æ¯ä¸ªåƒç´ éƒ½è¢«åˆ†ç±»ä¸ºå…¶ä¸­ä¸€ä¸ªç±»åˆ«ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬å¯¹æ‰€æœ‰ç±»å‹çš„åˆ†å‰²è¿›è¡Œå¹¶æ’æ¯”è¾ƒã€‚\n",
    "\n",
    "![åˆ†å‰²å›¾æ¯”è¾ƒ](../../resources/images/segmentation-comparison.png)\n",
    "\n",
    "çœ‹åˆ°æ‰€æœ‰ç±»å‹çš„åˆ†å‰²åï¼Œè®©æˆ‘ä»¬æ·±å…¥äº†è§£ä¸ºè¯­ä¹‰åˆ†å‰²å¾®è°ƒæ¨¡å‹ã€‚\n",
    "\n",
    "è¯­ä¹‰åˆ†å‰²çš„å¸¸è§ç°å®åº”ç”¨åŒ…æ‹¬è®­ç»ƒè‡ªåŠ¨é©¾é©¶æ±½è½¦ä»¥è¯†åˆ«è¡Œäººå’Œé‡è¦äº¤é€šä¿¡æ¯ã€åœ¨åŒ»å­¦å›¾åƒä¸­è¯†åˆ«ç»†èƒå’Œå¼‚å¸¸æƒ…å†µï¼Œä»¥åŠä»å«æ˜Ÿå›¾åƒä¸­ç›‘æµ‹ç¯å¢ƒå˜åŒ–ã€‚\n",
    "\n",
    "## ä¸ºåˆ†å‰²å¾®è°ƒæ¨¡å‹\n",
    "\n",
    "æˆ‘ä»¬ç°åœ¨å°†ï¼š\n",
    "\n",
    "1. åœ¨ [SceneParse150](https://huggingface.co/datasets/scene_parse_150) æ•°æ®é›†ä¸Šå¾®è°ƒ [SegFormer](https://huggingface.co/docs/transformers/main/en/model_doc/segformer#segformer)ã€‚\n",
    "2. ä½¿ç”¨æ‚¨å¾®è°ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚\n",
    "\n",
    "è¦æŸ¥çœ‹ä¸æ­¤ä»»åŠ¡å…¼å®¹çš„æ‰€æœ‰æ¶æ„å’Œæ£€æŸ¥ç‚¹ï¼Œæˆ‘ä»¬å»ºè®®æŸ¥çœ‹ [ä»»åŠ¡é¡µé¢](https://huggingface.co/tasks/image-segmentation)ã€‚\n",
    "\n",
    "### åŠ è½½ SceneParse150 æ•°æ®é›†\n",
    "\n",
    "é¦–å…ˆä» ğŸ¤— Datasets åº“ä¸­åŠ è½½ SceneParse150 æ•°æ®é›†çš„ä¸€ä¸ªè¾ƒå°çš„å­é›†ã€‚è¿™å°†è®©æ‚¨æœ‰æœºä¼šè¿›è¡Œå®éªŒå¹¶ç¡®ä¿ä¸€åˆ‡æ­£å¸¸å·¥ä½œï¼Œç„¶åå†åœ¨å®Œæ•´æ•°æ®é›†ä¸ŠèŠ±è´¹æ›´å¤šæ—¶é—´è¿›è¡Œè®­ç»ƒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"scene_parse_150\", split=\"train[:50]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab5c548",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) æ–¹æ³•å°†æ•°æ®é›†çš„ `train` åˆ†å‰²æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bb794",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(test_size=0.2)\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429e11c",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åæŸ¥çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0]\n",
    "\n",
    "# æŸ¥çœ‹å›¾åƒ\n",
    "train_ds[0][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d533e1",
   "metadata": {},
   "source": [
    "\n",
    "- `image`ï¼šåœºæ™¯çš„ PIL å›¾åƒã€‚\n",
    "- `annotation`ï¼šåˆ†å‰²å›¾çš„ PIL å›¾åƒï¼Œè¿™ä¹Ÿæ˜¯æ¨¡å‹çš„ç›®æ ‡ã€‚\n",
    "- `scene_category`ï¼šæè¿°å›¾åƒåœºæ™¯çš„ç±»åˆ« IDï¼Œå¦‚â€œå¨æˆ¿â€æˆ–â€œåŠå…¬å®¤â€ã€‚åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæ‚¨åªéœ€è¦ `image` å’Œ `annotation`ï¼Œå®ƒä»¬éƒ½æ˜¯ PIL å›¾åƒã€‚\n",
    "\n",
    "æ‚¨è¿˜éœ€è¦åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œå°†æ ‡ç­¾ ID æ˜ å°„åˆ°æ ‡ç­¾ç±»ï¼Œè¿™åœ¨ç¨åè®¾ç½®æ¨¡å‹æ—¶å°†éå¸¸æœ‰ç”¨ã€‚ä» Hub ä¸‹è½½æ˜ å°„å¹¶åˆ›å»º `id2label` å’Œ `label2id` å­—å…¸ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7228601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "repo_id = \"huggingface/label-files\"\n",
    "filename = \"ade20k-id2label.json\"\n",
    "id2label = json.loads(Path(hf_hub_download(repo_id, filename, repo_type=\"dataset\")).read_text())\n",
    "id2label = {int(k): v for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "num_labels = len(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3424b",
   "metadata": {},
   "source": [
    "\n",
    "#### è‡ªå®šä¹‰æ•°æ®é›†\n",
    "\n",
    "å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åˆ›å»ºå¹¶ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨ [run_semantic_segmentation.py](https://github.com/huggingface/transformers/blob/main/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py) è„šæœ¬è€Œä¸æ˜¯ç¬”è®°æœ¬å®ä¾‹è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œã€‚è¯¥è„šæœ¬éœ€è¦ï¼š\n",
    "\n",
    "1. ä¸€ä¸ªåŒ…å«ä¸¤ä¸ª [Image](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Image) åˆ—çš„ [DatasetDict](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetDict)ï¼Œå³â€œimageâ€å’Œâ€œlabelâ€ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479cbc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, Image\n",
    "\n",
    "image_paths_train = [\"path/to/image_1.jpg\", \"path/to/image_2.jpg\", ..., \"path/to/image_n.jpg\"]\n",
    "label_paths_train = [\"path/to/annotation_1.png\", \"path/to/annotation_2.png\", ..., \"path/to/annotation_n.png\"]\n",
    "\n",
    "image_paths_validation = [...]\n",
    "label_paths_validation = [...]\n",
    "\n",
    "def create_dataset(image_paths, label_paths):\n",
    "    dataset = Dataset.from_dict({\"image\": sorted(image_paths),\n",
    "                                \"label\": sorted(label_paths)})\n",
    "    dataset = dataset.cast_column(\"image\", Image())\n",
    "    dataset = dataset.cast_column(\"label\", Image())\n",
    "    return dataset\n",
    "\n",
    "# æ­¥éª¤ 1: åˆ›å»º Dataset å¯¹è±¡\n",
    "train_dataset = create_dataset(image_paths_train, label_paths_train)\n",
    "validation_dataset = create_dataset(image_paths_validation, label_paths_validation)\n",
    "\n",
    "# æ­¥éª¤ 2: åˆ›å»º DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    }\n",
    ")\n",
    "\n",
    "# æ­¥éª¤ 3: æ¨é€åˆ° Hubï¼ˆå‡è®¾æ‚¨å·²åœ¨ç»ˆç«¯/ç¬”è®°æœ¬ä¸­è¿è¡Œäº† huggingface-cli login å‘½ä»¤ï¼‰\n",
    "dataset.push_to_hub(\"your-name/dataset-repo\")\n",
    "\n",
    "# å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥å°†æ¨¡å‹æ¨é€åˆ° Hub ä¸Šçš„ç§æœ‰ä»“åº“\n",
    "# dataset.push_to_hub(\"name of repo on the hub\", private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ca44b",
   "metadata": {},
   "source": [
    "\n",
    "2. ä¸€ä¸ªå°†ç±»æ•´æ•°æ˜ å°„åˆ°ç±»åçš„ id2label å­—å…¸ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a7d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# ç®€å•ç¤ºä¾‹\n",
    "id2label = {0: 'cat', 1: 'dog'}\n",
    "with open('id2label.json', 'w') as fp:\n",
    "    json.dump(id2label, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b529254a",
   "metadata": {},
   "source": [
    "\n",
    "ä¾‹å¦‚ï¼ŒæŸ¥çœ‹è¿™ä¸ªä½¿ç”¨ä¸Šè¿°æ­¥éª¤åˆ›å»ºçš„ [ç¤ºä¾‹æ•°æ®é›†](https://huggingface.co/datasets/nielsr/ade20k-demo)ï¼Œå®ƒåŒ…å«äº†åˆ›å»ºæ­¥éª¤ã€‚\n",
    "\n",
    "### é¢„å¤„ç†\n",
    "\n",
    "ä¸‹ä¸€æ­¥æ˜¯åŠ è½½ SegFormer å›¾åƒå¤„ç†å™¨æ¥å‡†å¤‡æ¨¡å‹æ‰€éœ€çš„å›¾åƒå’Œæ³¨é‡Šã€‚ä¸€äº›æ•°æ®é›†ï¼Œå¦‚æœ¬ä¾‹ä¸­çš„æ•°æ®é›†ï¼Œä½¿ç”¨é›¶ç´¢å¼•ä½œä¸ºèƒŒæ™¯ç±»ã€‚ç„¶è€Œï¼ŒèƒŒæ™¯ç±»å®é™…ä¸Šå¹¶ä¸åŒ…å«åœ¨ 150 ä¸ªç±»ä¸­ï¼Œå› æ­¤æ‚¨éœ€è¦è®¾ç½® `do_reduce_labels=True` ä»¥ä»æ‰€æœ‰æ ‡ç­¾ä¸­å‡å»ä¸€ã€‚é›¶ç´¢å¼•è¢«æ›¿æ¢ä¸º `255`ï¼Œè¿™æ · SegFormer çš„æŸå¤±å‡½æ•°å°±ä¼šå¿½ç•¥å®ƒï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16721e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "checkpoint = \"nvidia/mit-b0\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint, do_reduce_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59bcec",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch\n",
    "\n",
    "é€šå¸¸å¯¹å›¾åƒæ•°æ®é›†åº”ç”¨ä¸€äº›æ•°æ®å¢å¼ºï¼Œä»¥ä½¿æ¨¡å‹æ›´èƒ½æŠµæŠ—è¿‡æ‹Ÿåˆã€‚åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨ [torchvision](https://pytorch.org/vision/stable/index.html) çš„ `ColorJitter` å‡½æ•°éšæœºæ›´æ”¹å›¾åƒçš„é¢œè‰²å±æ€§ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨æ‚¨å–œæ¬¢çš„ä»»ä½•å›¾åƒåº“ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ColorJitter\n",
    "\n",
    "jitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae719fb6",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨åˆ›å»ºä¸¤ä¸ªé¢„å¤„ç†å‡½æ•°æ¥å‡†å¤‡æ¨¡å‹æ‰€éœ€çš„å›¾åƒå’Œæ³¨é‡Šã€‚è¿™äº›å‡½æ•°å°†å›¾åƒè½¬æ¢ä¸º `pixel_values`ï¼Œå¹¶å°†æ³¨é‡Šè½¬æ¢ä¸º `labels`ã€‚å¯¹äºè®­ç»ƒé›†ï¼Œ`jitter` åœ¨æä¾›å›¾åƒç»™å›¾åƒå¤„ç†å™¨ä¹‹å‰åº”ç”¨ã€‚å¯¹äºæµ‹è¯•é›†ï¼Œå›¾åƒå¤„ç†å™¨åªè£å‰ªå’Œè§„èŒƒåŒ– `images`ï¼Œå¹¶ä¸”åªè£å‰ª `labels`ï¼Œå› ä¸ºåœ¨æµ‹è¯•æœŸé—´ä¸åº”ç”¨æ•°æ®å¢å¼ºã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transforms(example_batch):\n",
    "    images = [jitter(x) for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels)\n",
    "    return inputs\n",
    "\n",
    "def val_transforms(example_batch):\n",
    "    images = [x for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c682d",
   "metadata": {},
   "source": [
    "\n",
    "è¦åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨ `jitter`ï¼Œä½¿ç”¨ ğŸ¤— Datasets çš„ [set_transform](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.set_transform) å‡½æ•°ã€‚è½¬æ¢æ˜¯å³æ—¶åº”ç”¨çš„ï¼Œè¿™æ›´å¿«ï¼Œå¹¶ä¸”æ¶ˆè€—æ›´å°‘çš„ç£ç›˜ç©ºé—´ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_transform(train_transforms)\n",
    "test_ds.set_transform(val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabb0ec",
   "metadata": {},
   "source": [
    "\n",
    "### è¯„ä¼°\n",
    "\n",
    "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒ…å«ä¸€ä¸ªæŒ‡æ ‡é€šå¸¸æœ‰åŠ©äºè¯„ä¼°æ‚¨çš„æ¨¡å‹æ€§èƒ½ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) åº“å¿«é€ŸåŠ è½½ä¸€ä¸ªè¯„ä¼°æ–¹æ³•ã€‚å¯¹äºæ­¤ä»»åŠ¡ï¼ŒåŠ è½½ [å¹³å‡äº¤å¹¶æ¯”](https://huggingface.co/spaces/evaluate-metric/accuracy) (IoU) æŒ‡æ ‡ï¼ˆå‚é˜… ğŸ¤— Evaluate [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/evaluate/a_quick_tour) ä»¥äº†è§£æ›´å¤šå…³äºå¦‚ä½•åŠ è½½å’Œè®¡ç®—æŒ‡æ ‡çš„ä¿¡æ¯ï¼‰ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc0463",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶ååˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥ [è®¡ç®—](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) æŒ‡æ ‡ã€‚æ‚¨çš„é¢„æµ‹éœ€è¦å…ˆè½¬æ¢ä¸º logitsï¼Œç„¶åé‡å¡‘ä»¥åŒ¹é…æ ‡ç­¾çš„å¤§å°ï¼Œç„¶åæ‚¨æ‰èƒ½è°ƒç”¨ [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute)ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5991bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    with torch.no_grad():\n",
    "        logits, labels = eval_pred\n",
    "        logits_tensor = torch.from_numpy(logits)\n",
    "        logits_tensor = nn.functional.interpolate(\n",
    "            logits_tensor,\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "        metrics = metric.compute(\n",
    "            predictions=pred_labels,\n",
    "            references=labels,\n",
    "            num_labels=num_labels,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "        for key, value in metrics.items():\n",
    "            if isinstance(value, np.ndarray):\n",
    "                metrics[key] = value.tolist()\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56278b",
   "metadata": {},
   "source": [
    "\n",
    "### è®­ç»ƒ\n",
    "\n",
    "PyTorch\n",
    "\n",
    "å¦‚æœæ‚¨ä¸ç†Ÿæ‚‰ä½¿ç”¨ [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹ [è¿™é‡Œ](../training#finetune-with-trainer) çš„åŸºæœ¬æ•™ç¨‹ï¼\n",
    "\n",
    "æ‚¨ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒæ‚¨çš„æ¨¡å‹äº†ï¼ä½¿ç”¨ [AutoModelForSemanticSegmentation](/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSemanticSegmentation) åŠ è½½ SegFormerï¼Œå¹¶å°†æ¨¡å‹ä¼ é€’ç»™æ ‡ç­¾ ID å’Œæ ‡ç­¾ç±»ä¹‹é—´çš„æ˜ å°„ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSemanticSegmentation, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ceed9",
   "metadata": {},
   "source": [
    "\n",
    "åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œåªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "1. åœ¨ [TrainingArguments](/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) ä¸­å®šä¹‰æ‚¨çš„è®­ç»ƒè¶…å‚æ•°ã€‚é‡è¦çš„æ˜¯æ‚¨ä¸è¦åˆ é™¤æœªä½¿ç”¨çš„åˆ—ï¼Œå› ä¸ºè¿™ä¼šåˆ é™¤ `image` åˆ—ã€‚å¦‚æœæ²¡æœ‰ `image` åˆ—ï¼Œæ‚¨å°±ä¸èƒ½åˆ›å»º `pixel_values`ã€‚è®¾ç½® `remove_unused_columns=False` ä»¥é˜²æ­¢è¿™ç§è¡Œä¸ºï¼å”¯ä¸€å…¶ä»–å¿…éœ€çš„å‚æ•°æ˜¯ `output_dir`ï¼Œå®ƒæŒ‡å®šä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚æ‚¨å°†é€šè¿‡è®¾ç½® `push_to_hub=True` å°†æ¨¡å‹æ¨é€åˆ° Hubï¼ˆæ‚¨éœ€è¦ç™»å½• Hugging Face æ‰èƒ½ä¸Šä¼ æ‚¨çš„æ¨¡å‹ï¼‰ã€‚åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ï¼Œ[Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) å°†è¯„ä¼° IoU æŒ‡æ ‡å¹¶ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚\n",
    "2. å°†è®­ç»ƒå‚æ•°ä¼ é€’ç»™ [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)ï¼Œä»¥åŠæ¨¡å‹ã€æ•°æ®é›†ã€tokenizerã€æ•°æ®æ•´ç†å™¨å’Œ `compute_metrics` å‡½æ•°ã€‚\n",
    "3. è°ƒç”¨ [train()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) æ¥å¾®è°ƒæ‚¨çš„æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b23ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"segformer-b0-scene-parse-150\",\n",
    "    learning_rate=6e-5,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    save_total_limit=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,\n",
    "    eval_steps=20,\n",
    "    logging_steps=1,\n",
    "    eval_accumulation_steps=5,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb4986",
   "metadata": {},
   "source": [
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ [push_to_hub()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) æ–¹æ³•å°†æ‚¨çš„æ¨¡å‹åˆ†äº«åˆ° Hubï¼Œä»¥ä¾¿æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨æ‚¨çš„æ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3813dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db1022",
   "metadata": {},
   "source": [
    "\n",
    "### æ¨ç†\n",
    "\n",
    "å¤ªå¥½äº†ï¼Œç°åœ¨æ‚¨å·²ç»å¾®è°ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†äº†ï¼\n",
    "\n",
    "é‡æ–°åŠ è½½æ•°æ®é›†å¹¶åŠ è½½ä¸€ä¸ªå›¾åƒè¿›è¡Œæ¨ç†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b244ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"scene_parse_150\", split=\"train[:50]\")\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "test_ds = ds[\"test\"]\n",
    "image = ds[\"test\"][0][\"image\"]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36f265",
   "metadata": {},
   "source": [
    "\n",
    "![å§å®¤å›¾åƒ](../../resources/images/semantic-seg-image.png)\n",
    "\n",
    "PyTorch\n",
    "\n",
    "æˆ‘ä»¬ç°åœ¨å°†çœ‹åˆ°å¦‚ä½•åœ¨æ²¡æœ‰ç®¡é“çš„æƒ…å†µä¸‹è¿›è¡Œæ¨ç†ã€‚ä½¿ç”¨å›¾åƒå¤„ç†å™¨å¤„ç†å›¾åƒï¼Œå¹¶å°† `pixel_values` æ”¾åœ¨ GPU ä¸Šï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3583765",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # å¦‚æœå¯ç”¨ï¼Œä½¿ç”¨ GPUï¼Œå¦åˆ™ä½¿ç”¨ CPU\n",
    "encoding = image_processor(image, return_tensors=\"pt\")\n",
    "pixel_values = encoding.pixel_values.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85a7ef",
   "metadata": {},
   "source": [
    "\n",
    "å°†æ‚¨çš„è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å¹¶è¿”å› `logits`ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(pixel_values=pixel_values)\n",
    "logits = outputs.logits.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57388824",
   "metadata": {},
   "source": [
    "\n",
    "æ¥ä¸‹æ¥ï¼Œå°† logits ç¼©æ”¾åˆ°åŸå§‹å›¾åƒå¤§å°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_logits = nn.functional.interpolate(\n",
    "    logits,\n",
    "    size=image.size[::-1],\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=False,\n",
    ")\n",
    "\n",
    "pred_seg = upsampled_logits.argmax(dim=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b55afe",
   "metadata": {},
   "source": [
    "\n",
    "ä¸ºäº†å¯è§†åŒ–ç»“æœï¼ŒåŠ è½½ [æ•°æ®é›†é¢œè‰²è°ƒè‰²æ¿](https://github.com/tensorflow/models/blob/3f1ca33afe3c1631b733ea7e40c294273b9e406d/research/deeplab/utils/get_dataset_colormap.py#L51) ä½œä¸º `ade_palette()`ï¼Œå®ƒå°†æ¯ä¸ªç±»æ˜ å°„åˆ°å®ƒä»¬çš„ RGB å€¼ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ade_palette():\n",
    "    return np.asarray([\n",
    "        [0, 0, 0],\n",
    "        [120, 120, 120],\n",
    "        [180, 120, 120],\n",
    "        [6, 230, 230],\n",
    "        [80, 50, 50],\n",
    "        [4, 200, 3],\n",
    "        [120, 120, 80],\n",
    "        [140, 140, 140],\n",
    "        [204, 5, 255],\n",
    "        [230, 230, 230],\n",
    "        [4, 250, 7],\n",
    "        [224, 5, 255],\n",
    "        [235, 255, 7],\n",
    "        [150, 5, 61],\n",
    "        [120, 120, 70],\n",
    "        [8, 255, 51],\n",
    "        [255, 6, 82],\n",
    "        [143, 255, 140],\n",
    "        [204, 255, 4],\n",
    "        [255, 51, 7],\n",
    "        [204, 70, 3],\n",
    "        [0, 102, 200],\n",
    "        [61, 230, 250],\n",
    "        [255, 6, 51],\n",
    "        [11, 102, 255],\n",
    "        [255, 7, 71],\n",
    "        [255, 9, 224],\n",
    "        [9, 7, 230],\n",
    "        [220, 220, 220],\n",
    "        [255, 9, 92],\n",
    "        [112, 9, 255],\n",
    "        [8, 255, 214],\n",
    "        [7, 255, 224],\n",
    "        [255, 184, 6],\n",
    "        [10, 255, 71],\n",
    "        [255, 41, 10],\n",
    "        [7, 255, 255],\n",
    "        [224, 255, 8],\n",
    "        [102, 8, 255],\n",
    "        [255, 61, 6],\n",
    "        [255, 194, 7],\n",
    "        [255, 122, 8],\n",
    "        [0, 255, 20],\n",
    "        [255, 8, 41],\n",
    "        [255, 5, 153],\n",
    "        [6, 51, 255],\n",
    "        [235, 12, 255],\n",
    "        [160, 150, 20],\n",
    "        [0, 163, 255],\n",
    "        [140, 140, 140],\n",
    "        [250, 10, 15],\n",
    "        [20, 255, 0],\n",
    "        [31, 255, 0],\n",
    "        [255, 31, 0],\n",
    "        [255, 224, 0],\n",
    "        [153, 255, 0],\n",
    "        [0, 0, 255],\n",
    "        [255, 71, 0],\n",
    "        [0, 235, 255],\n",
    "        [0, 173, 255],\n",
    "        [31, 0, 255],\n",
    "        [11, 200, 200],\n",
    "        [255, 82, 0],\n",
    "        [0, 255, 245],\n",
    "        [0, 61, 255],\n",
    "        [0, 255, 112],\n",
    "        [0, 255, 133],\n",
    "        [255, 0, 0],\n",
    "        [255, 163, 0],\n",
    "        [255, 102, 0],\n",
    "        [194, 255, 0],\n",
    "        [0, 143, 255],\n",
    "        [51, 255, 0],\n",
    "        [0, 82, 255],\n",
    "        [0, 255, 41],\n",
    "        [0, 255, 173],\n",
    "        [10, 0, 255],\n",
    "        [173, 255, 0],\n",
    "        [0, 255, 153],\n",
    "        [255, 92, 0],\n",
    "        [255, 0, 255],\n",
    "        [255, 0, 245],\n",
    "        [255, 0, 102],\n",
    "        [255, 173, 0],\n",
    "        [255, 0, 20],\n",
    "        [255, 184, 184],\n",
    "        [0, 31, 255],\n",
    "        [0, 255, 61],\n",
    "        [0, 71, 255],\n",
    "        [255, 0, 204],\n",
    "        [0, 255, 194],\n",
    "        [0, 255, 82],\n",
    "        [0, 10, 255],\n",
    "        [0, 112, 255],\n",
    "        [51, 0, 255],\n",
    "        [0, 194, 255],\n",
    "        [0, 122, 255],\n",
    "        [0, 255, 163],\n",
    "        [255, 153, 0],\n",
    "        [0, 255, 10],\n",
    "        [255, 112, 0],\n",
    "        [143, 255, 0],\n",
    "        [82, 0, 255],\n",
    "        [163, 255, 0],\n",
    "        [255, 235, 0],\n",
    "        [8, 184, 170],\n",
    "        [133, 0, 255],\n",
    "        [0, 255, 92],\n",
    "        [184, 0, 255],\n",
    "        [255, 0, 31],\n",
    "        [0, 184, 255],\n",
    "        [0, 214, 255],\n",
    "        [255, 0, 112],\n",
    "        [92, 255, 0],\n",
    "        [0, 224, 255],\n",
    "        [112, 224, 255],\n",
    "        [70, 184, 160],\n",
    "        [163, 0, 255],\n",
    "        [153, 0, 255],\n",
    "        [71, 255, 0],\n",
    "        [255, 0, 163],\n",
    "        [255, 204, 0],\n",
    "        [255, 0, 143],\n",
    "        [0, 255, 235],\n",
    "        [133, 255, 0],\n",
    "        [255, 0, 235],\n",
    "        [245, 0, 255],\n",
    "        [255, 0, 122],\n",
    "        [255, 245, 0],\n",
    "        [10, 190, 212],\n",
    "        [214, 255, 0],\n",
    "        [0, 204, 255],\n",
    "        [20, 0, 255],\n",
    "        [255, 255, 0],\n",
    "        [0, 153, 255],\n",
    "        [0, 41, 255],\n",
    "        [0, 255, 204],\n",
    "        [41, 0, 255],\n",
    "        [41, 255, 0],\n",
    "        [173, 0, 255],\n",
    "        [0, 245, 255],\n",
    "        [71, 0, 255],\n",
    "        [122, 0, 255],\n",
    "        [0, 255, 184],\n",
    "        [0, 92, 255],\n",
    "        [184, 255, 0],\n",
    "        [0, 133, 255],\n",
    "        [255, 214, 0],\n",
    "        [25, 194, 194],\n",
    "        [102, 255, 0],\n",
    "        [92, 0, 255],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c757c",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åï¼Œæ‚¨å¯ä»¥ç»„åˆå¹¶ç»˜åˆ¶æ‚¨çš„å›¾åƒå’Œé¢„æµ‹çš„åˆ†å‰²å›¾ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "color_seg = np.zeros((pred_seg.shape[0], pred_seg.shape[1], 3), dtype=np.uint8)\n",
    "palette = np.array(ade_palette())\n",
    "for label, color in enumerate(palette):\n",
    "    color_seg[pred_seg == label, :] = color\n",
    "color_seg = color_seg[..., ::-1]  # è½¬æ¢ä¸º BGR\n",
    "\n",
    "img = np.array(image) * 0.5 + color_seg * 0.5  # ç»˜åˆ¶å¸¦æœ‰åˆ†å‰²å›¾çš„å›¾åƒ\n",
    "img = img.astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635450bf",
   "metadata": {},
   "source": [
    "\n",
    "![å¸¦æœ‰åˆ†å‰²å›¾çš„å§å®¤å›¾åƒ](../../resources/images/semantic-seg-preds.png)\n",
    "\n",
    "æ­å–œï¼æ‚¨å·²ç»æˆåŠŸåœ°å¾®è°ƒäº†ä¸€ä¸ªå›¾åƒåˆ†å‰²æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å®ƒè¿›è¡Œäº†æ¨ç†ã€‚æ‚¨ç°åœ¨å¯ä»¥å°†è¿™ä¸ªæ¨¡å‹ç”¨äºå„ç§å›¾åƒåˆ†å‰²ä»»åŠ¡ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€åŒ»å­¦å›¾åƒåˆ†æå’Œç¯å¢ƒç›‘æµ‹ã€‚"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
