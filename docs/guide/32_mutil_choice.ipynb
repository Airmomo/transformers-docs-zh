{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb78ceca",
   "metadata": {},
   "source": [
    "# å¤šé¡¹é€‰æ‹©ä»»åŠ¡\n",
    "\n",
    "å¤šé¡¹é€‰æ‹©ä»»åŠ¡ç±»ä¼¼äºé—®ç­”ä»»åŠ¡ï¼Œä¸åŒä¹‹å¤„åœ¨äºæä¾›äº†å¤šä¸ªå€™é€‰ç­”æ¡ˆä»¥åŠä¸€äº›ä¸Šä¸‹æ–‡ï¼Œæ¨¡å‹éœ€è¦è®­ç»ƒä»¥é€‰æ‹©æ­£ç¡®çš„ç­”æ¡ˆã€‚\n",
    "\n",
    "æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ï¼š\n",
    "\n",
    "1. åœ¨ SWAG æ•°æ®é›†çš„ `regular` é…ç½®ä¸Šå¾®è°ƒ BERTï¼Œä»¥åœ¨ç»™å®šçš„å¤šä¸ªé€‰é¡¹å’Œä¸€äº›ä¸Šä¸‹æ–‡ä¸­é€‰æ‹©æœ€ä½³ç­”æ¡ˆã€‚\n",
    "2. ä½¿ç”¨æ‚¨å¾®è°ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886502b7",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f3b2f",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬é¼“åŠ±æ‚¨ç™»å½•æ‚¨çš„ Hugging Face è´¦æˆ·ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥ä¸Šä¼ å¹¶ä¸ç¤¾åŒºåˆ†äº«æ‚¨çš„æ¨¡å‹ã€‚å½“æç¤ºæ—¶ï¼Œè¾“å…¥æ‚¨çš„ä»¤ç‰Œä»¥ç™»å½•ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6dae22",
   "metadata": {},
   "source": [
    "\n",
    "## åŠ è½½ SWAG æ•°æ®é›†\n",
    "\n",
    "é¦–å…ˆä» ğŸ¤— Datasets åº“ä¸­åŠ è½½ SWAG æ•°æ®é›†çš„ `regular` é…ç½®ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "swag = load_dataset(\"swag\", \"regular\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93717c",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åæŸ¥çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989cd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "swag[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ffaa1",
   "metadata": {},
   "source": [
    "\n",
    "è™½ç„¶è¿™é‡Œçœ‹èµ·æ¥æœ‰å¾ˆå¤šå­—æ®µï¼Œä½†å®é™…ä¸Šéå¸¸ç®€å•ï¼š\n",
    "\n",
    "- `sent1` å’Œ `sent2`ï¼šè¿™äº›å­—æ®µæ˜¾ç¤ºäº†å¥å­æ˜¯å¦‚ä½•å¼€å§‹çš„ï¼Œå¦‚æœæ‚¨å°†è¿™ä¸¤ä¸ªå­—æ®µæ”¾åœ¨ä¸€èµ·ï¼Œå°±ä¼šå¾—åˆ° `startphrase` å­—æ®µã€‚\n",
    "- `ending`ï¼šå»ºè®®ä¸€ä¸ªå¯èƒ½çš„å¥å­ç»“æŸæ–¹å¼ï¼Œä½†åªæœ‰ä¸€ä¸ªæ˜¯æ­£ç¡®çš„ã€‚\n",
    "- `label`ï¼šæ ‡è¯†æ­£ç¡®çš„å¥å­ç»“æŸã€‚\n",
    "\n",
    "## é¢„å¤„ç†\n",
    "\n",
    "ä¸‹ä¸€æ­¥æ˜¯åŠ è½½ BERT åˆ†è¯å™¨æ¥å¤„ç†å¥å­å¼€å¤´å’Œå››ä¸ªå¯èƒ½çš„ç»“å°¾ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdebe4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa842b3c",
   "metadata": {},
   "source": [
    "\n",
    "æ‚¨éœ€è¦åˆ›å»ºçš„é¢„å¤„ç†å‡½æ•°éœ€è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\n",
    "\n",
    "1. åˆ¶ä½œ `sent1` å­—æ®µçš„å››ä»½å‰¯æœ¬ï¼Œå¹¶å°†æ¯ä¸ªå‰¯æœ¬ä¸ `sent2` ç»“åˆä»¥é‡æ–°åˆ›å»ºå¥å­å¼€å¤´çš„æ–¹å¼ã€‚\n",
    "2. å°† `sent2` ä¸æ¯ä¸ªå¯èƒ½çš„å¥å­ç»“å°¾ç»“åˆã€‚\n",
    "3. æ‰å¹³åŒ–è¿™ä¸¤ä¸ªåˆ—è¡¨ä»¥ä¾¿è¿›è¡Œåˆ†è¯ï¼Œç„¶ååœ¨åˆ†è¯åè¿›è¡Œåæ‰å¹³åŒ–ï¼Œä»¥ä¾¿æ¯ä¸ªç¤ºä¾‹éƒ½æœ‰ç›¸åº”çš„ `input_ids`ã€`attention_mask` å’Œ `labels` å­—æ®µã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]\n",
    "    question_headers = examples[\"sent2\"]\n",
    "    second_sentences = [\n",
    "        [f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)\n",
    "    ]\n",
    "\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    return {k: [v[i:i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b661a2",
   "metadata": {},
   "source": [
    "\n",
    "è¦åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨é¢„å¤„ç†å‡½æ•°ï¼Œè¯·ä½¿ç”¨ ğŸ¤— Datasets çš„ `map` æ–¹æ³•ã€‚æ‚¨å¯ä»¥é€šè¿‡è®¾ç½® `batched=True` æ¥åŠ é€Ÿ `map` å‡½æ•°ï¼Œä»¥ä¾¿ä¸€æ¬¡å¤„ç†æ•°æ®é›†ä¸­çš„å¤šä¸ªå…ƒç´ ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a481e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_swag = swag.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601fbf9",
   "metadata": {},
   "source": [
    "\n",
    "ğŸ¤— Transformers æ²¡æœ‰ä¸ºå¤šé¡¹é€‰æ‹©æä¾›æ•°æ®æ•´ç†å™¨ï¼Œå› æ­¤æ‚¨éœ€è¦è°ƒæ•´ `DataCollatorWithPadding` æ¥åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ‰¹æ¬¡ã€‚åœ¨æ•´ç†è¿‡ç¨‹ä¸­ï¼ŒåŠ¨æ€åœ°å°†å¥å­å¡«å……åˆ°æ‰¹æ¬¡ä¸­æœ€é•¿çš„é•¿åº¦ï¼Œè€Œä¸æ˜¯å°†æ•´ä¸ªæ•°æ®é›†å¡«å……åˆ°æœ€å¤§é•¿åº¦ï¼Œè¿™æ ·åšæ›´æœ‰æ•ˆç‡ã€‚\n",
    "\n",
    "`DataCollatorForMultipleChoice` æ‰å¹³åŒ–æ‰€æœ‰æ¨¡å‹è¾“å…¥ï¼Œåº”ç”¨å¡«å……ï¼Œç„¶ååæ‰å¹³åŒ–ç»“æœï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edee75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7d539",
   "metadata": {},
   "source": [
    "\n",
    "## è¯„ä¼°\n",
    "\n",
    "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒ…å«ä¸€ä¸ªæŒ‡æ ‡é€šå¸¸æœ‰åŠ©äºè¯„ä¼°æ‚¨çš„æ¨¡å‹æ€§èƒ½ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ ğŸ¤— Evaluate åº“å¿«é€ŸåŠ è½½ä¸€ä¸ªè¯„ä¼°æ–¹æ³•ã€‚å¯¹äºæ­¤ä»»åŠ¡ï¼ŒåŠ è½½å‡†ç¡®æ€§æŒ‡æ ‡ï¼ˆè¯·å‚é˜… ğŸ¤— Evaluate å¿«é€Ÿå…¥é—¨ä»¥äº†è§£æ›´å¤šå…³äºå¦‚ä½•åŠ è½½å’Œè®¡ç®—æŒ‡æ ‡çš„ä¿¡æ¯ï¼‰ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a10d4a",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶ååˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå°†æ‚¨çš„é¢„æµ‹å’Œæ ‡ç­¾ä¼ é€’ç»™ `compute` ä»¥è®¡ç®—å‡†ç¡®æ€§ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b382023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d1e4b",
   "metadata": {},
   "source": [
    "\n",
    "æ‚¨çš„ `compute_metrics` å‡½æ•°ç°åœ¨å‡†å¤‡å¥½äº†ï¼Œå½“æ‚¨è®¾ç½®è®­ç»ƒæ—¶ï¼Œæ‚¨å°†è¿”å›åˆ°å®ƒã€‚\n",
    "\n",
    "## è®­ç»ƒ\n",
    "\n",
    "å¦‚æœæ‚¨ä¸ç†Ÿæ‚‰ä½¿ç”¨ `Trainer` å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹åŸºæœ¬æ•™ç¨‹ï¼\n",
    "\n",
    "æ‚¨ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒæ‚¨çš„æ¨¡å‹äº†ï¼ä½¿ç”¨ `AutoModelForMultipleChoice` åŠ è½½ BERTï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f937816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a22c02b",
   "metadata": {},
   "source": [
    "\n",
    "åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œåªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "1. åœ¨ `TrainingArguments` ä¸­å®šä¹‰æ‚¨çš„è®­ç»ƒè¶…å‚æ•°ã€‚å”¯ä¸€éœ€è¦çš„å‚æ•°æ˜¯ `output_dir`ï¼Œå®ƒæŒ‡å®šäº†ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚æ‚¨å¯ä»¥é€šè¿‡è®¾ç½® `push_to_hub=True` å°†æ¨¡å‹æ¨é€åˆ° Hubï¼ˆæ‚¨éœ€è¦ç™»å½• Hugging Face æ‰èƒ½ä¸Šä¼ æ¨¡å‹ï¼‰ã€‚åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ï¼Œ`Trainer` å°†è¯„ä¼°å‡†ç¡®æ€§å¹¶ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚\n",
    "2. å°†è®­ç»ƒå‚æ•°ä¼ é€’ç»™ `Trainer`ï¼Œä»¥åŠæ¨¡å‹ã€æ•°æ®é›†ã€åˆ†è¯å™¨ã€æ•°æ®æ•´ç†å™¨å’Œ `compute_metrics` å‡½æ•°ã€‚\n",
    "3. è°ƒç”¨ `train()` ä»¥å¾®è°ƒæ‚¨çš„æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_swag_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_swag[\"train\"],\n",
    "    eval_dataset=tokenized_swag[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808f0734",
   "metadata": {},
   "source": [
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ `push_to_hub()` æ–¹æ³•å°†æ‚¨çš„æ¨¡å‹åˆ†äº«åˆ° Hubï¼Œä»¥ä¾¿æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨æ‚¨çš„æ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709504d9",
   "metadata": {},
   "source": [
    "\n",
    "## æ¨ç†\n",
    "\n",
    "å¤ªå¥½äº†ï¼Œç°åœ¨æ‚¨å·²ç»å¾®è°ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†ï¼\n",
    "\n",
    "æƒ³å‡ºä¸€äº›æ–‡æœ¬å’Œä¸¤ä¸ªå€™é€‰ç­”æ¡ˆï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81656dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"France has a bread law, Le DÃ©cret Pain, with strict rules on what is allowed in a traditional baguette.\"\n",
    "candidate1 = \"The law does not apply to croissants and brioche.\"\n",
    "candidate2 = \"The law applies to baguettes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550aeb3",
   "metadata": {},
   "source": [
    "\n",
    "å¯¹æ¯ä¸ªæç¤ºå’Œå€™é€‰ç­”æ¡ˆå¯¹è¿›è¡Œåˆ†è¯ï¼Œå¹¶è¿”å› PyTorch å¼ é‡ã€‚æ‚¨è¿˜åº”è¯¥åˆ›å»ºä¸€äº› `labels`ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea28070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"username/my_awesome_swag_model\")\n",
    "inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=\"pt\", padding=True)\n",
    "labels = torch.tensor(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b46c9",
   "metadata": {},
   "source": [
    "\n",
    "å°†æ‚¨çš„è¾“å…¥å’Œæ ‡ç­¾ä¼ é€’ç»™æ¨¡å‹ï¼Œå¹¶è¿”å› `logits`ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"username/my_awesome_swag_model\")\n",
    "outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b3f028",
   "metadata": {},
   "source": [
    "\n",
    "è·å–æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = logits.argmax().item()\n",
    "predicted_class"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
