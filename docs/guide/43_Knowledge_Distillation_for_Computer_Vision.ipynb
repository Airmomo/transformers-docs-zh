{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7e876a",
   "metadata": {},
   "source": [
    "# çŸ¥è¯†è’¸é¦åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨\n",
    "\n",
    "çŸ¥è¯†è’¸é¦æ˜¯ä¸€ç§å°†å¤§å‹å¤æ‚æ¨¡å‹ï¼ˆæ•™å¸ˆæ¨¡å‹ï¼‰çš„çŸ¥è¯†è½¬ç§»åˆ°å°å‹ç®€å•æ¨¡å‹ï¼ˆå­¦ç”Ÿæ¨¡å‹ï¼‰çš„æŠ€æœ¯ã€‚ä¸ºäº†ä»ä¸€ä¸ªæ¨¡å‹ä¸­æå–çŸ¥è¯†å¹¶ä¼ é€’ç»™å¦ä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„æ•™å¸ˆæ¨¡å‹ï¼ˆä¾‹å¦‚å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼‰ï¼Œç„¶åéšæœºåˆå§‹åŒ–ä¸€ä¸ªå­¦ç”Ÿæ¨¡å‹æ¥å­¦ä¹ ç›¸åŒçš„ä»»åŠ¡ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ï¼Œä½¿å…¶è¾“å‡ºä¸æ•™å¸ˆæ¨¡å‹çš„è¾“å‡ºå°½å¯èƒ½æ¥è¿‘ï¼Œä»è€Œæ¨¡æ‹Ÿæ•™å¸ˆæ¨¡å‹çš„è¡Œä¸ºã€‚è¿™ä¸€æŠ€æœ¯æœ€æ—©ç”± Hinton ç­‰äººåœ¨è®ºæ–‡ [ã€Šç¥ç»ç½‘ç»œä¸­çš„çŸ¥è¯†è’¸é¦ã€‹](https://arxiv.org/abs/1503.02531) ä¸­æå‡ºã€‚åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†è¿›è¡Œç‰¹å®šä»»åŠ¡çš„çŸ¥è¯†è’¸é¦ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ [beans æ•°æ®é›†](https://huggingface.co/datasets/beans)ã€‚\n",
    "\n",
    "æœ¬æŒ‡å—å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ ğŸ¤— Transformers çš„ [Trainer API](https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer) å°†ä¸€ä¸ªç»è¿‡å¾®è°ƒçš„ [ViT æ¨¡å‹](https://huggingface.co/merve/vit-mobilenet-beans-224)ï¼ˆæ•™å¸ˆæ¨¡å‹ï¼‰è’¸é¦åˆ°ä¸€ä¸ª [MobileNet](https://huggingface.co/google/mobilenet_v2_1.4_224)ï¼ˆå­¦ç”Ÿæ¨¡å‹ï¼‰ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬å®‰è£…è’¸é¦å’Œè¯„ä¼°è¿‡ç¨‹ä¸­éœ€è¦çš„åº“ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df364fdc",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets accelerate tensorboard evaluate --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e2458",
   "metadata": {},
   "source": [
    "\n",
    "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `merve/beans-vit-224` æ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäº `google/vit-base-patch16-224-in21k` åœ¨ beans æ•°æ®é›†ä¸Šå¾®è°ƒçš„å›¾åƒåˆ†ç±»æ¨¡å‹ã€‚æˆ‘ä»¬å°†æŠŠè¿™ä¸ªæ¨¡å‹è’¸é¦åˆ°ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„ MobileNetV2ã€‚\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬åŠ è½½æ•°æ®é›†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"beans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4564ea5",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»ä¸€æ¨¡å‹çš„å›¾åƒå¤„ç†å™¨ï¼Œå› ä¸ºåœ¨è¿™ç§æƒ…å†µä¸‹å®ƒä»¬è¿”å›ç›¸åŒåˆ†è¾¨ç‡çš„ç›¸åŒè¾“å‡ºã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `dataset` çš„ `map()` æ–¹æ³•å¯¹æ•°æ®é›†çš„æ¯ä¸ªåˆ†ç‰‡è¿›è¡Œé¢„å¤„ç†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "teacher_processor = AutoImageProcessor.from_pretrained(\"merve/beans-vit-224\")\n",
    "\n",
    "def process(examples):\n",
    "    processed_inputs = teacher_processor(examples[\"image\"])\n",
    "    return processed_inputs\n",
    "\n",
    "processed_datasets = dataset.map(process, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afce494",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®©å­¦ç”Ÿæ¨¡å‹ï¼ˆéšæœºåˆå§‹åŒ–çš„ MobileNetï¼‰æ¨¡ä»¿æ•™å¸ˆæ¨¡å‹ï¼ˆå¾®è°ƒåçš„è§†è§‰å˜æ¢å™¨ï¼‰ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬é¦–å…ˆè·å–æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹çš„ logits è¾“å‡ºã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æ¯ç§è¾“å‡ºé™¤ä»¥å‚æ•° `temperature`ï¼Œè¯¥å‚æ•°æ§åˆ¶æ¯ä¸ªè½¯ç›®æ ‡çš„é‡è¦æ€§ã€‚å‚æ•° `lambda` ç”¨äºæƒè¡¡è’¸é¦æŸå¤±çš„é‡è¦æ€§ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `temperature=5` å’Œ `lambda=0.5`ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Kullback-Leibler æ•£åº¦æŸå¤±æ¥è®¡ç®—å­¦ç”Ÿæ¨¡å‹å’Œæ•™å¸ˆæ¨¡å‹ä¹‹é—´çš„å·®å¼‚ã€‚ç»™å®šä¸¤ä¸ªæ•°æ® P å’Œ Qï¼ŒKL æ•£åº¦è§£é‡Šäº†ç”¨ Q è¡¨ç¤º P æ‰€éœ€çš„é¢å¤–ä¿¡æ¯é‡ã€‚å¦‚æœä¸¤è€…å®Œå…¨ç›¸åŒï¼Œå®ƒä»¬çš„ KL æ•£åº¦ä¸ºé›¶ï¼Œå› ä¸ºä¸éœ€è¦å…¶ä»–ä¿¡æ¯æ¥è§£é‡Š Pã€‚å› æ­¤ï¼Œåœ¨çŸ¥è¯†è’¸é¦çš„èƒŒæ™¯ä¸‹ï¼ŒKL æ•£åº¦æ˜¯æœ‰ç”¨çš„ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageDistilTrainer(Trainer):\n",
    "    def __init__(self, teacher_model=None, student_model=None, temperature=None, lambda_param=None, *args, **kwargs):\n",
    "        super().__init__(model=student_model, *args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        self.loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.teacher.to(device)\n",
    "        self.teacher.eval()\n",
    "        self.temperature = temperature\n",
    "        self.lambda_param = lambda_param\n",
    "\n",
    "    def compute_loss(self, student, inputs, return_outputs=False):\n",
    "        student_output = self.student(**inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_output = self.teacher(**inputs)\n",
    "\n",
    "        # è®¡ç®—æ•™å¸ˆå’Œå­¦ç”Ÿçš„è½¯ç›®æ ‡\n",
    "        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)\n",
    "        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)\n",
    "\n",
    "        # è®¡ç®—æŸå¤±\n",
    "        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)\n",
    "\n",
    "        # è®¡ç®—çœŸå®æ ‡ç­¾çš„æŸå¤±\n",
    "        student_target_loss = student_output.loss\n",
    "\n",
    "        # è®¡ç®—æœ€ç»ˆæŸå¤±\n",
    "        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss\n",
    "        return (loss, student_output) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65504da",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨æˆ‘ä»¬ç™»å½• Hugging Face Hubï¼Œä»¥ä¾¿é€šè¿‡ `Trainer` å°†æ¨¡å‹æ¨é€åˆ° Hugging Face Hubã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a7672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156c6f8",
   "metadata": {},
   "source": [
    "\n",
    "è®¾ç½® `TrainingArguments`ã€æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a79d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification, MobileNetV2Config, MobileNetV2ForImageClassification\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my-awesome-model\",\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    logging_dir=f\"{repo_name}/logs\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub=True,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_model_id=repo_name,\n",
    ")\n",
    "\n",
    "num_labels = len(processed_datasets[\"train\"].features[\"labels\"].names)\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "teacher_model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"merve/beans-vit-224\",\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# ä»å¤´å¼€å§‹è®­ç»ƒ MobileNetV2\n",
    "student_config = MobileNetV2Config()\n",
    "student_config.num_labels = num_labels\n",
    "student_model = MobileNetV2ForImageClassification(student_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a733ad",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `compute_metrics` å‡½æ•°åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ã€‚æ­¤å‡½æ•°å°†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®¡ç®—æ¨¡å‹çš„ `accuracy` å’Œ `f1`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd718c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    acc = accuracy.compute(references=labels, predictions=np.argmax(predictions, axis=1))\n",
    "    return {\"accuracy\": acc[\"accuracy\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d2c2b",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨æˆ‘ä»¬ä½¿ç”¨å®šä¹‰çš„è®­ç»ƒå‚æ•°åˆå§‹åŒ– `Trainer`ã€‚æˆ‘ä»¬è¿˜å°†åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "trainer = ImageDistilTrainer(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    training_args=training_args,\n",
    "    train_dataset=processed_datasets[\"train\"],\n",
    "    eval_dataset=processed_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=teacher_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    temperature=5,\n",
    "    lambda_param=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424aa589",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥è®­ç»ƒæ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd45d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc132630",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬å¯ä»¥åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9486ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(processed_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ff428",
   "metadata": {},
   "source": [
    "\n",
    "åœ¨æµ‹è¯•é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¾¾åˆ°äº† 72% çš„å‡†ç¡®ç‡ã€‚ä¸ºäº†éªŒè¯è’¸é¦çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨ç›¸åŒçš„è¶…å‚æ•°ä»å¤´å¼€å§‹è®­ç»ƒäº†ä¸€ä¸ª MobileNetï¼Œç»“æœåœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º 63%ã€‚æˆ‘ä»¬é¼“åŠ±è¯»è€…å°è¯•ä¸åŒçš„é¢„è®­ç»ƒæ•™å¸ˆæ¨¡å‹ã€å­¦ç”Ÿæ¶æ„ã€è’¸é¦å‚æ•°ï¼Œå¹¶æŠ¥å‘Šä»–ä»¬çš„å‘ç°ã€‚è’¸é¦æ¨¡å‹çš„è®­ç»ƒæ—¥å¿—å’Œæ£€æŸ¥ç‚¹å¯ä»¥åœ¨ [è¿™ä¸ªä»“åº“](https://huggingface.co/merve/vit-mobilenet-beans-224) ä¸­æ‰¾åˆ°ï¼Œä»å¤´å¼€å§‹è®­ç»ƒçš„ MobileNetV2 å¯ä»¥åœ¨ [è¿™ä¸ªä»“åº“](https://huggingface.co/merve/resnet-mobilenet-beans-5) ä¸­æ‰¾åˆ°ã€‚\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
