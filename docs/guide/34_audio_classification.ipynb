{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f14f358",
   "metadata": {},
   "source": [
    "# éŸ³é¢‘åˆ†ç±»\n",
    "\n",
    "éŸ³é¢‘åˆ†ç±»ä¸æ–‡æœ¬åˆ†ç±»ç±»ä¼¼ï¼Œéƒ½æ˜¯ä»è¾“å…¥æ•°æ®ä¸­åˆ†é…ä¸€ä¸ªç±»åˆ«æ ‡ç­¾ã€‚ä¸åŒä¹‹å¤„åœ¨äºï¼ŒéŸ³é¢‘åˆ†ç±»å¤„ç†çš„æ˜¯åŸå§‹éŸ³é¢‘æ³¢å½¢ï¼Œè€Œä¸æ˜¯æ–‡æœ¬ã€‚éŸ³é¢‘åˆ†ç±»çš„ä¸€äº›å®é™…åº”ç”¨åŒ…æ‹¬è¯†åˆ«è¯´è¯äººçš„æ„å›¾ã€è¯­è¨€åˆ†ç±»ï¼Œç”šè‡³æ˜¯é€šè¿‡å£°éŸ³è¯†åˆ«åŠ¨ç‰©ç§ç±»ã€‚\n",
    "\n",
    "æœ¬æŒ‡å—å°†å‘ä½ å±•ç¤ºå¦‚ä½•ï¼š\n",
    "\n",
    "1. åœ¨ [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) æ•°æ®é›†ä¸Šå¾®è°ƒ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) æ¨¡å‹ï¼Œä»¥åˆ†ç±»è¯´è¯äººçš„æ„å›¾ã€‚\n",
    "2. ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚\n",
    "\n",
    "è¦æŸ¥çœ‹ä¸æ­¤ä»»åŠ¡å…¼å®¹çš„æ‰€æœ‰æ¶æ„å’Œæ£€æŸ¥ç‚¹ï¼Œå»ºè®®æŸ¥é˜… [ä»»åŠ¡é¡µé¢](https://huggingface.co/tasks/audio-classification)ã€‚\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²ç»å®‰è£…äº†æ‰€æœ‰å¿…è¦çš„åº“ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4747b21a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705b004",
   "metadata": {},
   "source": [
    "\n",
    "æˆ‘ä»¬é¼“åŠ±ä½ ç™»å½•ä½ çš„ Hugging Face è´¦æˆ·ï¼Œä»¥ä¾¿ä½ å¯ä»¥ä¸Šä¼ å¹¶åˆ†äº«ä½ çš„æ¨¡å‹ã€‚å½“æç¤ºä½ æ—¶ï¼Œè¾“å…¥ä½ çš„ä»¤ç‰Œæ¥ç™»å½•ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5923a5",
   "metadata": {},
   "source": [
    "\n",
    "## åŠ è½½ MInDS-14 æ•°æ®é›†\n",
    "\n",
    "é¦–å…ˆä» ğŸ¤— Datasets åº“åŠ è½½ MInDS-14 æ•°æ®é›†ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647eb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bf3a8",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ [train_test_split](https://huggingface.co/docs/datasets/v3.0.2/en/package_reference/main_classes#datasets.Dataset.train_test_split) æ–¹æ³•å°†æ•°æ®é›†çš„ `train` åˆ†å‰²æˆè¾ƒå°çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚è¿™å¯ä»¥è®©ä½ åœ¨å®éªŒå’Œç¡®ä¿ä¸€åˆ‡æ­£å¸¸å·¥ä½œä¹‹å‰ï¼Œä¸å¿…èŠ±è´¹å¤ªå¤šæ—¶é—´åœ¨å®Œæ•´æ•°æ®é›†ä¸Šã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a93a2a",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶åæŸ¥çœ‹æ•°æ®é›†ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7fb34",
   "metadata": {},
   "source": [
    "\n",
    "è¾“å‡ºï¼š"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a24519af",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
    "        num_rows: 450\n",
    "    })\n",
    "    test: Dataset({\n",
    "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
    "        num_rows: 113\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb004f",
   "metadata": {},
   "source": [
    "\n",
    "è™½ç„¶æ•°æ®é›†ä¸­åŒ…å«äº†å¾ˆå¤šæœ‰ç”¨çš„ä¿¡æ¯ï¼Œå¦‚ `lang_id` å’Œ `english_transcription`ï¼Œä½†åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨ `audio` å’Œ `intent_class`ã€‚ä½¿ç”¨ [remove_columns](https://huggingface.co/docs/datasets/v3.0.2/en/package_reference/main_classes#datasets.Dataset.remove_columns) æ–¹æ³•ç§»é™¤å…¶ä»–åˆ—ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c14374",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.remove_columns([\"path\", \"transcription\", \"english_transcription\", \"lang_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8cf9b2",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨æŸ¥çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047453c",
   "metadata": {},
   "source": [
    "\n",
    "è¾“å‡ºï¼š"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b94915f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{\n",
    "    'audio': {\n",
    "        'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00048828,\n",
    "         -0.00024414, -0.00024414], dtype=float32),\n",
    "        'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',\n",
    "        'sampling_rate': 8000\n",
    "    },\n",
    "    'intent_class': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42804560",
   "metadata": {},
   "source": [
    "\n",
    "è¿™é‡Œæœ‰ä¸¤ä¸ªå­—æ®µï¼š\n",
    "\n",
    "- `audio`ï¼šä¸€ç»´ `array` çš„è¯­éŸ³ä¿¡å·ï¼Œéœ€è¦è°ƒç”¨æ¥åŠ è½½å’Œé‡é‡‡æ ·éŸ³é¢‘æ–‡ä»¶ã€‚\n",
    "- `intent_class`ï¼šè¡¨ç¤ºè¯´è¯äººæ„å›¾çš„ç±»åˆ« IDã€‚\n",
    "\n",
    "ä¸ºäº†æ–¹ä¾¿æ¨¡å‹ä»æ ‡ç­¾ ID è·å–æ ‡ç­¾åç§°ï¼Œåˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œå°†æ ‡ç­¾åç§°æ˜ å°„åˆ°æ•´æ•°ï¼Œåä¹‹äº¦ç„¶ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = minds[\"train\"].features[\"intent_class\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa1877",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨ä½ å¯ä»¥å°†æ ‡ç­¾ ID è½¬æ¢ä¸ºæ ‡ç­¾åç§°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe76e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label[str(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006021ba",
   "metadata": {},
   "source": [
    "\n",
    "è¾“å‡ºï¼š"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec2c7dde",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "'app_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2a446",
   "metadata": {},
   "source": [
    "\n",
    "## é¢„å¤„ç†\n",
    "\n",
    "ä¸‹ä¸€æ­¥æ˜¯åŠ è½½ä¸€ä¸ª Wav2Vec2 ç‰¹å¾æå–å™¨æ¥å¤„ç†éŸ³é¢‘ä¿¡å·ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325e964",
   "metadata": {},
   "source": [
    "\n",
    "MInDS-14 æ•°æ®é›†çš„é‡‡æ ·ç‡ä¸º 8000Hzï¼ˆä½ å¯ä»¥åœ¨å…¶ [æ•°æ®é›†å¡ç‰‡](https://huggingface.co/datasets/PolyAI/minds14) ä¸­æ‰¾åˆ°è¿™äº›ä¿¡æ¯ï¼‰ï¼Œè¿™æ„å‘³ç€ä½ éœ€è¦å°†æ•°æ®é›†é‡é‡‡æ ·åˆ° 16000Hz ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„ Wav2Vec2 æ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5fbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "minds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed1279",
   "metadata": {},
   "source": [
    "\n",
    "è¾“å‡ºï¼š"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0266625b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{\n",
    "    'audio': {\n",
    "        'array': array([ 2.2098757e-05,  4.6582241e-05, -2.2803260e-05, ...,\n",
    "         -2.8419291e-04, -2.3305941e-04, -1.1425107e-04], dtype=float32),\n",
    "        'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',\n",
    "        'sampling_rate': 16000\n",
    "    },\n",
    "    'intent_class': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc587c",
   "metadata": {},
   "source": [
    "\n",
    "ç°åœ¨åˆ›å»ºä¸€ä¸ªé¢„å¤„ç†å‡½æ•°ï¼Œè¯¥å‡½æ•°ï¼š\n",
    "\n",
    "1. è°ƒç”¨ `audio` åˆ—æ¥åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼Œå¹¶åœ¨å¿…è¦æ—¶é‡é‡‡æ ·ã€‚\n",
    "2. æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶çš„é‡‡æ ·ç‡æ˜¯å¦ä¸æ¨¡å‹é¢„è®­ç»ƒæ—¶çš„é‡‡æ ·ç‡åŒ¹é…ã€‚ä½ å¯ä»¥åœ¨ Wav2Vec2 çš„ [æ¨¡å‹å¡ç‰‡](https://huggingface.co/facebook/wav2vec2-base) ä¸­æ‰¾åˆ°è¿™äº›ä¿¡æ¯ã€‚\n",
    "3. è®¾ç½®æœ€å¤§è¾“å…¥é•¿åº¦ï¼Œä»¥ä¾¿åœ¨ä¸æˆªæ–­çš„æƒ…å†µä¸‹æ‰¹é‡å¤„ç†è¾ƒé•¿çš„è¾“å…¥ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b83661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa3236",
   "metadata": {},
   "source": [
    "\n",
    "ä¸ºäº†åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨é¢„å¤„ç†å‡½æ•°ï¼Œä½¿ç”¨ ğŸ¤— Datasets çš„ [map](https://huggingface.co/docs/datasets/v3.0.2/en/package_reference/main_classes#datasets.Dataset.map) å‡½æ•°ã€‚é€šè¿‡è®¾ç½® `batched=True` å¯ä»¥åŠ å¿« `map` çš„é€Ÿåº¦ï¼Œä»¥ä¾¿ä¸€æ¬¡å¤„ç†å¤šä¸ªæ•°æ®é›†å…ƒç´ ã€‚ç§»é™¤ä¸éœ€è¦çš„åˆ—ï¼Œå¹¶å°† `intent_class` é‡å‘½åä¸º `label`ï¼Œå› ä¸ºè¿™æ˜¯æ¨¡å‹æœŸæœ›çš„åç§°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_minds = minds.map(preprocess_function, remove_columns=\"audio\", batched=True)\n",
    "encoded_minds = encoded_minds.rename_column(\"intent_class\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29baaf1d",
   "metadata": {},
   "source": [
    "\n",
    "## è¯„ä¼°\n",
    "\n",
    "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒ…å«ä¸€ä¸ªè¯„ä¼°æŒ‡æ ‡é€šå¸¸æœ‰åŠ©äºè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚ä½ å¯ä»¥ä½¿ç”¨ ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) åº“å¿«é€ŸåŠ è½½è¯„ä¼°æ–¹æ³•ã€‚å¯¹äºæ­¤ä»»åŠ¡ï¼ŒåŠ è½½ [å‡†ç¡®ç‡](https://huggingface.co/spaces/evaluate-metric/accuracy) æŒ‡æ ‡ï¼ˆæœ‰å…³å¦‚ä½•åŠ è½½å’Œè®¡ç®—æŒ‡æ ‡çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… ğŸ¤— Evaluate çš„ [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/evaluate/a_quick_tour)ï¼‰ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed858c",
   "metadata": {},
   "source": [
    "\n",
    "ç„¶ååˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå°†é¢„æµ‹å€¼å’Œæ ‡ç­¾ä¼ é€’ç»™ `compute` ä»¥è®¡ç®—å‡†ç¡®ç‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f55571",
   "metadata": {},
   "source": [
    "\n",
    "ä½ ç°åœ¨å·²ç»å‡†å¤‡å¥½äº† `compute_metrics` å‡½æ•°ï¼Œç¨ååœ¨è®¾ç½®è®­ç»ƒæ—¶ä¼šç”¨åˆ°å®ƒã€‚\n",
    "\n",
    "## è®­ç»ƒ\n",
    "\n",
    "å¦‚æœä½ ä¸ç†Ÿæ‚‰ä½¿ç”¨ [Trainer](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer) å¾®è°ƒæ¨¡å‹ï¼Œè¯·å‚è€ƒ [è¿™é‡Œ](../training#train-with-pytorch-trainer) çš„åŸºæœ¬æ•™ç¨‹ï¼\n",
    "\n",
    "ä½ ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ï¼ä½¿ç”¨ [AutoModelForAudioClassification](/docs/transformers/v4.46.0/en/model_doc/auto#transformers.AutoModelForAudioClassification) åŠ è½½ Wav2Vec2ï¼Œå¹¶æŒ‡å®šé¢„æœŸçš„æ ‡ç­¾æ•°é‡å’Œæ ‡ç­¾æ˜ å°„ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ddd384",
   "metadata": {},
   "source": [
    "\n",
    "æ­¤æ—¶åªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "1. åœ¨ [TrainingArguments](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.TrainingArguments) ä¸­å®šä¹‰è®­ç»ƒè¶…å‚æ•°ã€‚å”¯ä¸€å¿…éœ€çš„å‚æ•°æ˜¯ `output_dir`ï¼Œå®ƒæŒ‡å®šäº†ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚é€šè¿‡è®¾ç½® `push_to_hub=True` å¯ä»¥å°†æ¨¡å‹æ¨é€åˆ° Hubï¼ˆéœ€è¦ç™»å½• Hugging Face æ‰èƒ½ä¸Šä¼ æ¨¡å‹ï¼‰ã€‚æ¯ä¸ª epoch ç»“æŸæ—¶ï¼Œ[Trainer](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer) å°†è¯„ä¼°å‡†ç¡®ç‡å¹¶ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚\n",
    "2. å°†è®­ç»ƒå‚æ•°ä¼ é€’ç»™ [Trainer](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer)ï¼Œå¹¶ä¼ å…¥æ¨¡å‹ã€æ•°æ®é›†ã€åˆ†è¯å™¨ã€æ•°æ®æ”¶é›†å™¨å’Œ `compute_metrics` å‡½æ•°ã€‚\n",
    "3. è°ƒç”¨ [train()](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer.train) æ¥å¾®è°ƒæ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_mind_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_minds[\"train\"],\n",
    "    eval_dataset=encoded_minds[\"test\"],\n",
    "    processing_class=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b97d2",
   "metadata": {},
   "source": [
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ [push_to_hub()](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer.push_to_hub) æ–¹æ³•å°†æ¨¡å‹æ¨é€åˆ° Hubï¼Œä»¥ä¾¿æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨ä½ çš„æ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d882a",
   "metadata": {},
   "source": [
    "\n",
    "æœ‰å…³å¦‚ä½•å¾®è°ƒæ¨¡å‹è¿›è¡ŒéŸ³é¢‘åˆ†ç±»çš„æ›´è¯¦ç»†ç¤ºä¾‹ï¼Œè¯·å‚é˜…ç›¸åº”çš„ [PyTorch ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)ã€‚\n",
    "\n",
    "## æ¨ç†\n",
    "\n",
    "å¾ˆå¥½ï¼Œç°åœ¨ä½ å·²ç»å¾®è°ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†äº†ï¼\n",
    "\n",
    "åŠ è½½ä¸€ä¸ªä½ æƒ³è¿›è¡Œæ¨ç†çš„éŸ³é¢‘æ–‡ä»¶ã€‚å¦‚æœéœ€è¦ï¼Œè®°å¾—å°†éŸ³é¢‘æ–‡ä»¶çš„é‡‡æ ·ç‡è°ƒæ•´ä¸ºæ¨¡å‹çš„é‡‡æ ·ç‡ï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52608cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "audio_file = dataset[0][\"audio\"][\"path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8afa32",
   "metadata": {},
   "source": [
    "\n",
    "æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨ [pipeline()](/docs/transformers/v4.46.0/en/main_classes/pipelines#transformers.pipeline) è¿›è¡Œæ¨ç†ã€‚å®ä¾‹åŒ–ä¸€ä¸ªç”¨äºéŸ³é¢‘åˆ†ç±»çš„ `pipeline`ï¼Œå¹¶å°†ä½ çš„éŸ³é¢‘æ–‡ä»¶ä¼ é€’ç»™å®ƒï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62471c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"audio-classification\", model=\"stevhliu/my_awesome_minds_model\")\n",
    "classifier(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054410e",
   "metadata": {},
   "source": [
    "\n",
    "è¾“å‡ºï¼š"
   ]
  },
  {
   "cell_type": "raw",
   "id": "428fbb4e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "[\n",
    "    {'score': 0.09766869246959686, 'label': 'cash_deposit'},\n",
    "    {'score': 0.07998877018690109, 'label': 'app_error'},\n",
    "    {'score': 0.0781070664525032, 'label': 'joint_account'},\n",
    "    {'score': 0.07667109370231628, 'label': 'pay_bill'},\n",
    "    {'score': 0.0755252093076706, 'label': 'balance'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bd144",
   "metadata": {},
   "source": [
    "\n",
    "ä½ ä¹Ÿå¯ä»¥æ‰‹åŠ¨å¤åˆ¶ `pipeline` çš„ç»“æœï¼š\n",
    "\n",
    "åŠ è½½ä¸€ä¸ªç‰¹å¾æå–å™¨æ¥é¢„å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼Œå¹¶è¿”å› `input` ä½œä¸º PyTorch å¼ é‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdfe7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"stevhliu/my_awesome_minds_model\")\n",
    "inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b84e90",
   "metadata": {},
   "source": [
    "\n",
    "å°†è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å¹¶è¿”å› logitsï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"stevhliu/my_awesome_minds_model\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67251130",
   "metadata": {},
   "source": [
    "\n",
    "è·å–æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ï¼Œå¹¶ä½¿ç”¨æ¨¡å‹çš„ `id2label` æ˜ å°„å°†å…¶è½¬æ¢ä¸ºæ ‡ç­¾ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "predicted_class_ids = torch.argmax(logits).item()\n",
    "predicted_label = model.config.id2label[predicted_class_ids]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135cf3d",
   "metadata": {},
   "source": [
    "\n",
    "è¾“å‡ºï¼š"
   ]
  },
  {
   "cell_type": "raw",
   "id": "579a4ec1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "'cash_deposit'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
