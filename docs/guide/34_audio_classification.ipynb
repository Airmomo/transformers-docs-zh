{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f14f358",
   "metadata": {},
   "source": [
    "# 音频分类\n",
    "\n",
    "音频分类与文本分类类似，都是从输入数据中分配一个类别标签。不同之处在于，音频分类处理的是原始音频波形，而不是文本。音频分类的一些实际应用包括识别说话人的意图、语言分类，甚至是通过声音识别动物种类。\n",
    "\n",
    "本指南将向你展示如何：\n",
    "\n",
    "1. 在 [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) 数据集上微调 [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) 模型，以分类说话人的意图。\n",
    "2. 使用微调后的模型进行推理。\n",
    "\n",
    "要查看与此任务兼容的所有架构和检查点，建议查阅 [任务页面](https://huggingface.co/tasks/audio-classification)。\n",
    "\n",
    "在开始之前，请确保你已经安装了所有必要的库：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4747b21a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705b004",
   "metadata": {},
   "source": [
    "\n",
    "我们鼓励你登录你的 Hugging Face 账户，以便你可以上传并分享你的模型。当提示你时，输入你的令牌来登录：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5923a5",
   "metadata": {},
   "source": [
    "\n",
    "## 加载 MInDS-14 数据集\n",
    "\n",
    "首先从 🤗 Datasets 库加载 MInDS-14 数据集：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647eb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bf3a8",
   "metadata": {},
   "source": [
    "\n",
    "使用 [train_test_split](https://huggingface.co/docs/datasets/v3.0.2/en/package_reference/main_classes#datasets.Dataset.train_test_split) 方法将数据集的 `train` 分割成较小的训练集和测试集。这可以让你在实验和确保一切正常工作之前，不必花费太多时间在完整数据集上。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a93a2a",
   "metadata": {},
   "source": [
    "\n",
    "然后查看数据集：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7fb34",
   "metadata": {},
   "source": [
    "\n",
    "输出："
   ]
  },
  {
   "cell_type": "raw",
   "id": "a24519af",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
    "        num_rows: 450\n",
    "    })\n",
    "    test: Dataset({\n",
    "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
    "        num_rows: 113\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb004f",
   "metadata": {},
   "source": [
    "\n",
    "虽然数据集中包含了很多有用的信息，如 `lang_id` 和 `english_transcription`，但在本指南中，我们将重点关注 `audio` 和 `intent_class`。使用 [remove_columns](https://huggingface.co/docs/datasets/v3.0.2/en/package_reference/main_classes#datasets.Dataset.remove_columns) 方法移除其他列：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c14374",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.remove_columns([\"path\", \"transcription\", \"english_transcription\", \"lang_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8cf9b2",
   "metadata": {},
   "source": [
    "\n",
    "现在查看一个示例：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047453c",
   "metadata": {},
   "source": [
    "\n",
    "输出："
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b94915f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{\n",
    "    'audio': {\n",
    "        'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00048828,\n",
    "         -0.00024414, -0.00024414], dtype=float32),\n",
    "        'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',\n",
    "        'sampling_rate': 8000\n",
    "    },\n",
    "    'intent_class': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42804560",
   "metadata": {},
   "source": [
    "\n",
    "这里有两个字段：\n",
    "\n",
    "- `audio`：一维 `array` 的语音信号，需要调用来加载和重采样音频文件。\n",
    "- `intent_class`：表示说话人意图的类别 ID。\n",
    "\n",
    "为了方便模型从标签 ID 获取标签名称，创建一个字典，将标签名称映射到整数，反之亦然：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = minds[\"train\"].features[\"intent_class\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa1877",
   "metadata": {},
   "source": [
    "\n",
    "现在你可以将标签 ID 转换为标签名称：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe76e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label[str(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006021ba",
   "metadata": {},
   "source": [
    "\n",
    "输出："
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec2c7dde",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "'app_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2a446",
   "metadata": {},
   "source": [
    "\n",
    "## 预处理\n",
    "\n",
    "下一步是加载一个 Wav2Vec2 特征提取器来处理音频信号：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325e964",
   "metadata": {},
   "source": [
    "\n",
    "MInDS-14 数据集的采样率为 8000Hz（你可以在其 [数据集卡片](https://huggingface.co/datasets/PolyAI/minds14) 中找到这些信息），这意味着你需要将数据集重采样到 16000Hz 以使用预训练的 Wav2Vec2 模型：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5fbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "minds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed1279",
   "metadata": {},
   "source": [
    "\n",
    "输出："
   ]
  },
  {
   "cell_type": "raw",
   "id": "0266625b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{\n",
    "    'audio': {\n",
    "        'array': array([ 2.2098757e-05,  4.6582241e-05, -2.2803260e-05, ...,\n",
    "         -2.8419291e-04, -2.3305941e-04, -1.1425107e-04], dtype=float32),\n",
    "        'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',\n",
    "        'sampling_rate': 16000\n",
    "    },\n",
    "    'intent_class': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc587c",
   "metadata": {},
   "source": [
    "\n",
    "现在创建一个预处理函数，该函数：\n",
    "\n",
    "1. 调用 `audio` 列来加载音频文件，并在必要时重采样。\n",
    "2. 检查音频文件的采样率是否与模型预训练时的采样率匹配。你可以在 Wav2Vec2 的 [模型卡片](https://huggingface.co/facebook/wav2vec2-base) 中找到这些信息。\n",
    "3. 设置最大输入长度，以便在不截断的情况下批量处理较长的输入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b83661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa3236",
   "metadata": {},
   "source": [
    "\n",
    "为了在整个数据集上应用预处理函数，使用 🤗 Datasets 的 [map](https://huggingface.co/docs/datasets/v3.0.2/en/package_reference/main_classes#datasets.Dataset.map) 函数。通过设置 `batched=True` 可以加快 `map` 的速度，以便一次处理多个数据集元素。移除不需要的列，并将 `intent_class` 重命名为 `label`，因为这是模型期望的名称：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_minds = minds.map(preprocess_function, remove_columns=\"audio\", batched=True)\n",
    "encoded_minds = encoded_minds.rename_column(\"intent_class\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29baaf1d",
   "metadata": {},
   "source": [
    "\n",
    "## 评估\n",
    "\n",
    "在训练过程中包含一个评估指标通常有助于评估模型的性能。你可以使用 🤗 [Evaluate](https://huggingface.co/docs/evaluate/index) 库快速加载评估方法。对于此任务，加载 [准确率](https://huggingface.co/spaces/evaluate-metric/accuracy) 指标（有关如何加载和计算指标的更多信息，请参阅 🤗 Evaluate 的 [快速入门](https://huggingface.co/docs/evaluate/a_quick_tour)）：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed858c",
   "metadata": {},
   "source": [
    "\n",
    "然后创建一个函数，将预测值和标签传递给 `compute` 以计算准确率：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f55571",
   "metadata": {},
   "source": [
    "\n",
    "你现在已经准备好了 `compute_metrics` 函数，稍后在设置训练时会用到它。\n",
    "\n",
    "## 训练\n",
    "\n",
    "如果你不熟悉使用 [Trainer](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer) 微调模型，请参考 [这里](../training#train-with-pytorch-trainer) 的基本教程！\n",
    "\n",
    "你现在可以开始训练模型了！使用 [AutoModelForAudioClassification](/docs/transformers/v4.46.0/en/model_doc/auto#transformers.AutoModelForAudioClassification) 加载 Wav2Vec2，并指定预期的标签数量和标签映射：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ddd384",
   "metadata": {},
   "source": [
    "\n",
    "此时只剩下三个步骤：\n",
    "\n",
    "1. 在 [TrainingArguments](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.TrainingArguments) 中定义训练超参数。唯一必需的参数是 `output_dir`，它指定了保存模型的位置。通过设置 `push_to_hub=True` 可以将模型推送到 Hub（需要登录 Hugging Face 才能上传模型）。每个 epoch 结束时，[Trainer](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer) 将评估准确率并保存训练检查点。\n",
    "2. 将训练参数传递给 [Trainer](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer)，并传入模型、数据集、分词器、数据收集器和 `compute_metrics` 函数。\n",
    "3. 调用 [train()](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer.train) 来微调模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_mind_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_minds[\"train\"],\n",
    "    eval_dataset=encoded_minds[\"test\"],\n",
    "    processing_class=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b97d2",
   "metadata": {},
   "source": [
    "\n",
    "训练完成后，使用 [push_to_hub()](/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer.push_to_hub) 方法将模型推送到 Hub，以便每个人都可以使用你的模型：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d882a",
   "metadata": {},
   "source": [
    "\n",
    "有关如何微调模型进行音频分类的更详细示例，请参阅相应的 [PyTorch 笔记本](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)。\n",
    "\n",
    "## 推理\n",
    "\n",
    "很好，现在你已经微调了一个模型，可以使用它进行推理了！\n",
    "\n",
    "加载一个你想进行推理的音频文件。如果需要，记得将音频文件的采样率调整为模型的采样率！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52608cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "audio_file = dataset[0][\"audio\"][\"path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8afa32",
   "metadata": {},
   "source": [
    "\n",
    "最简单的方法是使用 [pipeline()](/docs/transformers/v4.46.0/en/main_classes/pipelines#transformers.pipeline) 进行推理。实例化一个用于音频分类的 `pipeline`，并将你的音频文件传递给它：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62471c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"audio-classification\", model=\"stevhliu/my_awesome_minds_model\")\n",
    "classifier(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054410e",
   "metadata": {},
   "source": [
    "\n",
    "输出："
   ]
  },
  {
   "cell_type": "raw",
   "id": "428fbb4e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "[\n",
    "    {'score': 0.09766869246959686, 'label': 'cash_deposit'},\n",
    "    {'score': 0.07998877018690109, 'label': 'app_error'},\n",
    "    {'score': 0.0781070664525032, 'label': 'joint_account'},\n",
    "    {'score': 0.07667109370231628, 'label': 'pay_bill'},\n",
    "    {'score': 0.0755252093076706, 'label': 'balance'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bd144",
   "metadata": {},
   "source": [
    "\n",
    "你也可以手动复制 `pipeline` 的结果：\n",
    "\n",
    "加载一个特征提取器来预处理音频文件，并返回 `input` 作为 PyTorch 张量：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdfe7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"stevhliu/my_awesome_minds_model\")\n",
    "inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b84e90",
   "metadata": {},
   "source": [
    "\n",
    "将输入传递给模型并返回 logits：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"stevhliu/my_awesome_minds_model\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67251130",
   "metadata": {},
   "source": [
    "\n",
    "获取概率最高的类别，并使用模型的 `id2label` 映射将其转换为标签：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "predicted_class_ids = torch.argmax(logits).item()\n",
    "predicted_label = model.config.id2label[predicted_class_ids]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135cf3d",
   "metadata": {},
   "source": [
    "\n",
    "输出："
   ]
  },
  {
   "cell_type": "raw",
   "id": "579a4ec1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "'cash_deposit'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
