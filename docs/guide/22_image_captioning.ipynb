{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba73147",
   "metadata": {},
   "source": [
    "# 图像描述生成\n",
    "\n",
    "图像描述生成（Image Captioning）是指为给定图像生成描述性文字的任务。它在现实世界中的应用包括帮助视障人士在不同情境中导航。因此，图像描述生成通过为人们描述图像，提高了内容的可访问性。\n",
    "\n",
    "本指南将展示如何：\n",
    "\n",
    "* 微调一个图像描述生成模型。\n",
    "* 使用微调后的模型进行推理。\n",
    "\n",
    "在开始之前，请确保安装了所有必要的库：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e7c6f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate -q\n",
    "pip install jiwer -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece9377a",
   "metadata": {},
   "source": [
    "\n",
    "我们鼓励您登录您的 Hugging Face 账户，以便上传并与社区分享您的模型。当提示时，输入您的令牌以登录：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e208c",
   "metadata": {},
   "source": [
    "\n",
    "## 加载 Pokémon BLIP 描述数据集\n",
    "\n",
    "使用 🤗 Dataset 库加载一个包含 {图像-描述} 对的数据集。要创建您自己的 PyTorch 图像描述生成数据集，可以参考[这个笔记本](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/GIT/Fine_tune_GIT_on_an_image_captioning_dataset.ipynb)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48307f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"lambdalabs/pokemon-blip-captions\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7172c0a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['image', 'text'],\n",
    "        num_rows: 833\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07de23d",
   "metadata": {},
   "source": [
    "\n",
    "数据集有两个特征：`image` 和 `text`。\n",
    "\n",
    "许多图像描述生成数据集为每张图像包含多个描述。在这种情况下，常见的策略是在训练过程中从可用的描述中随机采样一个。\n",
    "\n",
    "使用 [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) 方法将数据集的训练部分分为训练集和测试集：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[\"train\"].train_test_split(test_size=0.1)\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab5d94",
   "metadata": {},
   "source": [
    "\n",
    "让我们可视化训练集中的几个样本。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa406137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_images(images, captions):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(1, len(images), i + 1)\n",
    "        caption = captions[i]\n",
    "        caption = \"\\n\".join(wrap(caption, 12))\n",
    "        plt.title(caption)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "sample_images_to_visualize = [np.array(train_ds[i][\"image\"]) for i in range(5)]\n",
    "sample_captions = [train_ds[i][\"text\"] for i in range(5)]\n",
    "plot_images(sample_images_to_visualize, sample_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a0265",
   "metadata": {},
   "source": [
    "\n",
    "![样本训练图像](../../resources/images/sample_training_images_image_cap.png)\n",
    "\n",
    "## 预处理数据集\n",
    "\n",
    "由于数据集有两种模态（图像和文本），预处理流程将分别处理图像和描述。\n",
    "\n",
    "为此，加载与您即将微调的模型相关联的处理器类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "checkpoint = \"microsoft/git-base\"\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f6945",
   "metadata": {},
   "source": [
    "\n",
    "处理器将内部预处理图像（包括调整大小和像素缩放）并对描述进行分词。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7657f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(example_batch):\n",
    "    images = [x for x in example_batch[\"image\"]]\n",
    "    captions = [x for x in example_batch[\"text\"]]\n",
    "    inputs = processor(images=images, text=captions, padding=\"max_length\")\n",
    "    inputs.update({\"labels\": inputs[\"input_ids\"]})\n",
    "    return inputs\n",
    "\n",
    "train_ds.set_transform(transforms)\n",
    "test_ds.set_transform(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0b5fa",
   "metadata": {},
   "source": [
    "\n",
    "数据集准备好后，您可以设置模型进行微调。\n",
    "\n",
    "## 加载基础模型\n",
    "\n",
    "将 [\"microsoft/git-base\"](https://huggingface.co/microsoft/git-base) 加载到 [`AutoModelForCausalLM`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM) 对象中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3372da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a439c78",
   "metadata": {},
   "source": [
    "\n",
    "## 评估\n",
    "\n",
    "图像描述生成模型通常使用 [Rouge Score](https://huggingface.co/spaces/evaluate-metric/rouge) 或 [Word Error Rate](https://huggingface.co/spaces/evaluate-metric/wer) 进行评估。在本指南中，您将使用 Word Error Rate (WER)。\n",
    "\n",
    "我们使用 🤗 Evaluate 库来进行评估。关于 WER 的潜在限制和其他注意事项，请参考[这个指南](https://huggingface.co/spaces/evaluate-metric/wer)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5886755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "wer = load(\"wer\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predicted = logits.argmax(-1)\n",
    "    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=True)\n",
    "    wer_score = wer.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "    return {\"wer_score\": wer_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7cff2e",
   "metadata": {},
   "source": [
    "\n",
    "## 训练！\n",
    "\n",
    "现在，您已准备好开始微调模型。您将使用 🤗 [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) 进行此操作。\n",
    "\n",
    "首先，使用 [TrainingArguments](/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) 定义训练参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef32734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_name = checkpoint.split(\"/\")[1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-pokemon\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=50,\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=2,\n",
    "    save_total_limit=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    logging_steps=50,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=True,\n",
    "    label_names=[\"labels\"],\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4bf2d9",
   "metadata": {},
   "source": [
    "\n",
    "然后将它们与数据集和模型一起传递给 🤗 Trainer。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e9a38",
   "metadata": {},
   "source": [
    "\n",
    "要开始训练，只需在 [Trainer](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) 对象上调用 [train()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f176eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378cf9cc",
   "metadata": {},
   "source": [
    "\n",
    "您应该看到训练损失随着训练的进行而平稳下降。\n",
    "\n",
    "训练完成后，使用 [push_to_hub()](/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) 方法将您的模型分享到 Hub，以便所有人都可以使用您的模型：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef713ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9df50d",
   "metadata": {},
   "source": [
    "\n",
    "## 推理\n",
    "\n",
    "从 `test_ds` 中取一个样本图像来测试模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"https://huggingface.co/datasets/sayakpaul/sample-datasets/resolve/main/pokemon.png\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d3219",
   "metadata": {},
   "source": [
    "\n",
    "![测试图像](../../resources/images/test_image_image_cap.png)\n",
    "\n",
    "准备图像以供模型使用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c940b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "pixel_values = inputs.pixel_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de27f9e",
   "metadata": {},
   "source": [
    "\n",
    "调用 `generate` 并解码预测结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_caption)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6455cbe",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "a drawing of a pink and blue pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6a195b",
   "metadata": {},
   "source": [
    "从结果看来，微调后的模型生成了一个相当不错的描述！"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
