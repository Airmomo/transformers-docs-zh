{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本转语音 (Text-to-speech, TTS)\n",
    "\n",
    "文本转语音（TTS）是将文字转换成自然语音的任务，这种语音可以支持多种语言和多个说话者。目前，🤗 Transformers 中已经提供了多种文本转语音模型，比如 [Bark](https://huggingface.co/docs/transformers/main/en/model_doc/bark)、[MMS](https://huggingface.co/docs/transformers/main/en/model_doc/mms)、[VITS](https://huggingface.co/docs/transformers/main/en/model_doc/vits) 和 [SpeechT5](https://huggingface.co/docs/transformers/main/en/model_doc/speecht5)。\n",
    "\n",
    "你可以通过 `text-to-audio` pipeline（或者它的别名——`text-to-speech`）轻松生成音频。\n",
    "\n",
    "有些模型，比如 Bark 还可以生成非语言语音，比如笑声、叹息和哭泣，甚至可以添加音乐。下面是一个使用 Bark 进行“文本转语音”的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-to-speech\", model=\"suno/bark-small\")\n",
    "text = \"[clears throat] This is a test ... and I just took a long pause.\"\n",
    "output = pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有一个代码片段，你可以在 notebook 中运行它来试听生成的音频："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想了解更多关于 Bark 和其他预训练 TTS 模型的示例，请参考我们的[音频课程](https://huggingface.co/learn/audio-course/chapter6/pre-trained_models)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想要微调一个 TTS 模型，目前 🤗 Transformers 中可用的文本转语音模型只有 [SpeechT5](https://huggingface.co/docs/transformers/main/en/tasks/model_doc/speecht5) 和 [FastSpeech2Conformer](https://huggingface.co/docs/transformers/main/en/tasks/model_doc/fastspeech2_conformer)，不过未来会添加更多模型。\n",
    "\n",
    "SpeechT5 是在语音转文本和文本转语音数据的组合上进行预训练的，这使得它能够学习一个统一的隐含表示空间，这个空间由文本和语音共享。这意味着同一个预训练模型可以针对不同任务进行微调。此外，SpeechT5 通过 `x-vector` 说话者嵌入支持多个说话者。\n",
    "\n",
    "本指南的其余部分将展示如何：\n",
    "\n",
    "1. 将原本在英语语音上训练的 [SpeechT5](https://huggingface.co/docs/transformers/main/en/model_doc/speecht5) 微调到 [VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli) 数据集的荷兰语（nl）子集上。\n",
    "2. 使用你微调后的模型进行推理，有两种方法：使用 pipeline 或直接使用。\n",
    "\n",
    "在开始之前，请确保你已经安装了所有必要的库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install datasets soundfile speechbrain accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要从源代码安装 🤗Transformers，因为并非所有 SpeechT5 的功能都已合并到官方版本中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若要按照本指南操作，你还需要一个 GPU。如果你在 notebook 中工作，运行以下命令来检查是否有可用的 GPU："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 AMD GPU，可以使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!rocm-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们鼓励你登录你的 Hugging Face 账户，以便上传并与社区分享你的模型。当提示时，输入你的令牌进行登录："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集\n",
    "\n",
    "[VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli) 是一个大规模的多语种语音语料库，数据来源于2009-2020年欧洲议会活动录音。它包含15种欧洲语言的标记音频-转录数据。在本指南中，我们使用荷兰语子集，你也可以选择其他子集。\n",
    "\n",
    "请注意，VoxPopuli 或任何其他自动语音识别（ASR）数据集可能不是训练 TTS 模型的最佳选择。那些对 ASR 有益的特性，比如过多的背景噪音，在 TTS 中通常是不希望出现的。所以，找到高质量、多语种、多说话者的 TTS 数据集确实相当有挑战性。\n",
    "\n",
    "让我们加载数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"facebook/voxpopuli\", \"nl\", split=\"train\")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20968 个示例应该足够用于微调。SpeechT5 要求音频数据的采样率为 16 kHz，所以请确保数据集中的示例满足这一要求："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理数据\n",
    "\n",
    "首先，定义要使用的模型 checkpoint 并加载相应的处理器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor\n",
    "\n",
    "checkpoint = \"microsoft/speecht5_tts\"\n",
    "processor = SpeechT5Processor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为 SpeechT5 分词进行文本清理\n",
    "\n",
    "首先，清理文本数据。你需要使用处理器的分词器部分来处理文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集示例包含 `raw_text` 和 `normalized_text` 特征。在决定使用哪个特征作为文本输入时，考虑到 `SpeechT5` 的分词器没有用于数字的任何标记。在 `normalized_text` 中，数字被写成文本形式。因此，它更适合作为输入文本，我们建议使用 `normalized_text`。\n",
    "\n",
    "由于 `SpeechT5` 是在英语上训练的，它可能无法识别荷兰语数据集中的某些字符。如果保留原样，这些字符将被转换为 `<unk>` 标记。然而，在荷兰语中，某些字符如 `à` 用于强调音节。为了保留文本的意义，我们可以将这个字符替换为普通的 `a`。\n",
    "\n",
    "为了识别不支持的标记，使用 `SpeechT5Tokenizer` 提取数据集中的所有唯一字符，该分词器以字符作为标记。为此，编写 `extract_all_chars` 映射函数，将所有示例的转录文本连接成一个字符串，并将其转换为字符集合。确保在 `dataset.map()` 中设置 `batched=True` 和 `batch_size=-1`，以便所有转录文本一次性提供给映射函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"normalized_text\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "\n",
    "vocabs = dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=dataset.column_names,\n",
    ")\n",
    "\n",
    "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
    "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你有两套字符集：一套是数据集中的词汇，另一套是分词器中的词汇。\n",
    "\n",
    "为了识别数据集中任何不支持的字符，你可以取这两个集合的差集。结果集合将包含那些在数据集中但不在分词器中的字符，即不支持的字符集合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vocab - tokenizer_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了处理上一步中得到的不支持的字符，需要定义一个函数将这些字符映射到有效的标记。请注意，分词器中空格已经用 ▁ 替换，不需要单独处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = [\n",
    "    (\"à\", \"a\"),\n",
    "    (\"ç\", \"c\"),\n",
    "    (\"è\", \"e\"),\n",
    "    (\"ë\", \"e\"),\n",
    "    (\"í\", \"i\"),\n",
    "    (\"ï\", \"i\"),\n",
    "    (\"ö\", \"o\"),\n",
    "    (\"ü\", \"u\"),\n",
    "]\n",
    "\n",
    "\n",
    "def cleanup_text(inputs):\n",
    "    for src, dst in replacements:\n",
    "        inputs[\"normalized_text\"] = inputs[\"normalized_text\"].replace(src, dst)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "dataset = dataset.map(cleanup_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你已经处理了文本中的特殊字符（不支持的字符），接下来该将注意力转向音频数据了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说话者\n",
    "VoxPopuli 数据集包含多位说话者的语音，但数据集中有多少位说话者呢？\n",
    "\n",
    "为了确定这一点，我们可以统计具有独特特征的说话者的数量以及每位说话者为数据集贡献的示例数量。考虑到数据集中一共有 20,968 个示例，这些信息将帮助我们更好地理解说话者和示例在数据中的分布情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "speaker_counts = defaultdict(int)\n",
    "\n",
    "for speaker_id in dataset[\"speaker_id\"]:\n",
    "    speaker_counts[speaker_id] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过绘制直方图，你可以了解每位说话者有多少数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(speaker_counts.values(), bins=20)\n",
    "plt.ylabel(\"Speakers\")\n",
    "plt.xlabel(\"Examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直方图显示，数据集中大约三分之一的说话者拥有少于 100 个示例，而大约 10 位说话者拥有超过 500 个示例。\n",
    "\n",
    "为了提高训练效率并平衡数据集，我们可以将数据限制在拥有 100 到 400 个示例的说话者范围内。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_speaker(speaker_id):\n",
    "    return 100 <= speaker_counts[speaker_id] <= 400\n",
    "\n",
    "\n",
    "dataset = dataset.filter(select_speaker, input_columns=[\"speaker_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们检查一下还剩下多少位说话者："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dataset[\"speaker_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们看看还剩下多少个示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你现在大约有10,000 个示例，来自大约 40 位独特的说话者，这应该是足够的。\n",
    "\n",
    "请注意，如果示例较长，那些只有少量示例的说话者实际上可能会拥有更多的音频数据。然而，确定每位说话者的总音频量需要遍历整个数据集，这是一个比较耗时的过程，涉及加载和解码每个音频文件。因此，我们选择在这里跳过这一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说话者嵌入\n",
    "为了让 TTS 模型能够区分多位说话者，你需要为每个示例创建一个说话者嵌入。说话者嵌入是模型的额外输入，用于捕捉特定说话者的声音特征。\n",
    "\n",
    "为了生成这些说话者嵌入，这里使用 `SpeechBrain` 的预训练模型 [spkrec-xvect-voxceleb](https://huggingface.co/speechbrain/spkrec-xvect-voxceleb)。\n",
    "\n",
    "创建一个函数 `create_speaker_embedding()`，它接受一个输入音频波形，并输出一个包含相应说话者嵌入的 512 元素向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from speechbrain.inference.classifiers import EncoderClassifier\n",
    "\n",
    "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "speaker_model = EncoderClassifier.from_hparams(\n",
    "    source=spk_model_name,\n",
    "    run_opts={\"device\": device},\n",
    "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
    ")\n",
    "\n",
    "\n",
    "def create_speaker_embedding(waveform):\n",
    "    with torch.no_grad():\n",
    "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
    "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
    "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
    "    return speaker_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，`speechbrain/spkrec-xvect-voxceleb` 模型是在 `VoxCeleb` 数据集的英语语音上训练的，而本指南中的训练示例是荷兰语。尽管我们相信这个模型仍能为我们的荷兰语数据集生成合理的说话者嵌入，但这种假设在所有情况下可能并不成立。\n",
    "\n",
    "为了获得最佳结果，我们建议首先在目标语音上训练一个 `X-vector` 模型。这将确保模型能够更好地捕捉荷兰语中独特的声音特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据集"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
