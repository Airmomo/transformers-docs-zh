{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8624968a",
   "metadata": {},
   "source": [
    "# 将模型导出至 TFLite\n",
    "\n",
    "[TensorFlow Lite](https://www.tensorflow.org/lite/guide) 是一个轻量级框架，用于在资源受限的设备（如手机、嵌入式系统和物联网设备）上部署机器学习模型。TFLite 设计的目的是在这些计算能力、内存和功耗有限的设备上高效地优化和运行模型。TensorFlow Lite 模型以一种特殊的高效便携格式表示，文件扩展名为 `.tflite`。\n",
    "\n",
    "🤗 Optimum 提供了将 🤗 Transformers 模型导出到 TFLite 的功能，通过 `exporters.tflite` 模块实现。支持的模型架构列表请参阅 [🤗 Optimum 文档](https://huggingface.co/docs/optimum/exporters/tflite/overview)。\n",
    "\n",
    "要将模型导出到 TFLite，请安装所需的依赖项：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496c426",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install optimum[exporters-tf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262f218",
   "metadata": {},
   "source": [
    "\n",
    "要查看所有可用的参数，可以参考 [🤗 Optimum 文档](https://huggingface.co/docs/optimum/main/en/exporters/tflite/usage_guides/export_a_model)，或在命令行中查看帮助信息：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897883a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "optimum-cli export tflite --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84782893",
   "metadata": {},
   "source": [
    "\n",
    "例如，要从 🤗 Hub 导出 `google-bert/bert-base-uncased` 模型的检查点，可以运行以下命令：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb2d9a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "optimum-cli export tflite --model google-bert/bert-base-uncased --sequence_length 128 bert_tflite/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f55644",
   "metadata": {},
   "source": [
    "\n",
    "你应该会看到日志显示进度，并指出生成的 `model.tflite` 文件保存的位置，如下所示：\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15d1cb88",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "验证 TFLite 模型...\n",
    "  - [✓] TFLite 模型输出名称与参考模型匹配 (logits)\n",
    "  - 验证 TFLite 模型输出 \"logits\":\n",
    "    - [✓] (1, 128, 30522) 匹配 (1, 128, 30522)\n",
    "    - [x] 值不足够接近，最大差异：5.817413330078125e-05 (atol: 1e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac125c66",
   "metadata": {},
   "source": [
    "\n",
    "导出成功，但有警告：参考模型和 TFLite 导出模型的输出之间的最大绝对差异不在设定的容差范围内 1e-05：\n",
    "- logits: 最大差异 = 5.817413330078125e-05。\n",
    "导出的模型已保存在：bert_tflite\n",
    "\n",
    "上述示例展示了如何从 🤗 Hub 导出模型。如果要导出本地模型，首先确保模型的权重和分词器文件都保存在同一目录下（`local_path`）。使用 CLI 时，将 `local_path` 传递给 `model` 参数，而不是 🤗 Hub 上的检查点名称。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
