{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf4f6c8",
   "metadata": {},
   "source": [
    "# Tiktoken 与 Transformers 的交互\n",
    "\n",
    "在加载模型时，🤗 Transformers 无缝支持 tiktoken 模型文件。当你从 Hub 加载带有 `tokenizer.model` tiktoken 文件的模型（通过 `from_pretrained` 方法）时，该文件会自动转换为我们的 [快速分词器](https://huggingface.co/docs/transformers/main/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)。\n",
    "\n",
    "### 已知发布带有 tiktoken.model 的模型：\n",
    "\n",
    "* gpt2\n",
    "* llama3\n",
    "\n",
    "## 示例用法\n",
    "\n",
    "为了在 `transformers` 中加载 `tiktoken` 文件，请确保 `tokenizer.model` 文件是一个 tiktoken 文件，它会在加载 `from_pretrained` 时自动加载。以下是如何加载分词器和模型的示例，这两个对象可以从同一个文件中加载：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, subfolder=\"original\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
