{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf4f6c8",
   "metadata": {},
   "source": [
    "# Tiktoken ä¸ Transformers çš„äº¤äº’\n",
    "\n",
    "åœ¨åŠ è½½æ¨¡å‹æ—¶ï¼ŒğŸ¤— Transformers æ— ç¼æ”¯æŒ tiktoken æ¨¡å‹æ–‡ä»¶ã€‚å½“ä½ ä» Hub åŠ è½½å¸¦æœ‰ `tokenizer.model` tiktoken æ–‡ä»¶çš„æ¨¡å‹ï¼ˆé€šè¿‡ `from_pretrained` æ–¹æ³•ï¼‰æ—¶ï¼Œè¯¥æ–‡ä»¶ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºæˆ‘ä»¬çš„ [å¿«é€Ÿåˆ†è¯å™¨](https://huggingface.co/docs/transformers/main/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)ã€‚\n",
    "\n",
    "### å·²çŸ¥å‘å¸ƒå¸¦æœ‰ tiktoken.model çš„æ¨¡å‹ï¼š\n",
    "\n",
    "* gpt2\n",
    "* llama3\n",
    "\n",
    "## ç¤ºä¾‹ç”¨æ³•\n",
    "\n",
    "ä¸ºäº†åœ¨ `transformers` ä¸­åŠ è½½ `tiktoken` æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ `tokenizer.model` æ–‡ä»¶æ˜¯ä¸€ä¸ª tiktoken æ–‡ä»¶ï¼Œå®ƒä¼šåœ¨åŠ è½½ `from_pretrained` æ—¶è‡ªåŠ¨åŠ è½½ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹çš„ç¤ºä¾‹ï¼Œè¿™ä¸¤ä¸ªå¯¹è±¡å¯ä»¥ä»åŒä¸€ä¸ªæ–‡ä»¶ä¸­åŠ è½½ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, subfolder=\"original\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
