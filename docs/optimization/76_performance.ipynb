{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbf4441",
   "metadata": {},
   "source": [
    "# 性能优化概述(性能与扩展性)\n",
    "\n",
    "训练大型变压器模型并将其部署到生产环境中面临着各种挑战。在训练过程中，模型可能需要比可用的更多的 GPU 内存，或者表现出训练速度缓慢的问题。在部署阶段，模型可能难以处理生产环境中所需的吞吐量。\n",
    "\n",
    "本文档旨在帮助您克服这些挑战，并找到适用于您场景的最佳设置。指南分为训练和推理两部分，因为每部分都伴随着不同的挑战和解决方案。每个部分中，您会找到针对不同硬件配置的单独指南，例如单个 GPU 与多个 GPU 的训练或 CPU 与 GPU 的推理。\n",
    "\n",
    "请将本文档作为您的起点，进一步导航至符合您情况的方法。\n",
    "\n",
    "## 训练\n",
    "\n",
    "高效地训练大型变压器模型通常需要加速器，如 GPU 或 TPU。最常见的场景是您有一个单个 GPU。您可以应用的方法来提高单个 GPU 上的训练效率，也可以扩展到其他设置，如多 GPU。然而，也有一些特定于多 GPU 或 CPU 训练的技术。我们在单独的部分中进行了介绍。\n",
    "\n",
    "* [在单个 GPU 上高效训练的方法和工具](perf_train_gpu_one)：从这里开始，了解常见的方法，这些方法可以帮助优化 GPU 内存利用率、加快训练速度，或两者兼顾。\n",
    "* [多 GPU 训练部分](perf_train_gpu_many)：探索这一部分，了解适用于多 GPU 设置的进一步优化方法，如数据并行、张量并行和管道并行。\n",
    "* [CPU 训练部分](perf_train_cpu)：了解 CPU 上的混合精度训练。\n",
    "* [在多个 CPU 上高效训练](perf_train_cpu_many)：了解分布式 CPU 训练。\n",
    "* [使用 TensorFlow 在 TPU 上训练](perf_train_tpu_tf)：如果您是 TPU 新手，请参考这一部分，了解有关在 TPU 上训练和使用 XLA 的意见介绍。\n",
    "* [用于训练的自定义硬件](perf_hardware)：在构建自己的深度学习设备时，查找技巧和窍门。\n",
    "* [使用 Trainer API 进行超参数搜索](hpo_train)\n",
    "\n",
    "## 推理\n",
    "\n",
    "在生产环境中使用大型模型进行高效推理可能与训练它们一样具有挑战性。在以下部分中，我们将介绍如何在 CPU 和单个/多个 GPU 设置上运行推理。\n",
    "\n",
    "* [在单个 CPU 上进行推理](perf_infer_cpu)\n",
    "* [在单个 GPU 上进行推理](perf_infer_gpu_one)\n",
    "* [多 GPU 推理](perf_infer_gpu_multi)\n",
    "* [TensorFlow 模型的 XLA 集成](tf_xla)\n",
    "\n",
    "## 训练与推理\n",
    "\n",
    "在这里，您将找到适用于训练模型或运行推理的技术、技巧和窍门。\n",
    "\n",
    "* [实例化大型模型](big_models)\n",
    "* [解决性能问题](debugging)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
