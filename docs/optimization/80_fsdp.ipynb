{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84514481",
   "metadata": {},
   "source": [
    "# 完全分片数据并行 (Fully Sharded Data Parallel)\n",
    "\n",
    "[完全分片数据并行 (FSDP)](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/) 是一种数据并行方法，它将模型的参数、梯度和优化器状态分布在可用的 GPU（也称为工作进程或 _rank_）上。与 [DistributedDataParallel (DDP)](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html) 不同，FSDP 通过在每个 GPU 上复制模型来减少内存使用。这提高了 GPU 的内存效率，并允许你在更少的 GPU 上训练更大的模型。FSDP 集成了 Accelerate 库，这是一个用于轻松管理分布式环境中的训练的库，这意味着你可以在 [Trainer](/docs/transformers/v4.47.1/en/main_classes/trainer#transformers.Trainer) 类中使用它。\n",
    "\n",
    "在开始之前，请确保已安装 Accelerate 并且至少使用 PyTorch 2.1.0 或更新版本。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992eb7f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3ec1f",
   "metadata": {},
   "source": [
    "\n",
    "## FSDP 配置\n",
    "\n",
    "首先，运行以下命令以创建一个配置文件，用于设置你的训练环境。Accelerate 使用这个配置文件根据你在 `accelerate config` 中选择的训练选项自动设置正确的训练环境。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b2b1e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "accelerate config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346f057",
   "metadata": {},
   "source": [
    "\n",
    "当你运行 `accelerate config` 时，系统会提示你选择一系列选项来配置你的训练环境。本节介绍一些最重要的 FSDP 选项。要了解其他可用的 FSDP 选项，请查看 [fsdp_config](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments.fsdp_config) 参数。\n",
    "\n",
    "### 分片策略\n",
    "\n",
    "FSDP 提供了多种分片策略供你选择：\n",
    "\n",
    "- `FULL_SHARD` - 在工作进程中分片模型参数、梯度和优化器状态；选择 `1` 表示此选项\n",
    "- `SHARD_GRAD_OP` - 在工作进程中分片梯度和优化器状态；选择 `2` 表示此选项\n",
    "- `NO_SHARD` - 不分片任何内容（相当于 DDP）；选择 `3` 表示此选项\n",
    "- `HYBRID_SHARD` - 在每个工作进程中分片模型参数、梯度和优化器状态，每个工作进程也有完整副本；选择 `4` 表示此选项\n",
    "- `HYBRID_SHARD_ZERO2` - 在每个工作进程中分片梯度和优化器状态，每个工作进程也有完整副本；选择 `5` 表示此选项\n",
    "\n",
    "这是通过 `fsdp_sharding_strategy` 标志启用的。\n",
    "\n",
    "### CPU 卸载\n",
    "\n",
    "你还可以在不使用参数和梯度时将其卸载到 CPU，以节省更多 GPU 内存，帮助你适应大模型，即使 FSDP 也不足以支持。这是通过在运行 `accelerate config` 时设置 `fsdp_offload_params: true` 来启用的。\n",
    "\n",
    "### 包装策略\n",
    "\n",
    "FSDP 通过包装网络中的每一层来应用。通常情况下，包装是以嵌套方式应用的，每次前向传递后丢弃完整的权重，以便为下一层节省内存。最简单的实现方法是使用 _自动包装_ 策略，你不需要更改任何代码。你应该选择 `fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP` 以包装 Transformer 层，并选择 `fsdp_transformer_layer_cls_to_wrap` 以指定要包装的层（例如 `BertLayer`）。\n",
    "\n",
    "否则，你可以选择基于大小的包装策略，当某层的参数数量超过一定阈值时，FSDP 将应用于该层。这是通过设置 `fsdp_wrap_policy: SIZE_BASED_WRAP` 和 `min_num_param` 为所需的大小阈值来启用的。\n",
    "\n",
    "### 检查点\n",
    "\n",
    "应使用 `fsdp_state_dict_type: SHARDED_STATE_DICT` 保存中间检查点，因为当 CPU 卸载在 rank 0 上启用时，保存完整的状态字典会耗费大量时间，并且经常由于无限期挂起导致 `NCCL Timeout` 错误。你可以使用 [load_state](https://huggingface.co/docs/accelerate/v1.2.0/en/package_reference/accelerator#accelerate.Accelerator.load_state) 方法从分片状态字典中恢复训练。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1559c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包含检查点的目录\n",
    "accelerator.load_state(\"ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef8b00",
   "metadata": {},
   "source": [
    "\n",
    "然而，当训练结束时，你希望保存完整的状态字典，因为分片状态字典仅适用于 FSDP。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainer.is_fsdp_enabled:\n",
    "    trainer.accelerator.state.fsdp_plugin.set_state_dict_type(\"FULL_STATE_DICT\")\n",
    "\n",
    "trainer.save_model(script_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f4c00",
   "metadata": {},
   "source": [
    "\n",
    "### TPU\n",
    "\n",
    "[PyTorch XLA](https://pytorch.org/xla/release/2.1/index.html) 支持 TPU 的 FSDP 训练，可以通过修改 `accelerate config` 生成的 FSDP 配置文件来启用。除了上面指定的分片策略和包装选项，你还可以在文件中添加以下参数。\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62589b61",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "xla: True  # 必须设置为 True 以启用 PyTorch/XLA\n",
    "xla_fsdp_settings:  # FSDP 的 XLA 特定参数\n",
    "  xla_fsdp_grad_ckpt: True  # 使用梯度检查点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1d6d6",
   "metadata": {},
   "source": [
    "\n",
    "[`xla_fsdp_settings`](https://github.com/pytorch/xla/blob/2e6e183e0724818f137c8135b34ef273dea33318/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py#L128) 允许你为 FSDP 配置更多的 XLA 特定参数。\n",
    "\n",
    "## 启动训练\n",
    "\n",
    "一个示例 FSDP 配置文件可能如下所示：\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b7fe052",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "compute_environment: LOCAL_MACHINE\n",
    "debug: false\n",
    "distributed_type: FSDP\n",
    "downcast_bf16: 'no'\n",
    "fsdp_config:\n",
    "  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP\n",
    "  fsdp_backward_prefetch_policy: BACKWARD_PRE\n",
    "  fsdp_cpu_ram_efficient_loading: true\n",
    "  fsdp_forward_prefetch: false\n",
    "  fsdp_offload_params: true\n",
    "  fsdp_sharding_strategy: 1\n",
    "  fsdp_state_dict_type: SHARDED_STATE_DICT\n",
    "  fsdp_sync_module_states: true\n",
    "  fsdp_transformer_layer_cls_to_wrap: BertLayer\n",
    "  fsdp_use_orig_params: true\n",
    "machine_rank: 0\n",
    "main_training_function: main\n",
    "mixed_precision: bf16\n",
    "num_machines: 1\n",
    "num_processes: 2\n",
    "rdzv_backend: static\n",
    "same_network: true\n",
    "tpu_env: []\n",
    "tpu_use_cluster: false\n",
    "tpu_use_sudo: false\n",
    "use_cpu: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab5957",
   "metadata": {},
   "source": [
    "\n",
    "要启动训练，运行以下命令，它将自动使用你之前使用 `accelerate config` 创建的配置文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cf1c9",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "accelerate launch my-trainer-script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070153e8",
   "metadata": {},
   "source": [
    "\n",
    "你也可以显式指定 FSDP 配置：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a2f8c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "accelerate launch --fsdp=\"full shard\" --fsdp_config=\"path/to/fsdp_config/\" my-trainer-script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b57c170",
   "metadata": {},
   "source": [
    "\n",
    "## 下一步\n",
    "\n",
    "FSDP 是训练大规模模型的强大工具，特别是在你有多个 GPU 或 TPU 的情况下。通过分片模型参数、优化器和梯度状态，甚至在不活跃时将它们卸载到 CPU，FSDP 可以降低大规模训练的高成本。如果你希望了解更多，以下资源可能会有所帮助：\n",
    "\n",
    "- 跟随 Accelerate 的 [FSDP 详细指南](https://huggingface.co/docs/accelerate/usage_guides/fsdp)。\n",
    "- 阅读 [介绍 PyTorch 完全分片数据并行 (FSDP) API](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/) 博客文章。\n",
    "- 阅读 [使用 FSDP 在云 TPU 上扩展 PyTorch 模型](https://pytorch.org/blog/scaling-pytorch-models-on-cloud-tpus-with-fsdp/) 博客文章。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
