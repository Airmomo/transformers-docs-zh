{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361f05de",
   "metadata": {},
   "source": [
    "# å°†æ¨¡å‹å¯¼å‡ºä¸º ONNX æ ¼å¼\n",
    "\n",
    "åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½² ğŸ¤— Transformers æ¨¡å‹æ—¶ï¼Œé€šå¸¸éœ€è¦å°†æ¨¡å‹å¯¼å‡ºä¸ºä¸€ç§åºåˆ—åŒ–æ ¼å¼ï¼Œä»¥ä¾¿åœ¨ä¸“ç”¨è¿è¡Œæ—¶å’Œç¡¬ä»¶ä¸ŠåŠ è½½å’Œæ‰§è¡Œã€‚\n",
    "\n",
    "ğŸ¤— Optimum æ˜¯ Transformers çš„ä¸€ä¸ªæ‰©å±•ï¼Œé€šè¿‡å…¶ `exporters` æ¨¡å—ï¼Œå¯ä»¥å°†æ¨¡å‹ä» PyTorch æˆ– TensorFlow å¯¼å‡ºä¸ºåºåˆ—åŒ–æ ¼å¼ï¼Œå¦‚ ONNX å’Œ TFLiteã€‚ğŸ¤— Optimum è¿˜æä¾›äº†ä¸€ç»„æ€§èƒ½ä¼˜åŒ–å·¥å…·ï¼Œä»¥åœ¨ç›®æ ‡ç¡¬ä»¶ä¸Šä»¥æœ€å¤§æ•ˆç‡è®­ç»ƒå’Œè¿è¡Œæ¨¡å‹ã€‚\n",
    "\n",
    "æœ¬æŒ‡å—æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ ğŸ¤— Optimum å°† ğŸ¤— Transformers æ¨¡å‹å¯¼å‡ºä¸º ONNX æ ¼å¼ã€‚æœ‰å…³å°†æ¨¡å‹å¯¼å‡ºä¸º TFLite çš„æŒ‡å—ï¼Œè¯·å‚é˜… [å¯¼å‡ºåˆ° TFLite é¡µé¢](tflite)ã€‚\n",
    "\n",
    "## å¯¼å‡ºåˆ° ONNX\n",
    "\n",
    "[ONNXï¼ˆå¼€æ”¾ç¥ç»ç½‘ç»œäº¤æ¢ï¼‰](http://onnx.ai) æ˜¯ä¸€ä¸ªå¼€æ”¾æ ‡å‡†ï¼Œå®šä¹‰äº†ä¸€ç»„é€šç”¨çš„æ“ä½œç¬¦å’Œä¸€ä¸ªé€šç”¨çš„æ–‡ä»¶æ ¼å¼ï¼Œç”¨äºåœ¨å„ç§æ¡†æ¶ï¼ˆåŒ…æ‹¬ PyTorch å’Œ TensorFlowï¼‰ä¸­è¡¨ç¤ºæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚å½“æ¨¡å‹å¯¼å‡ºä¸º ONNX æ ¼å¼æ—¶ï¼Œè¿™äº›æ“ä½œç¬¦ç”¨äºæ„å»ºä¸€ä¸ªè®¡ç®—å›¾ï¼ˆé€šå¸¸ç§°ä¸ºä¸­é—´è¡¨ç¤ºï¼‰ï¼Œè¯¥å›¾è¡¨ç¤ºæ•°æ®åœ¨ç¥ç»ç½‘ç»œä¸­çš„æµåŠ¨ã€‚\n",
    "\n",
    "é€šè¿‡å…¬å¼€å…·æœ‰æ ‡å‡†åŒ–æ“ä½œç¬¦å’Œæ•°æ®ç±»å‹çš„å›¾ï¼ŒONNX ä½¿å¾—åœ¨æ¡†æ¶ä¹‹é—´åˆ‡æ¢å˜å¾—å®¹æ˜“ã€‚ä¾‹å¦‚ï¼Œåœ¨ PyTorch ä¸­è®­ç»ƒçš„æ¨¡å‹å¯ä»¥å¯¼å‡ºä¸º ONNX æ ¼å¼ï¼Œç„¶ååœ¨ TensorFlow ä¸­å¯¼å…¥ï¼ˆåä¹‹äº¦ç„¶ï¼‰ã€‚\n",
    "\n",
    "ä¸€æ—¦å¯¼å‡ºä¸º ONNX æ ¼å¼ï¼Œæ¨¡å‹å¯ä»¥ï¼š\n",
    "\n",
    "* é€šè¿‡[å›¾ä¼˜åŒ–](https://huggingface.co/docs/optimum/onnxruntime/usage_guides/optimization)å’Œ[é‡åŒ–](https://huggingface.co/docs/optimum/onnxruntime/usage_guides/quantization)ç­‰æŠ€æœ¯è¿›è¡Œæ¨ç†ä¼˜åŒ–ã€‚\n",
    "* é€šè¿‡ [`ORTModelForXXX` ç±»](https://huggingface.co/docs/optimum/onnxruntime/package_reference/modeling_ort) ä½¿ç”¨ ONNX Runtime è¿è¡Œï¼Œè¿™äº›ç±»éµå¾ªä¸ ğŸ¤— Transformers ä¸­ç›¸åŒçš„ `AutoModel` APIã€‚\n",
    "* é€šè¿‡[ä¼˜åŒ–æ¨ç†ç®¡é“](https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/pipelines)è¿è¡Œï¼Œå…¶ API ä¸ ğŸ¤— Transformers ä¸­çš„ [pipeline()](/docs/transformers/v4.46.3/en/main_classes/pipelines#transformers.pipeline) å‡½æ•°ç›¸åŒã€‚\n",
    "\n",
    "ğŸ¤— Optimum é€šè¿‡åˆ©ç”¨é…ç½®å¯¹è±¡æ¥æ”¯æŒ ONNX å¯¼å‡ºã€‚è¿™äº›é…ç½®å¯¹è±¡ä¸ºå¤šç§æ¨¡å‹æ¶æ„æä¾›äº†ç°æˆçš„æ”¯æŒï¼Œå¹¶ä¸”è®¾è®¡ä¸ºæ˜“äºæ‰©å±•åˆ°å…¶ä»–æ¶æ„ã€‚\n",
    "\n",
    "æœ‰å…³ç°æˆé…ç½®çš„åˆ—è¡¨ï¼Œè¯·å‚é˜… [ğŸ¤— Optimum æ–‡æ¡£](https://huggingface.co/docs/optimum/exporters/onnx/overview)ã€‚\n",
    "\n",
    "æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å°† ğŸ¤— Transformers æ¨¡å‹å¯¼å‡ºä¸º ONNXï¼Œè¿™é‡Œæˆ‘ä»¬å±•ç¤ºä¸¤ç§æ–¹æ³•ï¼š\n",
    "\n",
    "* é€šè¿‡ CLI ä½¿ç”¨ ğŸ¤— Optimum å¯¼å‡ºã€‚\n",
    "* é€šè¿‡ `optimum.onnxruntime` ä½¿ç”¨ ğŸ¤— Optimum å¯¼å‡ºã€‚\n",
    "\n",
    "### é€šè¿‡ CLI å¯¼å‡º ğŸ¤— Transformers æ¨¡å‹åˆ° ONNX\n",
    "\n",
    "è¦å°† ğŸ¤— Transformers æ¨¡å‹å¯¼å‡ºä¸º ONNXï¼Œé¦–å…ˆå®‰è£…ä¸€ä¸ªé¢å¤–çš„ä¾èµ–é¡¹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb57098",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install optimum[exporters]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3725ec4b",
   "metadata": {},
   "source": [
    "\n",
    "è¦æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‚æ•°ï¼Œè¯·å‚é˜… [ğŸ¤— Optimum æ–‡æ¡£](https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)ï¼Œæˆ–åœ¨å‘½ä»¤è¡Œä¸­æŸ¥çœ‹å¸®åŠ©ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09556d42",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "optimum-cli export onnx --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d1c89",
   "metadata": {},
   "source": [
    "\n",
    "è¦ä» ğŸ¤— Hub å¯¼å‡ºæ¨¡å‹çš„æ£€æŸ¥ç‚¹ï¼Œä¾‹å¦‚ `distilbert/distilbert-base-uncased-distilled-squad`ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b1fda4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "optimum-cli export onnx --model distilbert/distilbert-base-uncased-distilled-squad distilbert_base_uncased_squad_onnx/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba08754",
   "metadata": {},
   "source": [
    "\n",
    "ä½ åº”è¯¥ä¼šçœ‹åˆ°æ—¥å¿—æŒ‡ç¤ºè¿›åº¦ï¼Œå¹¶æ˜¾ç¤ºä¿å­˜çš„ `model.onnx` æ–‡ä»¶çš„ä½ç½®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53e3f6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Validating ONNX model distilbert_base_uncased_squad_onnx/model.onnx...\n",
    "    -[âœ“] ONNX model output names match reference model (start_logits, end_logits)\n",
    "    - Validating ONNX Model output \"start_logits\":\n",
    "        -[âœ“] (2, 16) matches (2, 16)\n",
    "        -[âœ“] all values close (atol: 0.0001)\n",
    "    - Validating ONNX Model output \"end_logits\":\n",
    "        -[âœ“] (2, 16) matches (2, 16)\n",
    "        -[âœ“] all values close (atol: 0.0001)\n",
    "The ONNX export succeeded and the exported model was saved at: distilbert_base_uncased_squad_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848cfd2",
   "metadata": {},
   "source": [
    "\n",
    "ä¸Šé¢çš„ç¤ºä¾‹è¯´æ˜äº†ä» ğŸ¤— Hub å¯¼å‡ºæ£€æŸ¥ç‚¹ã€‚å½“å¯¼å‡ºæœ¬åœ°æ¨¡å‹æ—¶ï¼Œé¦–å…ˆç¡®ä¿ä½ å°†æ¨¡å‹çš„æƒé‡å’Œåˆ†è¯å™¨æ–‡ä»¶ä¿å­˜åœ¨åŒä¸€ç›®å½•ï¼ˆ`local_path`ï¼‰ä¸­ã€‚ä½¿ç”¨ CLI æ—¶ï¼Œå°† `local_path` ä¼ é€’ç»™ `model` å‚æ•°ï¼Œè€Œä¸æ˜¯ ğŸ¤— Hub ä¸Šçš„æ£€æŸ¥ç‚¹åç§°ï¼Œå¹¶æä¾› `--task` å‚æ•°ã€‚ä½ å¯ä»¥åœ¨ [ğŸ¤— Optimum æ–‡æ¡£](https://huggingface.co/docs/optimum/exporters/task_manager) ä¸­æŸ¥çœ‹æ”¯æŒçš„ä»»åŠ¡åˆ—è¡¨ã€‚å¦‚æœæœªæä¾› `task` å‚æ•°ï¼Œå®ƒå°†é»˜è®¤ä¸ºæ¨¡å‹æ¶æ„ï¼Œè€Œä¸å¸¦ä»»ä½•ä»»åŠ¡ç‰¹å®šçš„å¤´éƒ¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73459331",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "optimum-cli export onnx --model local_path --task question-answering distilbert_base_uncased_squad_onnx/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109d2b6",
   "metadata": {},
   "source": [
    "\n",
    "ç”Ÿæˆçš„ `model.onnx` æ–‡ä»¶å¯ä»¥åœ¨æ”¯æŒ ONNX æ ‡å‡†çš„[è®¸å¤šåŠ é€Ÿå™¨](https://onnx.ai/supported-tools.html#deployModel)ä¸Šè¿è¡Œã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [ONNX Runtime](https://onnxruntime.ai/) åŠ è½½å’Œè¿è¡Œæ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a3e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import ORTModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert_base_uncased_squad_onnx\")\n",
    "model = ORTModelForQuestionAnswering.from_pretrained(\"distilbert_base_uncased_squad_onnx\")\n",
    "inputs = tokenizer(\"What am I using?\", \"Using DistilBERT with ONNX Runtime!\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c7e44",
   "metadata": {},
   "source": [
    "\n",
    "å¯¹äº Hub ä¸Šçš„ TensorFlow æ£€æŸ¥ç‚¹ï¼Œè¿‡ç¨‹æ˜¯ç›¸åŒçš„ã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œæ˜¯å¦‚ä½•ä» [Keras ç»„ç»‡](https://huggingface.co/keras-io) å¯¼å‡ºçº¯ TensorFlow æ£€æŸ¥ç‚¹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbeb3a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "optimum-cli export onnx --model keras-io/transformers-qa distilbert_base_cased_squad_onnx/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24911c64",
   "metadata": {},
   "source": [
    "\n",
    "### é€šè¿‡ optimum.onnxruntime å¯¼å‡º ğŸ¤— Transformers æ¨¡å‹åˆ° ONNX\n",
    "\n",
    "é™¤äº† CLIï¼Œä½ è¿˜å¯ä»¥é€šè¿‡ç¼–ç¨‹æ–¹å¼å°† ğŸ¤— Transformers æ¨¡å‹å¯¼å‡ºä¸º ONNXï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d529bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert_base_uncased_squad\"\n",
    "save_directory = \"onnx/\"\n",
    "\n",
    "# ä» transformers åŠ è½½æ¨¡å‹å¹¶å¯¼å‡ºä¸º ONNX\n",
    "ort_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, export=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# ä¿å­˜ ONNX æ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "ort_model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798bf4c",
   "metadata": {},
   "source": [
    "\n",
    "### å¯¼å‡ºä¸æ”¯æŒæ¶æ„çš„æ¨¡å‹\n",
    "\n",
    "å¦‚æœä½ æƒ³é€šè¿‡æ·»åŠ å¯¹å½“å‰æ— æ³•å¯¼å‡ºçš„æ¨¡å‹çš„æ”¯æŒæ¥è´¡çŒ®ï¼Œä½ åº”è¯¥é¦–å…ˆæ£€æŸ¥å®ƒæ˜¯å¦åœ¨ [`optimum.exporters.onnx`](https://huggingface.co/docs/optimum/exporters/onnx/overview) ä¸­å—æ”¯æŒï¼Œå¦‚æœæœªå—æ”¯æŒï¼Œè¯·ç›´æ¥[è´¡çŒ®åˆ° ğŸ¤— Optimum](https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/contribute)ã€‚\n",
    "\n",
    "### é€šè¿‡ transformers.onnx å¯¼å‡ºæ¨¡å‹\n",
    "\n",
    "`transformers.onnx` ä¸å†ç»´æŠ¤ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°æ–¹æ³•ä½¿ç”¨ ğŸ¤— Optimum å¯¼å‡ºæ¨¡å‹ã€‚æ­¤éƒ¨åˆ†å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­åˆ é™¤ã€‚\n",
    "\n",
    "è¦å°† ğŸ¤— Transformers æ¨¡å‹é€šè¿‡ `transformers.onnx` å¯¼å‡ºä¸º ONNXï¼Œè¯·å®‰è£…é¢å¤–çš„ä¾èµ–é¡¹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c94a66",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers[onnx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16618c",
   "metadata": {},
   "source": [
    "\n",
    "ä½¿ç”¨ `transformers.onnx` åŒ…ä½œä¸º Python æ¨¡å—ï¼Œä½¿ç”¨ç°æˆçš„é…ç½®å¯¼å‡ºæ£€æŸ¥ç‚¹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0152d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python -m transformers.onnx --model=distilbert/distilbert-base-uncased onnx/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea9cff",
   "metadata": {},
   "source": [
    "\n",
    "è¿™å°†å¯¼å‡ºç”± `--model` å‚æ•°å®šä¹‰çš„æ£€æŸ¥ç‚¹çš„ ONNX å›¾ã€‚ä¼ é€’ ğŸ¤— Hub ä¸Šçš„ä»»ä½•æ£€æŸ¥ç‚¹æˆ–æœ¬åœ°å­˜å‚¨çš„æ£€æŸ¥ç‚¹ã€‚ç”Ÿæˆçš„ `model.onnx` æ–‡ä»¶å¯ä»¥åœ¨æ”¯æŒ ONNX æ ‡å‡†çš„è®¸å¤šåŠ é€Ÿå™¨ä¸Šè¿è¡Œã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ ONNX Runtime åŠ è½½å’Œè¿è¡Œæ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09036113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from onnxruntime import InferenceSession\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "session = InferenceSession(\"onnx/model.onnx\")\n",
    "# ONNX Runtime æœŸæœ›è¾“å…¥ä¸º NumPy æ•°ç»„\n",
    "inputs = tokenizer(\"Using DistilBERT with ONNX Runtime!\", return_tensors=\"np\")\n",
    "outputs = session.run(output_names=[\"last_hidden_state\"], input_feed=dict(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc21396",
   "metadata": {},
   "source": [
    "\n",
    "æ‰€éœ€çš„è¾“å‡ºåç§°ï¼ˆå¦‚ `[\"last_hidden_state\"]`ï¼‰å¯ä»¥é€šè¿‡æŸ¥çœ‹æ¯ä¸ªæ¨¡å‹çš„ ONNX é…ç½®æ¥è·å¾—ã€‚ä¾‹å¦‚ï¼Œå¯¹äº DistilBERTï¼Œæˆ‘ä»¬æœ‰ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.distilbert import DistilBertConfig, DistilBertOnnxConfig\n",
    "\n",
    "config = DistilBertConfig()\n",
    "onnx_config = DistilBertOnnxConfig(config)\n",
    "print(list(onnx_config.outputs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf901d6",
   "metadata": {},
   "source": [
    "\n",
    "å¯¹äº Hub ä¸Šçš„ TensorFlow æ£€æŸ¥ç‚¹ï¼Œè¿‡ç¨‹æ˜¯ç›¸åŒçš„ã€‚ä¾‹å¦‚ï¼Œå¯¼å‡ºçº¯ TensorFlow æ£€æŸ¥ç‚¹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c9afa",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python -m transformers.onnx --model=keras-io/transformers-qa onnx/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bf284",
   "metadata": {},
   "source": [
    "\n",
    "è¦å¯¼å‡ºæœ¬åœ°å­˜å‚¨çš„æ¨¡å‹ï¼Œè¯·å°†æ¨¡å‹çš„æƒé‡å’Œåˆ†è¯å™¨æ–‡ä»¶ä¿å­˜åœ¨åŒä¸€ç›®å½•ï¼ˆä¾‹å¦‚ `local-pt-checkpoint`ï¼‰ä¸­ï¼Œç„¶åé€šè¿‡å°† `transformers.onnx` åŒ…çš„ `--model` å‚æ•°æŒ‡å‘æ‰€éœ€ç›®å½•æ¥å°†å…¶å¯¼å‡ºä¸º ONNXï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61cb51",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python -m transformers.onnx --model=local-pt-checkpoint onnx/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
