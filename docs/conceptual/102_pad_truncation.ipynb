{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeeb165c",
   "metadata": {},
   "source": [
    "# 填充与截断\n",
    "\n",
    "在处理批量输入时，输入的长度通常是不同的，因此不能直接转换为固定大小的张量。填充（Padding）和截断（Truncation）是解决这一问题的策略，用于将不同长度的批量输入转换为矩形张量。填充通过添加特殊的**填充标记（padding token）**来确保较短的序列与批次中最长的序列或模型可接受的最大长度一致。截断则是通过截断较长的序列来解决问题。\n",
    "\n",
    "通常情况下，将批次填充到最长序列的长度，并截断到模型可接受的最大长度，这种方法效果很好。但API还支持更多策略。你需要了解的三个参数是：`padding`、`truncation` 和 `max_length`。\n",
    "\n",
    "### `padding` 参数\n",
    "\n",
    "`padding` 参数控制填充行为。它可以是布尔值或字符串：\n",
    "\n",
    "- `True` 或 `'longest'`：将填充到批次中最长的序列长度。如果你只提供单个序列，则不会应用填充。\n",
    "- `'max_length'`：将填充到由 `max_length` 参数指定的长度，或者如果未提供 `max_length`，则填充到模型可接受的最大长度。即使只提供单个序列，也会应用填充。\n",
    "- `False` 或 `'do_not_pad'`：不应用填充。这是默认行为。\n",
    "\n",
    "### `truncation` 参数\n",
    "\n",
    "`truncation` 参数控制截断行为。它可以是布尔值或字符串：\n",
    "\n",
    "- `True` 或 `'longest_first'`：将截断到由 `max_length` 参数指定的最大长度，或者如果未提供 `max_length`，则截断到模型可接受的最大长度。这会逐个标记截断，从一对序列中最长的序列中移除标记，直到达到适当的长度。\n",
    "- `'only_second'`：将截断到由 `max_length` 参数指定的最大长度，或者如果未提供 `max_length`，则截断到模型可接受的最大长度。这对成对序列中的第二个句子进行截断。\n",
    "- `'only_first'`：将截断到由 `max_length` 参数指定的最大长度，或者如果未提供 `max_length`，则截断到模型可接受的最大长度。这对成对序列中的第一个句子进行截断。\n",
    "- `False` 或 `'do_not_truncate'`：不应用截断。这是默认行为。\n",
    "\n",
    "### `max_length` 参数\n",
    "\n",
    "`max_length` 参数控制填充和截断的长度。它可以是整数或 `None`，在这种情况下，默认为模型可接受的最大长度。如果模型没有指定的最大输入长度，则不激活截断或填充到 `max_length`。\n",
    "\n",
    "下表总结了建议的填充和截断设置方式。如果你在以下示例中使用成对的输入序列，可以将 `truncation=True` 替换为 `STRATEGY`，选择 `['only_first', 'only_second', 'longest_first']` 中的策略，以控制成对序列中两个序列的截断方式。\n",
    "\n",
    "| 截断 | 填充 | 指令 |\n",
    "| --- | --- | --- |\n",
    "| 无截断 | 无填充 | `tokenizer(batch_sentences)` |\n",
    "|  | 填充到批次中最长序列长度 | `tokenizer(batch_sentences, padding=True)` 或 `tokenizer(batch_sentences, padding='longest')` |\n",
    "|  | 填充到模型最大输入长度 | `tokenizer(batch_sentences, padding='max_length')` |\n",
    "|  | 填充到指定长度 | `tokenizer(batch_sentences, padding='max_length', max_length=42)` |\n",
    "|  | 填充到某个值的倍数 | `tokenizer(batch_sentences, padding=True, pad_to_multiple_of=8)` |\n",
    "| 截断到模型最大输入长度 | 无填充 | `tokenizer(batch_sentences, truncation=True)` 或 `tokenizer(batch_sentences, truncation=STRATEGY)` |\n",
    "|  | 填充到批次中最长序列长度 | `tokenizer(batch_sentences, padding=True, truncation=True)` 或 `tokenizer(batch_sentences, padding=True, truncation=STRATEGY)` |\n",
    "|  | 填充到模型最大输入长度 | `tokenizer(batch_sentences, padding='max_length', truncation=True)` 或 `tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY)` |\n",
    "|  | 填充到指定长度 | 不支持 |\n",
    "| 截断到指定长度 | 无填充 | `tokenizer(batch_sentences, truncation=True, max_length=42)` 或 `tokenizer(batch_sentences, truncation=STRATEGY, max_length=42)` |\n",
    "|  | 填充到批次中最长序列长度 | `tokenizer(batch_sentences, padding=True, truncation=True, max_length=42)` 或 `tokenizer(batch_sentences, padding=True, truncation=STRATEGY, max_length=42)` |\n",
    "|  | 填充到模型最大输入长度 | 不支持 |\n",
    "|  | 填充到指定长度 | `tokenizer(batch_sentences, padding='max_length', truncation=True, max_length=42)` 或 `tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY, max_length=42)` |"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
