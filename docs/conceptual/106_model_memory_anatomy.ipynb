{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb5b6de",
   "metadata": {},
   "source": [
    "# 模型训练剖析\n",
    "\n",
    "要理解可以应用于提高模型训练速度和内存利用率的优化技术，了解 GPU 在训练中的使用情况以及不同操作的计算强度变化是很有帮助的。\n",
    "\n",
    "我们从一个 GPU 使用情况和模型训练运行的示例开始。为了演示，我们需要安装几个库：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ceb017",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets accelerate nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb3da5",
   "metadata": {},
   "source": [
    "\n",
    "`nvidia-ml-py3` 库允许我们在 Python 中监控模型的内存使用情况。你可能熟悉终端中的 `nvidia-smi` 命令——这个库可以直接在 Python 中访问相同的信息。\n",
    "\n",
    "接下来，我们创建一些虚拟数据：输入 ID 在 100 到 30000 之间的随机值，以及用于分类的二进制标签。总共生成 512 个长度为 512 的序列，并将其存储在一个使用 PyTorch 格式的 [Dataset](https://huggingface.co/docs/datasets/v3.2.0/en/package_reference/main_classes#datasets.Dataset) 中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "seq_len, dataset_size = 512, 512\n",
    "dummy_data = {\n",
    "    \"input_ids\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n",
    "    \"labels\": np.random.randint(0, 2, (dataset_size)),\n",
    "}\n",
    "ds = Dataset.from_dict(dummy_data)\n",
    "ds.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a93cf5",
   "metadata": {},
   "source": [
    "\n",
    "为了打印 GPU 使用情况的摘要统计信息和训练运行情况，我们定义两个辅助函数：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU 内存占用: {info.used//1024**2} MB.\")\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"时间: {result.metrics['train_runtime']:.2f} 秒\")\n",
    "    print(f\"每秒样本数: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992229c1",
   "metadata": {},
   "source": [
    "\n",
    "我们先确认 GPU 内存是空闲的：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_gpu_utilization()\n",
    "# 输出:\n",
    "# GPU 内存占用: 0 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27103e",
   "metadata": {},
   "source": [
    "\n",
    "一切正常：在加载任何模型之前，GPU 内存应该是空闲的。如果你的机器不是这样，请确保停止所有占用 GPU 内存的进程。然而，并不是所有空闲的 GPU 内存都可以被用户使用。当模型加载到 GPU 上时，内核也一同加载，这会占用 1-2GB 的内存。我们通过将一个小型张量加载到 GPU 来触发内核的加载。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e23dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.ones((1, 1)).to(\"cuda\")\n",
    "print_gpu_utilization()\n",
    "# 输出:\n",
    "# GPU 内存占用: 1343 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fa00e7",
   "metadata": {},
   "source": [
    "\n",
    "我们可以看到内核本身占用了 1.3GB 的 GPU 内存。现在我们来看看模型占用了多少空间。\n",
    "\n",
    "## 加载模型\n",
    "\n",
    "首先，我们加载 `google-bert/bert-large-uncased` 模型。我们将模型权重直接加载到 GPU 上，以检查它们占用的内存空间。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-large-uncased\").to(\"cuda\")\n",
    "print_gpu_utilization()\n",
    "# 输出:\n",
    "# GPU 内存占用: 2631 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853d8f9",
   "metadata": {},
   "source": [
    "\n",
    "我们看到模型权重本身占用了 1.3GB 的 GPU 内存。具体数量取决于你使用的 GPU。请注意，在较新的 GPU 上，模型可能会占用更多空间，因为权重是以优化的方式加载的，以加快模型的使用速度。现在，我们可以快速检查一下 `nvidia-smi` CLI 是否给出相同的结果：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508036e2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c0578",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "554a3073",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Tue Jan 11 08:58:05 2022\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 460.91.03    驱动版本: 460.91.03    CUDA 版本: 11.2     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  名称        持久模式 | 总线 ID        显示.A | 波动的未校正 ECC |\n",
    "| 风扇  温度  性能  功率:使用/上限 |         内存使用 | GPU 利用率  计算 M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla V100-SXM2...  On   | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   37C    P0    39W / 300W |   2631MiB / 16160MiB |      0%      默认 |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "\n",
    "+-----------------------------------------------------------------------------+\n",
    "| 进程:                                                                  |\n",
    "|  GPU   GI   CI        PID   类型   进程名称                  GPU 内存 |\n",
    "|        ID   ID                                                   使用      |\n",
    "|=============================================================================|\n",
    "|    0   N/A  N/A      3721      C   ...nvs/codeparrot/bin/python     2629MiB |\n",
    "+-----------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb7dd24",
   "metadata": {},
   "source": [
    "\n",
    "我们得到了与之前相同的数字，并且可以看到我们正在使用一个有 16GB 内存的 V100 GPU。现在我们可以开始训练模型，并观察 GPU 内存使用的变化。首先，我们设置一些标准的训练参数：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f81751",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8549ca5",
   "metadata": {},
   "source": [
    "\n",
    "如果你计划运行多个实验，为了正确清除内存，请在实验之间重启 Python 内核。\n",
    "\n",
    "## 原始训练的内存使用情况\n",
    "\n",
    "我们使用 [Trainer](/docs/transformers/v4.48.0/en/main_classes/trainer#transformers.Trainer) 来训练模型，不使用任何 GPU 性能优化技术，并设置批大小为 4：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10cf8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff72a8e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "38db5be0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "时间: 57.82 秒\n",
    "每秒样本数: 8.86\n",
    "GPU 内存占用: 14949 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49926412",
   "metadata": {},
   "source": [
    "\n",
    "我们可以看到即使是相对较小的批大小也几乎填满了 GPU 的全部内存。然而，更大的批大小通常可以加快模型收敛速度或提高最终性能。理想情况下，我们应该根据模型的需求调整批大小，而不是受 GPU 限制。有趣的是，我们使用的内存比模型本身的内存要多得多。为了更好地理解原因，我们来看看模型的操作和内存需求。\n",
    "\n",
    "## 模型操作剖析\n",
    "\n",
    "Transformer 架构包括以下三组主要操作，按计算强度分组：\n",
    "\n",
    "1. **张量收缩**\n",
    "   - 线性层和多头注意力组件中的所有操作都涉及批处理的 **矩阵-矩阵乘法**。这些操作是训练变压器最计算密集的部分。\n",
    "2. **统计归一化**\n",
    "   - Softmax 和层归一化操作比张量收缩要轻得多，涉及一个或多个 **归约操作**，其结果通过映射应用。\n",
    "3. **逐元素操作**\n",
    "   - 剩下的操作是 **偏置、Dropout、激活和残差连接**。这些是最不计算密集的操作。\n",
    "\n",
    "了解这些信息有助于分析性能瓶颈。\n",
    "\n",
    "## 模型内存剖析\n",
    "\n",
    "我们已经看到训练模型使用的内存远不止将模型加载到 GPU 上的内存。这是因为训练过程中使用的 GPU 内存有多个组件，包括：\n",
    "\n",
    "1. 模型权重\n",
    "2. 优化器状态\n",
    "3. 梯度\n",
    "4. 用于梯度计算的前向激活\n",
    "5. 临时缓冲区\n",
    "6. 功能特定内存\n",
    "\n",
    "一个典型的使用混合精度和 AdamW 优化器训练的模型需要每个参数 18 字节，加上激活内存。对于推理，没有优化器状态和梯度，因此可以减去这些部分，最终每个参数需要 6 字节加上激活内存。\n",
    "\n",
    "我们来看一下这些组件的详细信息：\n",
    "\n",
    "- **模型权重**：\n",
    "  - fp32 训练：4 字节 × 参数数量\n",
    "  - 混合精度训练：6 字节 × 参数数量（同时维护 fp32 和 fp16 模型）\n",
    "\n",
    "- **优化器状态**：\n",
    "  - 正常 AdamW：8 字节 × 参数数量（维护两个状态）\n",
    "  - 8 位 AdamW 优化器（如 [bitsandbytes](https://github.com/bitsandbytes-foundation/bitsandbytes)）：2 字节 × 参数数量\n",
    "  - 带动量的 SGD 等优化器：4 字节 × 参数数量（仅维护一个状态）\n",
    "\n",
    "- **梯度**：\n",
    "  - fp32 或混合精度训练：4 字节 × 参数数量（梯度始终保存为 fp32）\n",
    "\n",
    "- **前向激活**：\n",
    "  - 大小取决于许多因素，关键因素包括序列长度、隐藏大小和批大小。\n",
    "\n",
    "- **临时内存**：\n",
    "  - 在计算过程中会释放各种临时变量，但在计算过程中这些变量可能会占用额外的内存，导致内存不足。因此，在编程时要战略性地考虑这些临时变量，并在不再需要时显式释放。\n",
    "\n",
    "- **功能特定内存**：\n",
    "  - 例如，使用束搜索生成文本时，软件需要维护多个输入和输出的副本。\n",
    "\n",
    "- **前向 vs 后向执行速度**：\n",
    "  - 对于卷积和线性层，后向传播的浮点运算量是前向传播的两倍，通常导致后向传播的速度大约是前向传播的两倍（有时更多，因为后向传播的大小往往更尴尬）。激活通常受带宽限制，通常在后向传播中需要读取更多数据（例如，激活前向传播读取一次，写入一次，激活后向传播读取两次，gradOutput 和前向传播的输出，写入一次，gradInput）。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
