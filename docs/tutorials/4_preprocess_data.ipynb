{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é¢„å¤„ç†æ•°æ®\n",
    "\n",
    "åœ¨æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæ•°æ®éœ€è¦è¢«é¢„å¤„ç†ä¸ºæ¨¡å‹æœŸæœ›çš„è¾“å…¥æ ¼å¼ã€‚æ— è®ºæ•°æ®æ˜¯æ–‡æœ¬ã€å›¾åƒè¿˜æ˜¯éŸ³é¢‘ï¼Œå®ƒä»¬éƒ½éœ€è¦è¢«è½¬æ¢å¹¶ç»„åˆæˆæ‰¹é‡çš„å¼ é‡ã€‚\n",
    "\n",
    "ğŸ¤— Transformers æä¾›äº†ä¸€ç»„é¢„å¤„ç†ç±»æ¥å¸®åŠ©å‡†å¤‡æ•°æ®ä»¥ä¾›æ¨¡å‹ä½¿ç”¨ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œä½ å°†äº†è§£ä»¥ä¸‹å†…å®¹ï¼š\n",
    "1. å¯¹äºæ–‡æœ¬ï¼Œä½¿ç”¨[åˆ†è¯å™¨(Tokenizer)](https://huggingface.co/docs/transformers/v4.44.2/zh/main_classes/tokenizer)èƒ½å¤Ÿå°†æ–‡æœ¬è½¬æ¢ä¸ºä¸€ç³»åˆ—æ ‡è®°`tokens`ï¼Œå¹¶åˆ›å»º tokens çš„æ•°å­—è¡¨ç¤ºï¼Œå°†å®ƒä»¬ç»„åˆæˆå¼ é‡ã€‚\n",
    "2. å¯¹äºè¯­éŸ³å’ŒéŸ³é¢‘ï¼Œä½¿ç”¨[ç‰¹å¾æå–å™¨(Feature extractor)](https://huggingface.co/docs/transformers/v4.44.2/zh/main_classes/feature_extractor)èƒ½å¤Ÿä»éŸ³é¢‘æ³¢å½¢ä¸­æå–é¡ºåºç‰¹å¾å¹¶å°†å…¶è½¬æ¢ä¸ºå¼ é‡ã€‚\n",
    "3. å¯¹äºå›¾åƒï¼Œä½¿ç”¨`å›¾åƒå¤„ç†å™¨(ImageProcessor)`å°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ã€‚\n",
    "4. å¯¹äºå¤šæ¨¡æ€è¾“å…¥ï¼Œä½¿ç”¨[å¤„ç†å™¨(Processor)](https://huggingface.co/docs/transformers/v4.44.2/zh/main_classes/processors)ï¼Œå…¶ç»“åˆäº† Tokenizer å’Œ ImageProcessor æˆ– Processorã€‚\n",
    "\n",
    "`AutoProcessor` èƒ½å¤Ÿæœ‰æ•ˆçš„è‡ªåŠ¨é€‰æ‹©é€‚ç”¨äºæ¨¡å‹è¾“å…¥çš„é¢„å¤„ç†å·¥å…·ï¼Œæ— è®ºä½ ä½¿ç”¨çš„æ˜¯ `Tokenizer`ã€`ImageProcessor`ã€`Feature extractor`è¿˜æ˜¯`Processor`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·å®‰è£…`ğŸ¤— Datasets`ï¼Œå¯ä»¥åŠ è½½ä¸€äº›æ•°æ®é›†æ¥è¿›è¡Œå®éªŒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆæ–‡æœ¬é¢„å¤„ç†ï¼‰\n",
    "\n",
    "å¤„ç†æ–‡æœ¬æ•°æ®çš„ä¸»è¦å·¥å…·æ˜¯`åˆ†è¯å™¨(Tokenizer)`ï¼Œæ¨¡å‹æ‰€éœ€çš„ä»»ä½•é™„åŠ è¾“å…¥éƒ½ç”± Tokenizer è¿›è¡Œæ·»åŠ ã€‚\n",
    "\n",
    "Tokenizer ä¼šæ ¹æ®ä¸€ç»„è§„åˆ™å°†æ–‡æœ¬æ‹†åˆ†ä¸º tokensï¼Œç„¶åå°†è¿™äº›tokensè½¬æ¢ä¸ºæ•°å­—ï¼Œç„¶åè½¬æ¢ä¸ºå¼ é‡ï¼Œæˆä¸ºæ¨¡å‹çš„è¾“å…¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**å¦‚æœä½ é€‰æ‹©ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™éœ€è¦æ³¨æ„ä½¿ç”¨ä¸æ¨¡å‹å…³è”çš„é¢„è®­ç»ƒçš„Tokenizerã€‚**è¿™æ˜¯ä¸ºäº†ç¡®ä¿æ–‡æœ¬çš„æ‹†åˆ†æ–¹å¼ä¸é¢„è®­ç»ƒçš„è¯­æ–™åº“ç›¸åŒï¼Œå¹¶åœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨ç›¸åŒçš„å¯¹åº”å…³ç³»`æ ‡è®°-ç´¢å¼•`ï¼ˆé€šå¸¸ç§°ä¸ºè¯æ±‡è¡¨`vocab`ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¼€å§‹ä½¿ç”¨`AutoTokenizer.from_pretrained()`æ–¹æ³•åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„ Tokenizerï¼Œå¹¶ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹çš„è¯æ±‡è¡¨ vocabï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åæ–‡æœ¬è¾“å…¥ç»™ Tokenizerï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer ä¼šè¿”å›ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªé‡è¦å¯¹è±¡çš„å­—å…¸ï¼š\n",
    "\n",
    "- `input_ids`ï¼šè¿™æ˜¯ä¸€ä¸ªæ•´æ•°åºåˆ—ï¼Œæ¯ä¸ªæ•´æ•°ä»£è¡¨è¯æ±‡è¡¨ä¸­çš„ä¸€ä¸ªç‰¹å®štokenã€‚**æ¨¡å‹ä½¿ç”¨è¿™ä¸ªåºåˆ—ä½œä¸ºè¾“å…¥æ¥ç†è§£å’Œå¤„ç†æ–‡æœ¬æ•°æ®**ã€‚\n",
    "- `token_type_ids`ï¼šè¿™æ˜¯ä¸€ä¸ªä¸ input_ids ç›¸åŒé•¿åº¦çš„åºåˆ—ï¼Œå®ƒè¡¨ç¤ºè¾“å…¥åºåˆ—ä¸­æ¯ä¸ª token çš„ç±»å‹ã€‚è¿™ä¸ªå­—æ®µä¸»è¦ç”¨äº**åŒºåˆ†ä¸åŒç±»å‹çš„è¾“å…¥åºåˆ—**ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ç”±å¤šä¸ªæ–‡æœ¬åºåˆ—ç»„æˆçš„è¾“å…¥æ—¶ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿä¸­çš„é—®é¢˜å’Œç­”æ¡ˆï¼Œæˆ–è€…æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­çš„æ–‡æœ¬å’Œæ ‡ç­¾ã€‚\n",
    "- `attention_mask`ï¼šè¿™ä¸ªåºåˆ—è¡¨ç¤ºè¾“å…¥åºåˆ—ä¸­å“ªäº› token æ˜¯å®é™…çš„æ–‡æœ¬tokenï¼Œå“ªäº›æ˜¯å¡«å……ï¼ˆpaddingï¼‰tokenã€‚åœ¨å¤„ç†æ‰¹é‡æ•°æ®æ—¶ï¼Œ**ç”±äºä¸åŒåºåˆ—çš„é•¿åº¦å¯èƒ½ä¸åŒï¼Œé€šå¸¸éœ€è¦ä½¿ç”¨å¡«å……tokenæ¥ä½¿æ‰€æœ‰åºåˆ—é•¿åº¦ä¸€è‡´**ã€‚`attention_mask` ä¸­çš„ `1 è¡¨ç¤ºå®é™…çš„æ–‡æœ¬token`ï¼Œè€Œ `0 è¡¨ç¤ºå¡«å……token`ï¼Œè¿™æ ·æ¨¡å‹å°±å¯ä»¥å¿½ç•¥å¡«å……tokenã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€šè¿‡`tokenizer.decode()`å¯ä»¥è§£ç  `input_ids` å¾—åˆ°è¾“å…¥çš„æ–‡æœ¬ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»è§£ç å¾—åˆ°çš„æ–‡æœ¬å¯çŸ¥ï¼Œtokenizer åœ¨å¥å­ä¸­æ·»åŠ äº†ä¸¤ä¸ªç‰¹æ®Š token - `[CLS]` å’Œ `[SEP]`ï¼ˆåˆ†ç±»å™¨å’Œåˆ†éš”ç¬¦ï¼‰ã€‚\n",
    "\n",
    "**æ³¨æ„ï¼å¹¶ä¸æ˜¯æ‰€æœ‰æ¨¡å‹éƒ½éœ€è¦æ·»åŠ ç‰¹æ®Š tokenï¼Œä½†å¦‚æœéœ€è¦ï¼Œtokenizer ä¼šè‡ªåŠ¨ç»™ä½ æ·»åŠ ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæœ‰å¤šä¸ªå¥å­éœ€è¦è¿›è¡Œé¢„å¤„ç†ï¼Œå¯ä»¥å°†å®ƒä»¬ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™ tokenizerï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_inputs = tokenizer(batch_sentences)\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¡«å……\n",
    "\n",
    "è¾“å…¥å¥å­çš„é•¿åº¦å¹¶ä¸æ€»æ˜¯ç›¸åŒçš„ï¼Œè¿™æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºæ¨¡å‹è¾“å…¥çš„å¼ é‡éœ€è¦å…·æœ‰ç»Ÿä¸€çš„å½¢çŠ¶ã€‚\n",
    "\n",
    "å¡«å……æ˜¯ä¸€ç§è§£å†³åŠæ³•ï¼Œé€šè¿‡åœ¨è¾ƒçŸ­çš„å¥å­ä¸­æ·»åŠ ä¸€ä¸ªç‰¹æ®Šçš„ `padding token`ï¼Œä»¥ç¡®ä¿å¼ é‡æ˜¯çŸ©å½¢çš„ã€‚\n",
    "\n",
    "è®¾ç½®å‚æ•° `padding=True`ï¼Œå°†æ‰¹æ¬¡ä¸­è¾ƒçŸ­çš„åºåˆ—å¡«å……åˆ°ä¸æœ€é•¿çš„åºåˆ—ç›¸åŒçš„é•¿åº¦ï¼Œä¸€èˆ¬ç”¨ 0 è¿›è¡Œå¡«å……ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True)\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æˆªæ–­\n",
    "\n",
    "å¦ä¸€æ–¹é¢ï¼Œæœ‰æ—¶å€™ä¸€ä¸ªåºåˆ—å¯èƒ½å¯¹æ¨¡å‹æ¥è¯´å¤ªé•¿äº†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆ™éœ€è¦å°†åºåˆ—æˆªæ–­ä¸ºæ›´çŸ­çš„é•¿åº¦ã€‚\n",
    "\n",
    "è®¾ç½®å‚æ•° `truncation=True`ï¼Œå°†è¿‡é•¿çš„åºåˆ—æˆªæ–­ä¸ºæ¨¡å‹æ¥å—çš„æœ€å¤§é•¿åº¦ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ max_length å‚æ•°è®¾ç½®æˆªæ–­çš„æœ€å¤§é•¿åº¦ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹[å¡«å……å’Œæˆªæ–­](https://huggingface.co/docs/transformers/main/en/pad_truncation)æ¦‚å¿µæŒ‡å—ï¼Œäº†è§£æ›´å¤šæœ‰å…³å¡«å……å’Œæˆªæ–­å‚æ•°çš„ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ„å»ºå¼ é‡\n",
    "\n",
    "æœ€åï¼Œ`tokenizer` ä¼šè¿”å›å®é™…è¾“å…¥åˆ°æ¨¡å‹çš„å¼ é‡ã€‚\n",
    "\n",
    "è®¾ç½®å‚æ•° `return_tensors=\"pt\"`ï¼ˆå¯¹äº PyTorch ï¼‰æˆ– `return_tensors=\"tf\"`ï¼ˆå¯¹äº TensorFlow ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## éŸ³é¢‘\n",
    "\n",
    "å¯¹äºéŸ³é¢‘ä»»åŠ¡ï¼Œéœ€è¦ä½¿ç”¨ `feature extractor` æ¥é¢„å¤„ç†æ•°æ®é›†ä»¥ä¾›æ¨¡å‹ä½¿ç”¨ã€‚\n",
    "\n",
    "`Feature extractor` èƒ½å¤Ÿä»åŸå§‹çš„éŸ³é¢‘æ•°æ®ä¸­æå–å‡ºç‰¹å¾ï¼Œå¹¶å°†å®ƒä»¬è½¬æ¢ä¸ºå¼ é‡ã€‚\n",
    "\n",
    "åŠ è½½`[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)`æ•°æ®é›†ï¼ˆæœ‰å…³å¦‚ä½•åŠ è½½æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… ğŸ¤—`[Datasetsæ•™ç¨‹](https://huggingface.co/docs/datasets/load_hub)`ï¼‰ä»¥äº†è§£å¦‚ä½•åœ¨éŸ³é¢‘æ•°æ®é›†ä¸­ä½¿ç”¨ feature extractorï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "\n",
    "# è®¿é—® audio åˆ—çš„ç¬¬ä¸€ä¸ªå…ƒç´ ä»¥æŸ¥çœ‹è¾“å…¥ã€‚è°ƒç”¨ audio åˆ—ä¼šè‡ªåŠ¨åŠ è½½å’Œé‡æ–°é‡‡æ ·éŸ³é¢‘æ–‡ä»¶ï¼š\n",
    "dataset[0][\"audio\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset[0][\"audio\"]è¿”å›çš„ç»“æœåŒ…å«äº†ä¸‰ä¸ªå¯¹è±¡ï¼š\n",
    "- `array` æ˜¯ä¸€ä¸ªåŒ…å«éŸ³é¢‘æ ·æœ¬æŒ¯å¹…å€¼çš„æ•°ç»„ï¼Œä¼šåœ¨å¿…è¦æ—¶é‡æ–°é‡‡ä¸ºä¸€ä½æ•°ç»„ï¼ˆ1D arrayï¼‰ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªéŸ³é¢‘æ ·æœ¬çš„æŒ¯å¹…ï¼Œé‡‡æ ·ç‡å†³å®šäº†æ¯ç§’é’Ÿé‡‡é›†çš„æ ·æœ¬æ•°ã€‚\n",
    "- `path` æ˜¯éŸ³é¢‘æ–‡ä»¶çš„ä½ç½®ã€‚\n",
    "- `sampling_rate` æ˜¯éŸ³é¢‘çš„é‡‡æ ·ç‡ï¼Œå•ä½æ˜¯èµ«å…¹ï¼ˆHzï¼‰ã€‚å¸¸è§çš„é‡‡æ ·ç‡æœ‰ 16000 Hzã€22050 Hzã€44100 Hz ç­‰ã€‚\n",
    "\n",
    "å‡è®¾æœ‰ä¸€ä¸ªé‡‡æ ·ç‡ä¸º 16000 Hz çš„éŸ³é¢‘ä¿¡å·ï¼ŒæŒç»­æ—¶é—´ä¸º1ç§’ï¼Œé‚£ä¹ˆè¿™ä¸ªéŸ³é¢‘ä¿¡å·å¯ä»¥ç”¨ä¸€ä¸ªåŒ…å«16000ä¸ªå…ƒç´ çš„1D arrayæ¥è¡¨ç¤ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼ŒåŠ è½½ä¸€ä¸ª`feature extractor`ä»¥å¯¹è¾“å…¥è¿›è¡Œæ ‡å‡†åŒ–å’Œå¡«å……ã€‚\n",
    "\n",
    "å¡«å……æ–‡æœ¬çš„ç†å¿µåŒæ ·é€‚ç”¨äºé¢„å¤„ç†éŸ³é¢‘æ•°æ®ã€‚å½“å¡«å……æ–‡æœ¬æ•°æ®æ—¶ï¼Œä¼šä¸ºè¾ƒçŸ­çš„åºåˆ—å¡«å…… 0ã€‚åœ¨`feature extractor`ä¸­ï¼Œä¼šä¸ºè¾ƒçŸ­çš„æ•°ç»„å¡«å…… 0 è¡¨ç¤ºé™éŸ³ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `AutoFeatureExtractor.from_pretrained()` åŠ è½½ feature extractorï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°†éŸ³é¢‘æ ·æœ¬çš„æ•°ç»„`dataset[0][\"audio\"][\"array\"]`ä¼ é€’ç»™ feature extractorã€‚ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_input = [dataset[0][\"audio\"][\"array\"]]\n",
    "feature_extractor(audio_input, sampling_rate=16000) # å»ºè®®åœ¨ feature extractor ä¸­è®¾ç½® sampling_rate å‚æ•°ä¸ºéŸ³é¢‘æ ·æœ¬çš„é‡‡æ ·ç‡ï¼Œä»¥æ›´å¥½åœ°è°ƒè¯•å¯èƒ½å‘ç”Ÿçš„é™éŸ³é”™è¯¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°±åƒ`tokenizer`ä¸€æ ·ï¼Œå¯ä»¥åº”ç”¨å¡«å……æˆ–æˆªæ–­æ¥å¤„ç†æ‰¹æ¬¡ä¸­ä¸åŒé•¿åº¦çš„åºåˆ—ã€‚è¯·æŸ¥çœ‹è¿™ä¸¤ä¸ªéŸ³é¢‘æ ·æœ¬çš„åºåˆ—é•¿åº¦ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"audio\"][\"array\"].shape\n",
    "\n",
    "dataset[1][\"audio\"][\"array\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥é¢„å¤„ç†æ•°æ®é›†ï¼Œä»¥ä½¿éŸ³é¢‘æ ·æœ¬å…·æœ‰ç›¸åŒçš„é•¿åº¦ã€‚é€šè¿‡æŒ‡å®šæ ·æœ¬æœ€å¤§çš„é•¿åº¦`max_length`ï¼Œ`feature extractor` å°†å¡«å……æˆ–æˆªæ–­åºåˆ—ä»¥ä½¿å…¶åŒ¹é…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=16000,\n",
    "        padding=True,\n",
    "        max_length=100000,\n",
    "        truncation=True,\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°†é¢„å¤„ç†å‡½æ•°`preprocess_function`åº”ç”¨äºæ•°æ®é›†ä¸­çš„å‰å‡ ä¸ªç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = preprocess_function(dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æ ·æœ¬çš„é•¿åº¦æ˜¯ç›¸åŒçš„ï¼Œå¹¶ä¸”ä¸æŒ‡å®šçš„æœ€å¤§é•¿åº¦ç›¸åŒ¹é…ã€‚ç°åœ¨å¯ä»¥å°†ç»è¿‡å¤„ç†çš„æ•°æ®é›†è¾“å…¥æ¨¡å‹äº†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset[\"input_values\"][0].shape\n",
    "\n",
    "processed_dataset[\"input_values\"][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®¡ç®—æœºè§†è§‰ï¼ˆå›¾åƒé¢„å¤„ç†ï¼‰\n",
    "\n",
    "å¯¹äºè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œéœ€è¦ä½¿ç”¨`image processor`æ¥é¢„å¤„ç†æ•°æ®é›†ä»¥ä¾›æ¨¡å‹ä½¿ç”¨ã€‚\n",
    "\n",
    "å›¾åƒé¢„å¤„ç†åŒ…æ‹¬å¤šä¸ªæ­¥éª¤ï¼Œèƒ½å¤Ÿå°†å›¾åƒè½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„è¾“å…¥æ ¼å¼ã€‚è¿™äº›æ­¥éª¤åŒ…æ‹¬è°ƒæ•´å›¾åƒå¤§å°ã€æ ‡å‡†åŒ–ã€é¢œè‰²é€šé“æ ¡æ­£ä»¥åŠå°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ç­‰æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å›¾åƒé¢„å¤„ç†é€šå¸¸éµå¾ªæŸç§å½¢å¼çš„å›¾åƒå¢å¼ºã€‚å›¾åƒé¢„å¤„ç†å’Œå›¾åƒå¢å¼ºéƒ½ä¼šæ”¹å˜å›¾åƒæ•°æ®ï¼Œä½†å®ƒä»¬æœ‰ä¸åŒçš„ç›®çš„ï¼š\n",
    "\n",
    "- `å›¾åƒå¢å¼º`å¯ä»¥å¸®åŠ©é˜²æ­¢è¿‡æ‹Ÿåˆå¹¶å¢åŠ æ¨¡å‹çš„é²æ£’æ€§ã€‚ä½ å¯ä»¥åœ¨æ•°æ®å¢å¼ºæ–¹é¢å……åˆ†å‘æŒ¥åˆ›é€ æ€§ï¼Œå¦‚è°ƒæ•´äº®åº¦å’Œé¢œè‰²ã€è£å‰ªã€æ—‹è½¬ã€è°ƒæ•´å¤§å°ã€ç¼©æ”¾ç­‰ï¼Œä½†è¦æ³¨æ„ä¸è¦æ”¹å˜å›¾åƒçš„å«ä¹‰ã€‚\n",
    "- `å›¾åƒé¢„å¤„ç†`ç¡®ä¿å›¾åƒä¸æ¨¡å‹é¢„æœŸçš„è¾“å…¥æ ¼å¼åŒ¹é…ã€‚åœ¨å¾®è°ƒè®¡ç®—æœºè§†è§‰æ¨¡å‹æ—¶ï¼Œå¿…é¡»ä¿è¯å¯¹æ ·æœ¬å›¾åƒè¿›è¡Œä¸æ¨¡å‹è®­ç»ƒæ—¶ç›¸åŒçš„é¢„å¤„ç†ã€‚**å¯¹äºå›¾åƒé¢„å¤„ç†ï¼Œè¯·ä½¿ç”¨ä¸æ¨¡å‹ç›¸å…³è”çš„ `ImageProcessor`**ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ è½½[food101](https://huggingface.co/datasets/food101)æ•°æ®é›†ï¼ˆæœ‰å…³å¦‚ä½•åŠ è½½æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ğŸ¤—[Datasetsæ•™ç¨‹](https://huggingface.co/docs/datasets/load_hub)ï¼‰ä»¥äº†è§£å¦‚ä½•åœ¨è®¡ç®—æœºè§†è§‰æ•°æ®é›†ä¸­ä½¿ç”¨å›¾åƒå¤„ç†å™¨ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ä¸ºå›¾åƒæ•°æ®é›†ç›¸å½“å¤§ï¼Œè¯·ä½¿ç”¨ ğŸ¤— Datasets çš„ `split` å‚æ•°åŠ è½½å°‘é‡çš„è®­ç»ƒæ ·æœ¬."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"food101\", split=\"train[:100]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ğŸ¤— Datasets çš„ `[Image](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image)` åŠŸèƒ½æŸ¥çœ‹å›¾åƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vision-preprocess-tutorial](../../resources/images/vision-preprocess-tutorial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `AutoImageProcessor.from_pretrained()` åŠ è½½ image processorï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆï¼Œè®©æˆ‘ä»¬è¿›è¡Œå›¾åƒå¢å¼ºã€‚ä½ å¯ä»¥ä½¿ç”¨ä»»ä½•ä½ å–œæ¬¢çš„å›¾åƒå¢å¼ºåº“ã€‚\n",
    "\n",
    "å¦‚æœä½ æœ‰å…´è¶£ä½¿ç”¨å…¶ä»–çš„å›¾åƒå¢å¼ºåº“ï¼Œå¯ä»¥å‚è€ƒä¸€ä¸‹[Albumentations](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)æˆ–[Kornia notebooks](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)ä¸­çš„ç¤ºä¾‹ã€‚\n",
    "\n",
    "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`torchvision`çš„`[transforms](https://pytorch.org/vision/stable/transforms.html)`åº“æ¥è¿›è¡Œå›¾åƒå¢å¼ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨`[Compose](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html)`å°†`[RandomResizedCrop](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html)`å’Œ`[ColorJitter](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html)`å˜æ¢è¿æ¥åœ¨ä¸€èµ·ã€‚**è¯·æ³¨æ„ï¼Œå¯¹äºè°ƒæ•´å¤§å°ï¼Œæˆ‘ä»¬å¯ä»¥ä»image_processorä¸­è·å–å›¾åƒå°ºå¯¸è¦æ±‚ã€‚**å¯¹äºä¸€äº›æ¨¡å‹ï¼Œéœ€è¦å®šä¹‰ç²¾ç¡®çš„é«˜åº¦å’Œå®½åº¦ï¼Œè€Œå¯¹äºå…¶ä»–æ¨¡å‹åˆ™åªéœ€å®šä¹‰`shortest_edge`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torchvision.transforms import RandomResizedCrop, ColorJitter, Compose\n",
    "except ImportError:\n",
    "    raise ImportError(\"'torchvision' could not be resolved. Please install it by 'pip install torchvision'.\")\n",
    "\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"]) # å¦‚æœä¸åŒ…å« shortest_edge é”®ï¼Œåˆ™ size å˜é‡è¢«è®¾ç½®ä¸ºå›¾åƒçš„åŸå§‹é«˜åº¦å’Œå®½åº¦ã€‚\n",
    ")\n",
    "\n",
    "_transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=0.5, hue=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shortest_edge`ï¼šæŒ‡çš„æ˜¯å›¾åƒçš„é«˜åº¦å’Œå®½åº¦ä¸­çš„è¾ƒå°å€¼ï¼Œä»¥ç¡®ä¿å¤„ç†åçš„å›¾åƒå…·æœ‰ä¸€è‡´çš„æœ€çŸ­è¾¹é•¿ã€‚ä¾‹å¦‚ï¼Œå¯¹äºä¸€ä¸ªå°ºå¯¸ä¸º 800x600 çš„å›¾åƒï¼Œå³shortest_edge=600ã€‚\n",
    "\n",
    "`image_processor.size`ï¼šæ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«äº†å›¾åƒå¤„ç†çš„ç›¸å…³å°ºå¯¸ä¿¡æ¯ã€‚å¯èƒ½åŒ…å« `shortest_edge`ã€`height` å’Œ `width` ç­‰å¥ã€‚\n",
    "\n",
    "`RandomResizedCrop(size)`ï¼š\n",
    "- è¿™ä¸ªå˜æ¢ä¼šéšæœºè£å‰ªå›¾åƒå¹¶è°ƒæ•´åˆ°æŒ‡å®šçš„ sizeã€‚\n",
    "- å¦‚æœ size æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œåˆ™è¡¨ç¤ºè£å‰ªåçš„å›¾åƒçš„æœ€çŸ­è¾¹é•¿ã€‚\n",
    "- å¦‚æœ size æ˜¯ä¸€ä¸ªå…ƒç»„ (height, width)ï¼Œåˆ™è¡¨ç¤ºè£å‰ªåçš„å›¾åƒçš„ç›®æ ‡å°ºå¯¸ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. æ¨¡å‹æ¥å— `pixel_values` ä½œä¸ºè¾“å…¥ã€‚`ImageProcessor` å¯ä»¥è¿›è¡Œå›¾åƒæ ‡å‡†åŒ–ï¼Œå¹¶ç”Ÿæˆå¼ é‡ã€‚åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå°†å›¾åƒå¢å¼ºå’Œå›¾åƒé¢„å¤„ç†çš„æ­¥éª¤ç»„åˆèµ·æ¥å¤„ç†æ‰¹é‡å›¾åƒï¼Œå¹¶ç”Ÿæˆ `pixel_values`ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    images = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    examples[\"pixel_values\"] = image_processor(images, do_resize=False, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é»˜è®¤æƒ…å†µä¸‹`ImageProcessor`ä¼šè°ƒæ•´å›¾åƒçš„å¤§å°ã€‚å› ä¸ºæˆ‘ä»¬å·²ç»åœ¨å›¾åƒå¢å¼ºè½¬æ¢ä¸­è°ƒæ•´äº†å›¾åƒçš„å¤§å°(`_transforms` ä¸­å·²ç»åŒ…å«äº†å°ºå¯¸è°ƒæ•´çš„æ­¥éª¤ï¼ˆå¦‚`RandomResizedCrop`ï¼‰)ï¼Œæ‰€ä»¥ä¸éœ€è¦ `image_processor` å†æ¬¡è°ƒæ•´å°ºå¯¸ï¼Œé€šè¿‡è®¾ç½®å‚æ•° `do_resize=False`å¯ä»¥ä¿æŒå›¾åƒçš„åŸå§‹å°ºå¯¸ã€‚\n",
    "\n",
    "å¦‚æœæƒ³è¦å°†å›¾åƒæ ‡å‡†åŒ–æ­¥éª¤ä¸ºå›¾åƒå¢å¼ºçš„ä¸€éƒ¨åˆ†ï¼Œè¯·ä½¿ç”¨`image_processor.image_mean`å’Œ`image_processor.image_std`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ç„¶åä½¿ç”¨ ğŸ¤— Datasets çš„`[set_transform](https://huggingface.co/docs/datasets/process#format-transform)`åœ¨è¿è¡Œæ—¶å¯¹å›¾ç‰‡åº”ç”¨`transforms`è¿›è¡Œå˜æ¢ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_transform(transforms)\n",
    "\n",
    "# å½“ä½ è®¿é—®å›¾åƒæ—¶ï¼Œå¯ä»¥çœ‹åˆ°`image processor`å·²æ·»åŠ äº†`pixel_valuesï¼ˆåƒç´ å€¼ï¼‰`ã€‚\n",
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ç°åœ¨å¯ä»¥å°†ç»è¿‡å¤„ç†çš„æ•°æ®é›†è¾“å…¥ç»™æ¨¡å‹äº†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = dataset[0][\"pixel_values\"]\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™æ˜¯åœ¨åº”ç”¨å˜æ¢åçš„å›¾åƒæ ·å­ã€‚å›¾åƒå·²è¢«éšæœºè£å‰ªï¼Œå¹¶ä½¿å…¶é¢œè‰²å±æ€§å‘ç”Ÿäº†å˜åŒ–ã€‚  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![preprocessed_image](../../resources/images/preprocessed_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹äºè¯¸å¦‚ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ã€å®ä¾‹åˆ†å‰²å’Œå…¨æ™¯åˆ†å‰²ç­‰ä»»åŠ¡ï¼Œ`ImageProcessor` éƒ½æä¾›äº†è®­ç»ƒåå¤„ç†æ–¹æ³•ã€‚**è¿™äº›æ–¹æ³•èƒ½å¤Ÿå°†æ¨¡å‹çš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºæœ‰æ„ä¹‰çš„é¢„æµ‹ç»“æœï¼Œå¦‚è¾¹ç•Œæ¡†æˆ–åˆ†å‰²åœ°å›¾ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¡«å……\n",
    "\n",
    "åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¾‹å¦‚ï¼Œåœ¨å¾®è°ƒ`[DETR](https://huggingface.co/docs/transformers/main/en/model_doc/detr)`æ—¶ï¼Œæ¨¡å‹åœ¨è®­ç»ƒé˜¶æ®µåº”ç”¨äº†å°ºåº¦å¢å¼ºï¼Œè¿™å¯èƒ½å¯¼è‡´æ‰¹å¤„ç†ä¸­çš„å›¾åƒå¤§å°ä¸åŒã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªå‡½æ•°`collate_fn`ï¼Œç”¨äºåœ¨æ•°æ®åŠ è½½è¿‡ç¨‹ä¸­å¯¹æ¯ä¸ªæ‰¹æ¬¡ï¼ˆbatchï¼‰çš„æ•°æ®è¿›è¡Œæ•´ç†å’Œé¢„å¤„ç†ã€‚\n",
    "\n",
    "åœ¨å¤„ç†å›¾åƒå’Œæ–‡æœ¬æ•°æ®æ—¶ï¼Œ`collate_fn` é€šå¸¸è®¾å®šä¸ºå°†ä¸€ä¸ªæ‰¹æ¬¡ä¸­çš„å¤šä¸ªæ ·æœ¬æ•´ç†æˆä¸€ä¸ªç»Ÿä¸€çš„æ ¼å¼ï¼Œä»¥ä¾¿äºæ¨¡å‹è®­ç»ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # 1. æå–åƒç´ å€¼ï¼šä»æ¯ä¸ªæ ·æœ¬ä¸­æå– pixel_valuesï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«å›¾åƒæ•°æ®çš„åˆ—è¡¨ã€‚\n",
    "    pixel_values = [item[\"pixel_values\"] for item in batch]\n",
    "    # 2. å¡«å……æ“ä½œï¼šä½¿ç”¨ DetrImageProcessor.pad() æ–¹æ³•å¯¹å›¾åƒæ•°æ®è¿›è¡Œå¡«å……ï¼Œç¡®ä¿æ‰€æœ‰å›¾åƒå…·æœ‰ç›¸åŒçš„å°ºå¯¸ï¼Œè¿”å› PyTorch å¼ é‡ã€‚\n",
    "    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "    # 3. æå–æ ‡ç­¾ï¼šä»æ¯ä¸ªæ ·æœ¬ä¸­æå– labelsï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«æ ‡ç­¾çš„åˆ—è¡¨ã€‚\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    # 4. åˆ›å»ºæ‰¹æ¬¡å­—å…¸ï¼šå°†å¡«å……åçš„åƒç´ å€¼ã€åƒç´ æ©ç å’Œæ ‡ç­¾æ•´ç†æˆä¸€ä¸ªå­—å…¸ï¼Œä¾¿äºåç»­çš„æ¨¡å‹è¾“å…¥ã€‚\n",
    "    batch = {}\n",
    "    batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n",
    "    batch[\"pixel_mask\"] = encoding[\"pixel_mask\"]\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºä»€ä¹ˆéœ€è¦ `collate_fn` \n",
    "\n",
    "- æ‰¹å¤„ç†ä¸€è‡´æ€§ï¼šåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ¨¡å‹é€šå¸¸ä»¥æ‰¹æ¬¡ä¸ºå•ä½è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡ collate_fn ç¡®ä¿æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®æ ¼å¼æ˜¯ä¸€è‡´çš„ã€‚\n",
    "- æ•°æ®å¡«å……ï¼šä¸åŒæ ·æœ¬çš„å›¾åƒå°ºå¯¸å¯èƒ½ä¸åŒï¼Œé€šè¿‡ collate_fn ä¸­çš„å¡«å……æ“ä½œå¯ä»¥ä½¿å®ƒä»¬å…·æœ‰ç›¸åŒçš„å°ºå¯¸ï¼Œä¾¿äºæ‰¹å¤„ç†ã€‚\n",
    "- æ©ç ç”Ÿæˆï¼šæ©ç å¯ä»¥å¸®åŠ©æ¨¡å‹åŒºåˆ†å®é™…æ•°æ®å’Œå¡«å……æ•°æ®ï¼Œé¿å…æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å—åˆ°å¡«å……æ•°æ®çš„å¹²æ‰°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¤šæ¨¡æ€\n",
    "\n",
    "å¯¹äºæ¶‰åŠå¤šæ¨¡æ€è¾“å…¥çš„ä»»åŠ¡ï¼Œä½ éœ€è¦ processor æ¥ä¸ºæ¨¡å‹å‡†å¤‡æ•°æ®é›†ã€‚\n",
    "\n",
    "`Processor` å°†ä¸¤ä¸ªå¤„ç†å¯¹è±¡ç»„åˆåœ¨ä¸€èµ·ï¼ˆä¾‹å¦‚tokenizerå’Œfeature extractorï¼‰ã€‚\n",
    "\n",
    "åŠ è½½[LJ Speech](https://huggingface.co/datasets/keithito/lj_speech)æ•°æ®é›†ï¼Œæœ‰å…³å¦‚ä½•åŠ è½½æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/load_hub) æ•™ç¨‹ï¼Œä»¥äº†è§£å¦‚ä½•ä½¿ç”¨ processor è¿›è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "lj_speech = load_dataset(\"lj_speech\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹äº`ASR`ï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰ï¼Œä¸»è¦å…³æ³¨`Audio`å’Œ`Text`ï¼Œå› æ­¤å¯ä»¥åˆ é™¤å…¶ä»–åˆ—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_speech = lj_speech.map(remove_columns=[\"file\", \"id\", \"normalized_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹`Audio`å’Œ`Text`åˆ—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_speech[0][\"audio\"]\n",
    "\n",
    "lj_speech[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ³¨æ„ï¼Œä½ åº”å§‹ç»ˆé‡æ–°é‡‡æ ·éŸ³é¢‘æ•°æ®é›†çš„é‡‡æ ·ç‡ï¼Œä¸ç”¨äºé¢„è®­ç»ƒæ¨¡å‹æ•°æ®é›†çš„é‡‡æ ·ç‡ä¿æŒä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_speech = lj_speech.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨`AutoProcessor.from_pretrained()`åŠ è½½ä¸€ä¸ª Processorï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. å®šä¹‰ä¸€ä¸ªå‡½æ•°`prepare_dataset`ï¼Œç”¨äºå°†åŒ…å«åœ¨ `array` ä¸­çš„éŸ³é¢‘æ•°æ®å¤„ç†ä¸º `input_values`ï¼Œå¹¶å°† `text` æ ‡è®°ä¸º `labels`ã€‚è¿™äº›å°†æ˜¯è¾“å…¥æ¨¡å‹çš„æ•°æ®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "    example.update(processor(audio=audio[\"array\"], text=example[\"text\"], sampling_rate=16000))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. å°† `prepare_dataset` åº”ç”¨äºä¸€ä¸ªç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset(lj_speech[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Processor` ç°åœ¨å·²ç»æ·»åŠ äº† `input_values` å’Œ `labels`ï¼Œå¹¶ä¸”é‡‡æ ·ç‡ä¹Ÿæ­£ç¡®åœ°é™ä½ä¸º16kHzã€‚ç°åœ¨å¯ä»¥å°†å¤„ç†åçš„æ•°æ®é›†è¾“å…¥ç»™æ¨¡å‹äº†ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
