{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å†™åœ¨æœ€å‰\n",
    "\n",
    "è¯·è®°ä½ï¼Œåœ¨æœ¬ç« çš„å†…å®¹ä¸­ï¼Œâ€œæ¶æ„â€æŒ‡çš„æ˜¯æ¨¡å‹çš„ç»“æ„ï¼Œè€Œ \"checkpoint\" æ˜¯ç»™å®šæ¶æ„çš„æƒé‡ï¼ˆä¹Ÿå°±æ˜¯é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡ï¼Œä¹Ÿå¯æŒ‡ä»£é¢„è®­ç»ƒæ¨¡å‹æœ¬èº«ï¼‰ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œâ€œBERTâ€ æ˜¯ä¸€ç§æ¶æ„ï¼Œè€Œ â€œgoogle-bert/bert-base-uncasedâ€ æ˜¯ä¸€ä¸ª checkpointã€‚â€œæ¨¡å‹â€åˆ™æ˜¯ä¸€ä¸ªé€šç”¨æœ¯è¯­ï¼Œå¯ä»¥æŒ‡ä»£æ¶æ„æˆ–checkpointã€‚\n",
    "\n",
    "åœ¨ `ğŸ¤— Transformers` çš„ç¤ºä¾‹ä»£ç ä¸­ï¼Œä½ é€šè¿‡æ›¿æ¢ \"model\" å‚æ•°çš„å€¼æ¥é€‰æ‹©ä¸åŒçš„æ¨¡å‹ã€‚\n",
    "\n",
    "åœ¨è¿™ä¸ªæ•™ç¨‹ä¸­ï¼Œå°†ä¼šå­¦ä¹ å¦‚ä½•ï¼š\n",
    "\n",
    "1. åŠ è½½é¢„è®­ç»ƒçš„åˆ†è¯å™¨ï¼ˆtokenizerï¼‰\n",
    "2. åŠ è½½é¢„è®­ç»ƒçš„å›¾åƒå¤„ç†å™¨(image processor)\n",
    "3. åŠ è½½é¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨(feature extractor)\n",
    "4. åŠ è½½é¢„è®­ç»ƒçš„å¤„ç†å™¨(processor)\n",
    "5. åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹ã€‚\n",
    "\n",
    "# ä½¿ç”¨AutoClassåŠ è½½é¢„è®­ç»ƒå®ä¾‹\n",
    "\n",
    "ç”±äºå­˜åœ¨è®¸å¤šä¸åŒçš„ Transformer æ¶æ„ï¼Œå› æ­¤ä¸º checkpoint åˆ›å»ºä¸€ä¸ªå¯ç”¨çš„æ¶æ„å¯èƒ½ä¼šå…·æœ‰æŒ‘æˆ˜æ€§ã€‚\n",
    "\n",
    "**é€šè¿‡ `AutoClass` å¯ä»¥è‡ªåŠ¨æ¨æ–­å¹¶ä»ç»™å®šçš„ checkpoint åŠ è½½æ­£ç¡®çš„æ¶æ„**, è¿™ä¹Ÿæ˜¯ä½“ç° ğŸ¤— Transformers æ˜“äºä½¿ç”¨ã€ç®€å•ä¸”çµæ´»çš„æ ¸å¿ƒéƒ¨åˆ†ã€‚\n",
    "\n",
    "**å¦‚æœä½ çš„ä»£ç é€‚ç”¨äºä¸€ä¸ª checkpointï¼Œå®ƒå°†é€‚ç”¨äºå¦ä¸€ä¸ª checkpoint**ï¼Œåªè¦å®ƒä»¬æ˜¯ä¸ºäº†ç›¸ä¼¼çš„ä»»åŠ¡è¿›è¡Œè®­ç»ƒçš„ï¼Œå³ä½¿å®ƒä»¬çš„æ¶æ„æœ‰æ‰€ä¸åŒã€‚\n",
    "\n",
    "`from_pretrained()` æ–¹æ³•å…è®¸ä½ å¿«é€ŸåŠ è½½ä»»ä½•æ¶æ„çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¸éœ€è¦èŠ±è´¹æ—¶é—´å’Œç²¾åŠ›ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoTokenizer\n",
    "\n",
    "å‡ ä¹æ‰€æœ‰çš„ NLP ä»»åŠ¡éƒ½ä»¥ `tokenizer` å¼€å§‹ã€‚Tokenizer èƒ½å¤Ÿå°†ä½ çš„è¾“å…¥è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£å’Œå¤„ç†çš„æ ¼å¼(å³æ¨¡å‹æ­£ç¡®çš„è¾“å…¥æ ¼å¼)ã€‚\n",
    "\n",
    "ä½¿ç”¨ `AutoTokenizer.from_pretrained()` åŠ è½½ tokenizerï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åæŒ‰ç…§å¦‚ä¸‹æ–¹å¼å¯¹è¾“å…¥è¿›è¡Œåˆ†è¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"In a hole in the ground there lived a hobbit.\"\n",
    "print(tokenizer(sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoImageProcessor\n",
    "\n",
    "å¯¹äºè§†è§‰ä»»åŠ¡ï¼Œ`ImageProcessor` èƒ½å¤Ÿå°†å›¾åƒå¤„ç†æˆæ­£ç¡®çš„è¾“å…¥æ ¼å¼ã€‚\n",
    "\n",
    "è¿™é‡Œä½¿ç”¨`AutoImageProcessor.from_pretrained()`åŠ è½½ Image Processorï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoFeatureExtractor\n",
    "\n",
    "å¯¹äºéŸ³é¢‘ä»»åŠ¡, `Feature Extractor` å°†éŸ³é¢‘ä¿¡å·å¤„ç†æˆæ­£ç¡®çš„è¾“å…¥æ ¼å¼ã€‚\n",
    "\n",
    "è¿™é‡Œä½¿ç”¨`AutoFeatureExtractor.from_pretrained()`åŠ è½½ Feature Extractorï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoProcessor\n",
    "\n",
    "å¯¹äºå¤šæ¨¡æ€ä»»åŠ¡åªéœ€è¦ä¸€ä¸ª `Processor` å°±èƒ½å¤Ÿå°†ä¸¤ç§ç±»å‹çš„é¢„å¤„ç†å·¥å…·ç»“åˆèµ·æ¥ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼ŒLayoutLMV2 æ¨¡å‹éœ€è¦ä¸€ä¸ª image processor æ¥å¤„ç†å›¾åƒå’Œä¸€ä¸ª tokenizer æ¥å¤„ç†æ–‡æœ¬ï¼›Processor ä¼šå°†ä¸¤è€…ç»“åˆèµ·æ¥ã€‚\n",
    "\n",
    "ä½¿ç”¨`AutoProcessor.from_pretrained()`åŠ è½½ Processorï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoModel\n",
    "\n",
    "`AutoModelFor*` ç±»èƒ½å¤ŸåŠ è½½ç»™å®šä»»åŠ¡ç±»å‹çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆ[æ”¯æŒçš„ä»»åŠ¡åˆ—è¡¨](https://huggingface.co/docs/transformers/main/en/model_doc/auto)ï¼‰ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œä½¿ç”¨ `AutoModelForSequenceClassification.from_pretrained()` åŠ è½½ç”¨äºåºåˆ—åˆ†ç±»çš„æ¨¡å‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯ä»¥ä½¿ç”¨ç›¸åŒçš„ checkpoint æ¥ä¸ºä¸åŒçš„ä»»åŠ¡åŠ è½½æ¨¡å‹æ¶æ„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹äº PyTorch æ¨¡å‹ï¼Œ`from_pretrained()`æ–¹æ³•åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œé€šå¸¸ä½¿ç”¨`torch.load()`ï¼Œå®ƒå†…éƒ¨ä½¿ç”¨çš„æ˜¯ä¸å®‰å…¨çš„ `pickle`ï¼Œ pickle åŠ è½½ä¸å¯ä¿¡çš„æ•°æ®å¯èƒ½å­˜åœ¨å®‰å…¨é£é™©ï¼ˆå¦‚ä»£ç æ‰§è¡Œæ¼æ´ï¼‰ã€‚\n",
    "\n",
    "æ°¸è¿œä¸è¦åŠ è½½é‚£äº›æ¥è‡ªä¸å¯ä¿¡æ¥æºæˆ–å¯èƒ½è¢«ç¯¡æ”¹çš„æ¨¡å‹ã€‚å»ºè®®å¯¹äºæ‰˜ç®¡åœ¨ Hugging Face Hub ä¸Šçš„å…¬å…±æ¨¡å‹ï¼Œå› ä¸ºæ¯æ¬¡æäº¤éƒ½ä¼šè¿›è¡Œæ¶æ„è½¯ä»¶æ‰«æï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äº†å®‰å…¨é£é™©ã€‚\n",
    "\n",
    "å»ºè®®ä½¿ç”¨[ä½¿ç”¨ GPG è¿›è¡Œç­¾åæäº¤éªŒè¯](https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg)ç­‰æœ€ä½³å®è·µæ¥è¿›ä¸€æ­¥ç¡®ä¿å®‰å…¨æ€§ï¼Œå¯å‚é˜…[Hub æ–‡æ¡£](https://huggingface.co/docs/hub/security)ä»¥äº†è§£æœ€ä½³å®è·µã€‚\n",
    "\n",
    "**TensorFlow å’Œ Flax åœ¨åŠ è½½ checkpoints ä¸ä½¿ç”¨ pickle ï¼Œä¸å­˜åœ¨ç”± pickle å¼•èµ·çš„å®‰å…¨é—®é¢˜ã€‚** \n",
    "\n",
    "åœ¨ PyTorch ä¸­å¯ä»¥é€šè¿‡ `from_pretrained()` æ–¹æ³•çš„ `from_tf` å’Œ `from_flax` å‚æ•°æ¥åŠ è½½ TensorFlow å’Œ Flax çš„ checkpointsï¼Œè¿›è€Œç»•è¿‡ torch.load() ä½¿ç”¨ pickle çš„å®‰å…¨é£é™©ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®é™…æ“ä½œç¤ºä¾‹\n",
    "\n",
    "é€šè¿‡åŠ è½½ TensorFlowå’Œ Flax çš„ checkpointsï¼Œå¯ä»¥é¿å…ä½¿ç”¨ torch.load()åŠå…¶pickleçš„å®‰å…¨é£é™©ã€‚\n",
    "\n",
    "å‡è®¾ä½ æƒ³è¦åŠ è½½ä¸€ä¸ªåœ¨ Hugging Face Hub ä¸Šæ‰˜ç®¡çš„ TensorFlow æ¨¡å‹åˆ° PyTorch ä¸­ï¼Œå¯ä»¥è¿™æ ·åšï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# åŠ è½½TensorFlowæ¨¡å‹ï¼Œå¹¶å°† TensorFlow æ¨¡å‹è½¬æ¢ä¸º PyTorch æ¨¡å‹\n",
    "pt_model = AutoModel.from_pretrained(\"bert-base-uncased\", from_tf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç±»ä¼¼åœ°ï¼Œå¦‚æœä½ è¦åŠ è½½ä¸€ä¸ª Flax æ¨¡å‹åˆ° PyTorch ä¸­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# åŠ è½½ Flax æ¨¡å‹ï¼Œå¹¶å°† Flax æ¨¡å‹è½¬æ¢ä¸º PyTorch æ¨¡å‹\n",
    "pt_model = AutoModel.from_pretrained(\"bert-base-uncased\", from_flax=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬ä¸å»ºè®®ä½¿ç”¨é€šç”¨çš„`AutoModel`æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯ä½¿ç”¨`AutoTokenizer`ç±»å’Œ`AutoModelFor*`ç±»æ¥åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹å®ä¾‹ï¼Œå› ä¸ºè¿™æ ·å¯ä»¥ç¡®ä¿åŠ è½½çš„æ˜¯æ­£ç¡®çš„æ¶æ„ã€‚\n",
    "\n",
    "åœ¨ä¸‹ä¸€ä¸ª[æ•™ç¨‹](../docs/4_preprocess_data.ipynb)ä¸­ï¼Œå­¦ä¹ å¦‚ä½•ä½¿ç”¨æ–°åŠ è½½çš„ tokenizer, image processor, feature extractor å’Œ processorå¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ä»¥è¿›è¡Œå¾®è°ƒã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
